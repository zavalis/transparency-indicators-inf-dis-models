<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2022-03-11T00:59:44Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:7699029" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:7699029</identifier>
        <datestamp>2020-12-01</datestamp>
        <setSpec>pheelsevier</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3-mathml3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Chaos Solitons Fractals</journal-id>
              <journal-id journal-id-type="iso-abbrev">Chaos Solitons Fractals</journal-id>
              <journal-title-group>
                <journal-title>Chaos, Solitons, and Fractals</journal-title>
              </journal-title-group>
              <issn pub-type="ppub">0960-0779</issn>
              <issn pub-type="epub">0960-0779</issn>
              <publisher>
                <publisher-name>Elsevier Ltd.</publisher-name>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC7699029</article-id>
              <article-id pub-id-type="pmcid">PMC7699029</article-id>
              <article-id pub-id-type="pmc-uid">7699029</article-id>
              <article-id pub-id-type="pmid">33281305</article-id>
              <article-id pub-id-type="pii">S0960-0779(20)30903-6</article-id>
              <article-id pub-id-type="doi">10.1016/j.chaos.2020.110511</article-id>
              <article-id pub-id-type="publisher-id">110511</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Article</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Prediction of COVID-19 confirmed cases combining deep learning methods and Bayesian optimization</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" id="au0001">
                  <name>
                    <surname>Abbasimehr</surname>
                    <given-names>Hossein</given-names>
                  </name>
                  <xref rid="cor0001" ref-type="corresp">⁎</xref>
                </contrib>
                <contrib contrib-type="author" id="au0002">
                  <name>
                    <surname>Paki</surname>
                    <given-names>Reza</given-names>
                  </name>
                </contrib>
                <aff id="aff0001">Faculty of Information Technology and Computer Engineering, Azarbaijan Shahid Madani University, Tabriz, Iran</aff>
              </contrib-group>
              <author-notes>
                <corresp id="cor0001"><label>⁎</label>Corresponding author.</corresp>
              </author-notes>
              <pub-date pub-type="pmc-release">
                <day>28</day>
                <month>11</month>
                <year>2020</year>
              </pub-date>
              <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
              <pub-date pub-type="ppub">
                <month>1</month>
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>28</day>
                <month>11</month>
                <year>2020</year>
              </pub-date>
              <volume>142</volume>
              <fpage>110511</fpage>
              <lpage>110511</lpage>
              <history>
                <date date-type="received">
                  <day>24</day>
                  <month>9</month>
                  <year>2020</year>
                </date>
                <date date-type="accepted">
                  <day>23</day>
                  <month>11</month>
                  <year>2020</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2020 Elsevier Ltd. All rights reserved.</copyright-statement>
                <copyright-year>2020</copyright-year>
                <copyright-holder>Elsevier Ltd</copyright-holder>
                <license>
                  <license-p>Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.</license-p>
                </license>
              </permissions>
              <abstract abstract-type="author-highlights" id="abs0001">
                <title>Highlights</title>
                <p>
                  <list list-type="simple" id="celist0001">
                    <list-item id="celistitem0001">
                      <label>•</label>
                      <p id="para0001">Three methods combining deep learning and Bayesian optimization are proposed.</p>
                    </list-item>
                    <list-item id="celistitem0002">
                      <label>•</label>
                      <p id="para0002">Bayesian optimization efficiently selects the optimized values for hyperparameters.</p>
                    </list-item>
                    <list-item id="celistitem0003">
                      <label>•</label>
                      <p id="para0003">The design of methods is based on the multiple-output forecasting strategy.</p>
                    </list-item>
                    <list-item id="celistitem0004">
                      <label>•</label>
                      <p id="para0004">The proposed methods outperform the benchmark model on COVID-19 time series data.</p>
                    </list-item>
                  </list>
                </p>
              </abstract>
              <abstract id="abs0002">
                <p>COVID-19 virus has encountered people in the world with numerous problems. Given the negative impacts of COVID-19 on all aspects of people's lives, especially health and economy, accurately forecasting the number of cases infected with this virus can help governments to make accurate decisions on the interventions that must be taken. In this study, we propose three hybrid approaches for forecasting COVID-19 time series methods based on combining three deep learning models such as multi-head attention, long short-term memory (LSTM), and convolutional neural network (CNN) with the Bayesian optimization algorithm. All models are designed based on the multiple-output forecasting strategy, which allows the forecasting of the multiple time points. The Bayesian optimization method automatically selects the best hyperparameters for each model and enhances forecasting performance. Using the publicly available epidemical data acquired from Johns Hopkins University's Coronavirus Resource Center, we conducted our experiments and evaluated the proposed models against the benchmark model. The results of experiments exhibit the superiority of the deep learning models over the benchmark model both for short-term forecasting and long-horizon forecasting. In particular, the mean SMAPE of the best deep learning model is 0.25 for the short-term forecasting (10 days ahead). Also, for long-horizon forecasting, the best deep learning model obtains the mean SMAPE of 2.59.</p>
              </abstract>
              <kwd-group id="keys0001">
                <title>Keywords</title>
                <kwd>COVID-19</kwd>
                <kwd>Deep learning</kwd>
                <kwd>Multi-head attention</kwd>
                <kwd>CNN</kwd>
                <kwd>LSTM</kwd>
                <kwd>Bayesian optimization</kwd>
              </kwd-group>
            </article-meta>
          </front>
          <body>
            <sec id="sec0001">
              <label>1</label>
              <title>Introduction</title>
              <p id="para0005">Coronavirus 2019 (COVID-19) pandemic <xref rid="bib0001" ref-type="bibr">[1]</xref> has spread from Wuhan, China to other countries in the world. It has high viral infectivity and a rapid rate of spread compared to prior infectious diseases which makes its control hard <xref rid="bib0002" ref-type="bibr">[2]</xref>. Since its emergence, COVID-19 disease has encountered people in the world with many problems. It has more negative impacts on people's health and interrupted the economy. As a result, many countries have implemented strong interventions to control the spread of the epidemic and to reduce the negative effects of COVID-19 disease <xref rid="bib0013" ref-type="bibr">[3]</xref>. Although the interventions vary between countries, the commonly adopted interventions are social distancing, border closure, school closure, lockdown, travel banning, and public events banning <xref rid="bib0004" ref-type="bibr">[4]</xref>. The effectiveness of interventions across 11 European countries has been investigated in Flaxman, Mishra <xref rid="bib0004" ref-type="bibr">[4]</xref> concluding that the adopted interventions were effective in reducing the rate of transmission of COVID-19 epidemic.</p>
              <p id="para0006">To evaluate the success of controlling COVID-19 epidemic, it is vital to accurately monitor and reveal the data about the number of cases infected with it <xref rid="bib0002" ref-type="bibr">[2]</xref>. Making public the data of confirmed cases of countries in the world allow academics to conduct modeling on data in order to gain useful knowledge about the trend of the disease. Johns Hopkins University's Corona Virus Resource Center <xref rid="bib0005" ref-type="bibr">[5]</xref> has collected and published the data about the COVID-19 confirmed cases which are used by scholars to model the spread of the disease and perform data analysis.</p>
              <p id="para0007">Given the negative impacts of COVID-19, accurately forecasting the number of cases infected with this virus is a vital task to reveal the trend of the disease and thereby to help governments to take preventive measures <xref rid="bib0006" ref-type="bibr">[6]</xref>. Previous researches on COVID-19 time series forecasting have adopted mathematical and computational intelligence models to forecast the number of confirmed cases. In <xref rid="bib0007" ref-type="bibr">[7]</xref> the adaptive neuro-fuzzy inference system (ANFIS) was employed to forecast the number of infected cases in China. In <xref rid="bib0003" ref-type="bibr">[3]</xref> mathematical and computational models such as Logistic, Gompertz, and ANN were applied to model the number of cases in Mexico. Castillo and Melin <xref rid="bib0008" ref-type="bibr">[8]</xref> proposed a new combined approach with fuzzy fractal and fuzzy logic to predict the number of confirmed cases of COVID-19 in 10 countries. Also, in <xref rid="bib0009" ref-type="bibr">[9]</xref>, a new ensemble approach based on ANNs and fuzzy aggregation was proposed and its performance was evaluated on COVID-19 time series of Mexico and its 12 states which showed significant improvement than single ANN. In recent studies [<xref rid="bib0002" ref-type="bibr">2</xref>,<xref rid="bib0010" ref-type="bibr">[10]</xref>, <xref rid="bib0011" ref-type="bibr">[11]</xref>, <xref rid="bib0012" ref-type="bibr">[12]</xref>], deep learning methods such as LSTM and bidirectional LSTM (BiLSTM) have been utilized for COVID-19 time series forecasting . The results indicated that LSTM and its variants have good performance in predicting the COVID-19 time series. In the literature review section, we will give a comprehensive review of studies related to COVID-19 time series forecasting.</p>
              <p id="para0008">Although LSTM was recently applied for COVID-19 infection forecasting, the predictive power of other deep learning methods that are suitable for sequence processing problems has not been explored in COVID-19 forecasting context. Therefore, in this paper, in addition to LSTM <xref rid="bib0013" ref-type="bibr">[13]</xref>, we focus on the other deep learning models including the multi-head attention <xref rid="bib0014" ref-type="bibr">[14]</xref>, and CNNs <xref rid="bib0015" ref-type="bibr">[15]</xref> to forecast the number of cases of COVID-19. Furthermore, the performance of deep learning methods mainly influenced by hyperparameter tuning <xref rid="bib0016" ref-type="bibr">[16]</xref>. There are several hyperparameters that must be specified when employing a deep learning model. The previous studies on COVID-19 forecasting using the LSTM method have not exploited an optimization method to identify the optimal hyperparameters. Most of those studies (e.g. [<xref rid="bib0002" ref-type="bibr">2</xref>,<xref rid="bib0010" ref-type="bibr">10</xref>,<xref rid="bib0012" ref-type="bibr">12</xref>]) have implemented models using hand-tuned hyperparameters. As another contribution, in this study, we utilize the Bayesian Optimization method <xref rid="bib0017" ref-type="bibr">[17]</xref> in order to optimize the hyperparameters of Multi-head attention, LSTM, and CNN. Besides, the design of proposed methods is based on the multiple output approach that allows forecasting of the number of cases for multiple next days.</p>
              <p id="para0009">Overall, the main contributions of this study are as follows:<list list-type="simple" id="celist0002"><list-item id="celistitem0005"><label>1</label><p id="para0010">Adopting the deep learning models to predict the number of daily infected cases with COVID-19.</p></list-item><list-item id="celistitem0006"><label>2</label><p id="para0011">Exploiting the Bayesian Optimization for optimal parameter selection.</p></list-item><list-item id="celistitem0007"><label>3</label><p id="para0012">Adopting a multiple-output modeling approach: The models are designed to be multi-output to predict the next few days. The usual approach to multi-step-ahead prediction is iterated one-step-ahead forecasting in which the forecasting of the <italic>n</italic> next steps performed as a <italic>n</italic> single step-ahead forecasting. Multi-output forecasting is an effective choice for long-horizon forecasting <xref rid="bib0018" ref-type="bibr">[18]</xref>.</p></list-item></list>
</p>
              <p id="para0013">The deep learning models are applied on COVID-19 data of the top 10 countries with the highest number of infections. To evaluate the performance of the proposed models, we perform two sets of experiments. The first set of experiments explores the effectiveness of the proposed models in short-term forecasting and compares their performance with the results of the fuzzy fractal model presented in <xref rid="bib0008" ref-type="bibr">[8]</xref>. The results indicated the deep models achieve better performance than the fuzzy fractal across all countries. Also, the second set of experiments are conducted to investigate the prediction power of the devised models in a wider forecasting window. The results can help governments in long-term decision making to control the pandemic.</p>
              <p id="para0014">The rest of this paper is organized as follows. In <xref rid="sec0002" ref-type="sec">Section 2</xref>, we provide a comprehensive literature review on models and methods proposed for COVID-19 time series forecasting. <xref rid="sec0003" ref-type="sec">Section 3</xref> describes the structure of the proposed models. In <xref rid="sec0007" ref-type="sec">Section 4</xref>, we describe the data and provide the detailed results of the proposed models and compare their performance to the benchmark model. <xref rid="sec0016" ref-type="sec">Section 5</xref> concludes the paper and outlines future work.</p>
            </sec>
            <sec id="sec0002">
              <label>2</label>
              <title>COVID-19 time series forecasting</title>
              <p id="para0015">In this section, we summarize the previous studies in the context of COVID-19 time series prediction. Since the publicly available data of COVID-19 contains daily statistics of the confirmed cases, so it is considered as a time series data and the time series forecasting techniques can be exploited to this data. <xref rid="tbl0001" ref-type="table">Table 1</xref>
illustrates the researches on COVID-19 time series forecasting. The table highlights the modeling techniques, the countries, and the time period of the utilized data in each study. As <xref rid="tbl0001" ref-type="table">Table 1</xref> indicates, various types of methods including mathematical, statistical, machine and deep learning, and fuzzy logic-based techniques have been employed for COVID-19 time series forecasting. From mathematical models, the Gompertz model and logistic models have been used in several studies (i.e. [<xref rid="bib0003" ref-type="bibr">3</xref>,<xref rid="bib0019" ref-type="bibr">19</xref>,<xref rid="bib0020" ref-type="bibr">20</xref>]). Also, from statistical methods, the Auto-Regressive Integrated Moving Average (ARIMA) approach has been employed in some studies such as [<xref rid="bib0002" ref-type="bibr">2</xref>,<xref rid="bib0006" ref-type="bibr">6</xref>,<xref rid="bib0011" ref-type="bibr">11</xref>]. Besides, the machine and deep learning techniques such as ANN and LSTM have exhibited improvements in COVID-19 time series forecasting studies (e.g. [<xref rid="bib0002" ref-type="bibr">2</xref>,<xref rid="bib0010" ref-type="bibr">10</xref>,<xref rid="bib0012" ref-type="bibr">12</xref>]). Also, some methods based on fuzzy logic have been proposed in the literature(e.g. [<xref rid="bib0007" ref-type="bibr">7</xref>,<xref rid="bib0008" ref-type="bibr">8</xref>]). As the literature review indicates, the exploitation of deep learning models has led to improvements in the prediction of COVID-19 cases [<xref rid="bib0002" ref-type="bibr">2</xref>,<xref rid="bib0010" ref-type="bibr">[10]</xref>, <xref rid="bib0011" ref-type="bibr">[11]</xref>, <xref rid="bib0012" ref-type="bibr">[12]</xref>]. Since the COVID-19 time series forecasting task is a kind of sequence processing, other deep learning models can be adopted to forecast the COVID-19 time series <xref rid="bib0012" ref-type="bibr">[12]</xref>. The remarkable characteristic of the machine and deep learning methods is their ability to capture nonlinear patterns <xref rid="bib0021" ref-type="bibr">[21]</xref>, which makes them suitable for modeling complex time series.<table-wrap position="float" id="tbl0001"><label>Table 1</label><caption><p>Summary of studies on COVID-19 infection forecasting.</p></caption><alt-text id="alt0027">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Reference</th><th valign="top">Modeling techniques</th><th valign="top">Country</th><th valign="top">Date</th></tr></thead><tbody><tr><td valign="top"><xref rid="bib0007" ref-type="bibr">[7]</xref></td><td valign="top">ANFIS</td><td valign="top">China</td><td valign="top">21 January, 2020 to 18 February, 2020</td></tr><tr><td valign="top"><xref rid="bib0019" ref-type="bibr">[19]</xref></td><td valign="top">Logistic model, Bertalanffy model and Gompertz model</td><td valign="top">China</td><td valign="top">15 January, 2020 to 4 April 2020</td></tr><tr><td valign="top"><xref rid="bib0020" ref-type="bibr">[20]</xref></td><td valign="top">Gompertz and Logistic</td><td valign="top">China, South Korea, Italy, and Singapore</td><td valign="top">Until 27 March, 2020</td></tr><tr><td valign="top"><xref rid="bib0003" ref-type="bibr">[3]</xref></td><td valign="top">Gompertz, Logistic Artificial Neural Networks</td><td valign="top">Mexico</td><td valign="top">February 27, 2020 to May 8, 2020</td></tr><tr><td align="left" rowspan="3" valign="top"><xref rid="bib0006" ref-type="bibr">[6]</xref></td><td align="left" rowspan="3" valign="top">ANN, ARIMA</td><td align="left" rowspan="3" valign="top">Iran</td><td valign="top">Trainset:19 February, 2020 to 24</td></tr><tr><td valign="top">March, 2020</td></tr><tr><td valign="top">Test set: 25 March, 2020 to 31 March, 2020</td></tr><tr><td valign="top"><xref rid="bib0008" ref-type="bibr">[8]</xref></td><td valign="top">Fuzzy Fractal</td><td valign="top">Ten countries: US, United Kingdom, Turkey, Spain, Mexico, Italy, Iran, Germany, France, and Belgium</td><td valign="top">July 22, 2020 to 7 August, 2020</td></tr><tr><td valign="top"><xref rid="bib0009" ref-type="bibr">[9]</xref></td><td valign="top">An ensemble of neural network models with fuzzy aggregation</td><td valign="top">Mexico and 12 states in Mexico</td><td valign="top">Not available</td></tr><tr><td valign="top"><xref rid="bib0002" ref-type="bibr">[2]</xref></td><td valign="top">ARIMA, nonlinear autoregression neural network (NARNN), and LSTM</td><td valign="top">Denmark, Belgium, Germany, France, United Kingdom, Finland, Switzerland and Turkey</td><td valign="top">Until 3 May, 2020</td></tr><tr><td valign="top"><xref rid="bib0010" ref-type="bibr">[10]</xref></td><td valign="top">Bi-directional LSTM,</td><td align="left" rowspan="3" valign="top">India (32 Indian states)</td><td align="left" rowspan="3" valign="top">March 14, 2020- May 14, 2020</td></tr><tr><td valign="top"/><td valign="top">Stacked LSTM, and</td></tr><tr><td valign="top"/><td valign="top">Convolutional LSTM</td></tr><tr><td valign="top"><xref rid="bib0011" ref-type="bibr">[11]</xref></td><td valign="top">ARIMA, support vector regression (SVR), LSTM, GRU, and Bi-LSTM</td><td valign="top">Ten countries: Brazil, China, Germany, India, Israel, Italy, Russia, Spain, UK, USA</td><td valign="top">Until June 27, 2020</td></tr><tr><td valign="top"><xref rid="bib0012" ref-type="bibr">[12]</xref></td><td valign="top">LSTM</td><td valign="top">Russia, Peru and Iran</td><td valign="top">Until July 7, 2020</td></tr></tbody></table></table-wrap></p>
              <p id="para0016">In the recent years, in addition to the LSTM model, other types of deep learning models such as methods based on the attention mechanisms and convolutional neural networks have demonstrated promising results in many areas of applications such as natural language processing (NLP) <xref rid="bib0022" ref-type="bibr">[22]</xref>, stock market price forecasting <xref rid="bib0021" ref-type="bibr">[21]</xref> and so on. Investigating the literature on COVID-19 forecasting reveals that attention mechanism and the convolutional neural network have not been employed for COVID-19 prediction. Therefore, this study aims to propose deep learning models based on these methods to evaluate their effectiveness in forecasting COVID-19 infected cases.</p>
            </sec>
            <sec id="sec0003">
              <label>3</label>
              <title>The proposed models</title>
              <p id="para0017">In this study, we consider three different deep learning methods to predict the cumulative number of cases. The three proposed methods are the multi-head attention-based method (ATT_BO), CNN-based method (CNN_BO), and LSTM-based method (LSTM_BO). As illustrated in <xref rid="fig0001" ref-type="fig">Fig. 1</xref>
, all proposed methods are combined with the Bayesian optimization algorithm to select the optimal values of hyperparameters. In <xref rid="fig0001" ref-type="fig">Fig. 1</xref>, the Bayesian optimizer <xref rid="bib0023" ref-type="bibr">[23]</xref> accomplishes the task of identifying the optimal hyperparameters. A common alternative to Bayesian optimization is the grid search which is a time-consuming method. The reason for choosing Bayesian optimization are: (1) the superiority of Bayesian optimization over grid search has been proved in previous studies <xref rid="bib0024" ref-type="bibr">[24]</xref> (2) unlike grid search, Bayesian optimization can efficiently find the optimal hyperparameters with fewer iterations <xref rid="bib0025" ref-type="bibr">[25]</xref>. In the following subsections, we describe the structure of the proposed models.<fig id="fig0001"><label>Fig. 1</label><caption><p>The general procedure of the proposed models.</p></caption><alt-text id="alt0001">Fig. 1</alt-text><graphic xlink:href="gr1_lrg"/></fig></p>
              <sec id="sec0004">
                <label>3.1</label>
                <title>ATT_BO</title>
                <p id="para0018">Recently attention mechanisms have been employed successfully in the sequence processing tasks and especially in natural language processing applications [<xref rid="bib0021" ref-type="bibr">21</xref>,<xref rid="bib0022" ref-type="bibr">22</xref>]. The study of Vaswani, Shazeer <xref rid="bib0026" ref-type="bibr">[26]</xref> demonstrated the effectiveness of the attention mechanism for processing sequence data. In this study, we propose a multi-head attention-based model for COVID-19 forecasting using the multi-head attention mechanism developed in <xref rid="bib0026" ref-type="bibr">[26]</xref> (<xref rid="fig0002" ref-type="fig">Fig. 2</xref>
). An attention function takes a query <inline-formula><mml:math id="M1" altimg="si1.svg"><mml:mi>Q</mml:mi></mml:math></inline-formula>and a set of keys and values <inline-formula><mml:math id="M2" altimg="si2.svg"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo linebreak="goodbreak">&gt;</mml:mo></mml:mrow></mml:math></inline-formula> to get the output <inline-formula><mml:math id="M3" altimg="si3.svg"><mml:mi>O</mml:mi></mml:math></inline-formula>. This procedure is often called Scaled Dot-Product Attention. Multi-head attention is a set of multiple heads that jointly learn different representations at every position in the sequence <xref rid="bib0014" ref-type="bibr">[14]</xref>. The proposed attention method (ATT_BO) has three main parts including the multi-head attention layer, the flatten layer, and the fully connected layer. After preprocessing the input data and creating the instances, the multi-head attention layer computes a new representation of the input data which are more informative than the input data. The output of the multi-head attention layer is reshaped using the flatten layer and finally, the outputs are produced using the fully connected layer. The superiority of the proposed model is attributed to the multi-head attention layer which has the ability to capture the most important input features and gives higher weights to them.<fig id="fig0002"><label>Fig. 2</label><caption><p>The proposed attention-based model (ATT_BO).</p></caption><alt-text id="alt0002">Fig. 2</alt-text><graphic xlink:href="gr2_lrg"/></fig></p>
              </sec>
              <sec id="sec0005">
                <label>3.2</label>
                <title>LSTM_BO</title>
                <p id="para0019">Deep learning methods such as RNNs are suitable for sequence processing as they consider the temporal behavior of a given time series <xref rid="bib0021" ref-type="bibr">[21]</xref>. But, the main shortcoming of RNNs is the vanishing/exploding gradient problem that makes their training a difficult task <xref rid="bib0027" ref-type="bibr">[27]</xref>. To overcome this problem, LSTM which is a kind of gated RNNs are often employed <xref rid="bib0028" ref-type="bibr">[28]</xref>. The structure of an LSTM block is depicted in <xref rid="fig0003" ref-type="fig">Fig. 3</xref>
. Each LSTM block consists of a memory cell along with three gates including an input gate <inline-formula><mml:math id="M4" altimg="si4.svg"><mml:mrow><mml:mi>i</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, the forget gate <inline-formula><mml:math id="M5" altimg="si5.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> and the output gate <inline-formula><mml:math id="M6" altimg="si6.svg"><mml:mrow><mml:mi>o</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> which regulate the flow of information to its cell state <inline-formula><mml:math id="M7" altimg="si7.svg"><mml:mrow><mml:mi>c</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>:<fig id="fig0003"><label>Fig. 3</label><caption><p>The structure of the LSTM <xref rid="bib0027" ref-type="bibr">[27]</xref>.</p></caption><alt-text id="alt0003">Fig. 3</alt-text><graphic xlink:href="gr3_lrg"/></fig></p>
                <p id="para0020">Each of the three gates accomplishes a different operation <xref rid="bib0029" ref-type="bibr">[29]</xref>:<list list-type="simple" id="celist0003"><list-item id="celistitem0008"><label>•</label><p id="para0021">The forget gate determines which information is discarded.</p></list-item><list-item id="celistitem0009"><label>•</label><p id="para0022">The input gate decides which information is input to the cell state.</p></list-item><list-item id="celistitem0010"><label>•</label><p id="para0023">The output gate regulates the outgoing information of the LSTM cell.</p></list-item></list>
</p>
                <p id="para0024">The architecture of the proposed LSTM-based (LSTM_BO) is articulated in <xref rid="fig0004" ref-type="fig">Fig. 4</xref>
. This method consists of three main parts, including the LSTM layer, the flatten layer, and the fully connected layer. The input time series is firstly preprocessed and then is fed into the LSTM layer, which learns a new representation of data considering the dependency among data. Afterward, the output of the LSTM layer is reshaped into a suitable format using a flatten layer and then is fed into a fully connected layer. Finally, the fully connected layer produces multiple outputs.<fig id="fig0004"><label>Fig. 4</label><caption><p>The Proposed LSTM-based model.</p></caption><alt-text id="alt0004">Fig. 4</alt-text><graphic xlink:href="gr4_lrg"/></fig></p>
              </sec>
              <sec id="sec0006">
                <label>3.3</label>
                <title>Convolutional model</title>
                <p id="para0025">CNNs are quite successful in processing machine vision problems <xref rid="bib0015" ref-type="bibr">[15]</xref>. In this study, we implement CNN for COVID-19 time series forecasting. The convolutional layers in CNNs take input data and apply convolution operation on data using convolution kernels to extract new features. The convolution kernel is a small window that slides over the input data and performs convolutional operations to extract new features <xref rid="bib0030" ref-type="bibr">[30]</xref>. The derived features using the convolution operation are usually more discriminative than the raw input data, therefore, improving the forecasting. The architecture of the proposed CNN-based model (CNN_BO) is described in <xref rid="fig0005" ref-type="fig">Fig. 5</xref>
. CNN_BO contains three main parts: the convolution layer, the flatten layer, and the fully connected layer. After preprocessing of the input data, features are extracted from the input time series using the convolution layer, and then the flatten layer reshapes data into a format that can be used by the fully connected layer and the fully connected layer generates the multiple outputs.<fig id="fig0005"><label>Fig. 5</label><caption><p>The proposed CNN-based model.</p></caption><alt-text id="alt0005">Fig. 5</alt-text><graphic xlink:href="gr5_lrg"/></fig></p>
              </sec>
            </sec>
            <sec id="sec0007">
              <label>4</label>
              <title>Empirical study and analysis</title>
              <sec id="sec0008">
                <label>4.1</label>
                <title>Data</title>
                <p id="para0026">The data utilized in this study was obtained from the Humanitarian Data Exchange (HDX) <xref rid="bib0031" ref-type="bibr">[31]</xref>. In this study, we perform two sets of experiments using two different datasets, including Dataset 1 and Dataset 2 that are described in <xref rid="tbl0002" ref-type="table">Table 2</xref>
. The first set of experiments examine the usefulness of the proposed deep learning model in a shorter 10 days window. To perform the first set of experiments, we utilize Dataset 1 which contains the data used in <xref rid="bib0008" ref-type="bibr">[8]</xref>. To compare the results of the proposed methods, we choose the fuzzy fractal method proposed by Castillo and Melin <xref rid="bib0008" ref-type="bibr">[8]</xref> as the benchmark.<table-wrap position="float" id="tbl0002"><label>Table 2</label><caption><p>The description of data.</p></caption><alt-text id="alt0028">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Dataset</th><th valign="top">Countries</th><th valign="top">Time period</th></tr></thead><tbody><tr><td valign="top">Dataset 1</td><td valign="top">US, United Kingdom, Turkey, Spain, Mexico, Italy, Iran, Germany, France, Belgium</td><td valign="top">January 20, 2020–August 1, 2020</td></tr><tr><td valign="top">Dataset 2</td><td valign="top">US, Brazil, India, Russia, South Africa, Mexico, Peru, Chile, Colombia, Iran</td><td valign="top">January 20, 2020- August 3, 2020</td></tr></tbody></table></table-wrap></p>
                <p id="para0027">Also, to evaluate the performance of the three proposed models in long-horizon forecasting, we use Dataset 2 that includes the updated data of COVID-19 cases until 3 August. Similar to Dataset 1, Dataset 2 contains data for ten countries with the highest number of cases. In selecting the top ten countries of Dataset 2, we firstly aggregate the data of all cities for each country.</p>
              </sec>
              <sec id="sec0009">
                <label>4.2</label>
                <title>Evaluation measures</title>
                <p id="para0028">To evaluate the effectiveness of the proposed methods on COVID-19 time series forecasting, we employ three primary measures including symmetric mean absolute percentage error (SMAPE), mean absolute percentage error (MAPE), and root mean square error (RMSE), as well as the following aggregate measures, which are based on the primary measures including mean of SMAPEs (Mean SMAPE), mean of the SMAPE ranks (Rank SMAPE), mean of MAPEs (Mean MAPE), mean of the MAPE ranks(Rank MAPE), mean of RMSEs (Mean RMSE) and the mean of RMSE ranks (Rank RMSE).</p>
                <p id="para0029">The definitions of SMAPE, MAPE, and RMSE are given by <xref rid="eqn0001" ref-type="disp-formula">Eqs. (1)</xref>–<xref rid="eqn0003" ref-type="disp-formula">(3)</xref> respectively:<disp-formula id="eqn0001"><label>(1)</label><mml:math id="M8" altimg="si8.svg"><mml:mrow><mml:mi>S</mml:mi><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mfrac><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mfrac><mml:mo linebreak="goodbreak">×</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></disp-formula>
<disp-formula id="eqn0002"><label>(2)</label><mml:math id="M9" altimg="si9.svg"><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mfrac><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mfrac><mml:mo linebreak="goodbreak">×</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></disp-formula>
<disp-formula id="eqn0003"><label>(3)</label><mml:math id="M10" altimg="si10.svg"><mml:mrow><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:math></disp-formula> where <inline-formula><mml:math id="M11" altimg="si11.svg"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M12" altimg="si12.svg"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> are the predicted and actual value at time point <inline-formula><mml:math id="M13" altimg="si13.svg"><mml:mi>t</mml:mi></mml:math></inline-formula>.</p>
              </sec>
              <sec id="sec0010">
                <label>4.3</label>
                <title>Preprocessing of data</title>
                <p id="para0031">In this study, as the architectures of the three proposed models indicate, we design the models following the multi-output forecasting strategy, which allows forecasting of multiple time steps rather than a single time step that is applied in the single-output strategy.</p>
                <p id="para0032">The proposed models require the input to be instances (data objects) of input-output format. So, the input time series must be converted into the input-output format. Therefore, considering the input size, L (Lag), which refers to the length of the input window, and the output size, O, which denotes the length of the output window, subsequences of length <inline-formula><mml:math id="M14" altimg="si14.svg"><mml:mrow><mml:mi>L</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi>O</mml:mi></mml:mrow></mml:math></inline-formula> are extracted from the series. The first <inline-formula><mml:math id="M15" altimg="si15.svg"><mml:mi>L</mml:mi></mml:math></inline-formula> points of a sequence are considered as the input, and the last O points are considered as the output values. For example, as depicted in <xref rid="fig0006" ref-type="fig">Fig. 6</xref>
, the process of the construction of the instances iteratively generates the instances using the input=3 (L=3) and the output size O=2.<fig id="fig0006"><label>Fig. 6</label><caption><p>The Process of instance generation.</p></caption><alt-text id="alt0006">Fig. 6</alt-text><graphic xlink:href="gr6_lrg"/></fig></p>
              </sec>
              <sec id="sec0011">
                <label>4.4</label>
                <title>Experiment setup</title>
                <p id="para0033">In this study, we combine the proposed methods with the Bayesian optimization algorithm to identify the optimal hyperparameter value. The proposed methods the proposed method are implemented using Keras library in python <xref rid="bib0032" ref-type="bibr">[32]</xref>. To prevent all methods from overfitting and improving their generalization to new data, we use early stopping <xref rid="bib0033" ref-type="bibr">[33]</xref>. To employ early stopping, we set the epoch limit to 500.</p>
                <sec id="sec0012">
                  <label>4.4.1</label>
                  <title>Hyperparameter selection</title>
                  <p id="para0034">To utilize the Bayesian optimizer, the range of the hyperparameters should be specified. One important hyperparameter which significantly impacts time series forecasting accuracy is the size of the input window (Lag). The range of Lag is set to (10, 11, 12, 13, 14,15) for all proposed methods. <xref rid="tbl0003" ref-type="table">Table 3</xref>
provides the range of hyperparameters utilized throughout the experiments. As the fully connected and output layers have been incorporated after the main layer of the proposed methods; for all deep learning models, we set the range of hyperparameters corresponding to these layers identical. To limit the search space of the Bayesian optimization algorithm, for these layers, we include their activation functions in the hyperparameter selection process. For both layers, “ReLU” and “Linear” activation functions <xref rid="bib0015" ref-type="bibr">[15]</xref> are utilized. Also, the range of learning rate parameter for all models is set to (0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05).<table-wrap position="float" id="tbl0003"><label>Table 3</label><caption><p>The range of hyperparameters used in the Bayesian optimization process.</p></caption><alt-text id="alt0029">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Model</th><th valign="top">Hyperparameter range</th></tr></thead><tbody><tr><td valign="top">ATT_BO</td><td valign="top">Activation function: (ReLU, Linear)</td></tr><tr><td valign="top">LSTM_BO</td><td valign="top">Activation function: (ReLU, Linear, Tanh)</td></tr><tr><td valign="top"/><td valign="top">Dropout rate: (0.0,0.1,0.2,0.3,0.4,0.50)</td></tr><tr><td valign="top"/><td valign="top">Number of neurons: (32,64,128,256)</td></tr><tr><td valign="top">CNN_BO</td><td valign="top">Size of kernel: (2,3,4,5,6)</td></tr><tr><td valign="top"/><td valign="top">Stride: (1,2)</td></tr><tr><td valign="top"/><td valign="top">Number of neurons: (32,64,128,256)</td></tr></tbody></table></table-wrap></p>
                </sec>
              </sec>
              <sec id="sec0013">
                <label>4.5</label>
                <title>Results and analysis</title>
                <p id="para0035">In this section, we give the results of the experiments conducted based on the two datasets. In the analysis of the first set of experiments, we consider the results of the fuzzy fractal model proposed in <xref rid="bib0008" ref-type="bibr">[8]</xref>. The main reason behind choosing the fuzzy fractal method as the benchmark is that this method was comprehensively evaluated in the recent study conducted by Castillo and Melin <xref rid="bib0008" ref-type="bibr">[8]</xref> using Dataset 1. Besides, on the second set of experiments, we explore the performance of our developed models on a wider forecasting window by adopting a multi-output forecasting strategy.</p>
                <sec id="sec0014">
                  <label>4.5.1</label>
                  <title>Results of the first set of experiments on Dataset 1</title>
                  <p id="para0036">To make the forecasting comparable with the results of the fuzzy fractal model <xref rid="bib0008" ref-type="bibr">[8]</xref>, for Dataset 1, we consider the last 10 days as the test points .The results of the proposed models as well as the benchmark model on Dataset 1 are illustrated in <xref rid="tbl0004" ref-type="table">Table 4</xref>, <xref rid="tbl0005" ref-type="table">Table 5</xref>, <xref rid="tbl0006" ref-type="table">Table 6</xref>
. As the results indicate, in terms of SMAPE (<xref rid="tbl0004" ref-type="table">Table 4</xref>), ATT_BO achieves better performance compared to the Fuzzy fractal in 6 countries out of 10 countries such as the US, UK, Mexico, Italy, Iran, and Belgium. Furthermore, CNN_BO obtains better performance in terms of SMAPE in comparison with the Fuzzy fractal method in 6 countries including the US, UK, Mexico, Italy, Iran, and Belgium. Also, the results of LSTM_BO indicate that it has similar performance to the Fuzzy fractal method. While LSTM_BO performs better than and fuzzy fractal for the US, UK, Mexico, Italy, and Iran, fuzzy fractal achieves a lower SMAPE than LSTM_BO for the remaining five countries. Overall, the results indicate that ATT_BO and CNN_BO achieve better results compared to the fuzzy fractal model. The Mean SMAPE and Rank SMAPE values over the ten countries are given in <xref rid="tbl0007" ref-type="table">Table 7</xref>
. The Mean SMAPEs of the three deep learning models are significantly lower than the fuzzy fractal's one (Mean SMAPE=0.7052) (as seen in <xref rid="tbl0007" ref-type="table">Table 7</xref>). Furthermore, the ATT_BO and CNN_BO models outperform the fuzzy fractal model in terms of Rank SMAPE.<table-wrap position="float" id="tbl0004"><label>Table 4</label><caption><p>The performance of the proposed methods in terms of SMAPE on Dataset 1.</p></caption><alt-text id="alt0030">Table 4</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Country</th><th valign="top">ATT_BO</th><th valign="top">LSTM_BO</th><th valign="top">CNN_BO</th><th valign="top">Fuzzy fractal</th></tr></thead><tbody><tr><td valign="top">US</td><td valign="top">0.4082</td><td valign="top">0.5325</td><td valign="top">0.2776</td><td valign="top">1.0755</td></tr><tr><td valign="top">UK</td><td valign="top">0.0464</td><td valign="top">0.056</td><td valign="top">0.0504</td><td valign="top">1.0147</td></tr><tr><td valign="top">Turkey</td><td valign="top">0.0412</td><td valign="top">0.0475</td><td valign="top">0.0984</td><td valign="top">0.0085</td></tr><tr><td valign="top">Spain</td><td valign="top">0.6536</td><td valign="top">0.62</td><td valign="top">0.6119</td><td valign="top">0.3572</td></tr><tr><td valign="top">Mexico</td><td valign="top">0.5171</td><td valign="top">0.5668</td><td valign="top">0.5684</td><td valign="top">0.693</td></tr><tr><td valign="top">Italy</td><td valign="top">0.0438</td><td valign="top">0.1117</td><td valign="top">0.0626</td><td valign="top">1.5343</td></tr><tr><td valign="top">Iran</td><td valign="top">0.0685</td><td valign="top">0.1313</td><td valign="top">0.0577</td><td valign="top">1.5343</td></tr><tr><td valign="top">Germany</td><td valign="top">0.1562</td><td valign="top">0.2321</td><td valign="top">0.1823</td><td valign="top">0.1174</td></tr><tr><td valign="top">France</td><td valign="top">0.3956</td><td valign="top">0.3169</td><td valign="top">0.313</td><td valign="top">0.2894</td></tr><tr><td valign="top">Belgium</td><td valign="top">0.2754</td><td valign="top">0.4366</td><td valign="top">0.2519</td><td valign="top">0.4281</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl0005"><label>Table 5</label><caption><p>The performance of the proposed methods in terms of MAPE on Dataset 1.</p></caption><alt-text id="alt0031">Table 5</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Country</th><th valign="top">ATT_BO</th><th valign="top">LSTM_BO</th><th valign="top">CNN_BO</th><th valign="top">Fuzzy fractal</th></tr></thead><tbody><tr><td valign="top">US</td><td valign="top">0.317</td><td valign="top">0.5314</td><td valign="top">0.276</td><td valign="top">1.0691</td></tr><tr><td valign="top">UK</td><td valign="top">0.0402</td><td valign="top">0.0542</td><td valign="top">0.0456</td><td valign="top">1.0214</td></tr><tr><td valign="top">Turkey</td><td valign="top">0.0412</td><td valign="top">0.0182</td><td valign="top">0.0984</td><td valign="top">0.0085</td></tr><tr><td valign="top">Spain</td><td valign="top">0.4977</td><td valign="top">0.5947</td><td valign="top">0.6025</td><td valign="top">0.3581</td></tr><tr><td valign="top">Mexico</td><td valign="top">0.4389</td><td valign="top">0.5355</td><td valign="top">0.5187</td><td valign="top">0.6901</td></tr><tr><td valign="top">Italy</td><td valign="top">0.0409</td><td valign="top">0.1114</td><td valign="top">0.0624</td><td valign="top">0.0551</td></tr><tr><td valign="top">Iran</td><td valign="top">0.0538</td><td valign="top">0.1269</td><td valign="top">0.0428</td><td valign="top">1.5196</td></tr><tr><td valign="top">Germany</td><td valign="top">0.1461</td><td valign="top">0.2128</td><td valign="top">0.1804</td><td valign="top">0.1173</td></tr><tr><td valign="top">France</td><td valign="top">0.3208</td><td valign="top">0.3033</td><td valign="top">0.3088</td><td valign="top">0.2893</td></tr><tr><td valign="top">Belgium</td><td valign="top">0.2609</td><td valign="top">0.39432</td><td valign="top">0.2491</td><td valign="top">0.4287</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl0006"><label>Table 6</label><caption><p>The performance of the proposed methods in terms of RMSE on Dataset 1.</p></caption><alt-text id="alt0032">Table 6</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Country</th><th valign="top">ATT_BO</th><th valign="top">LSTM_BO</th><th valign="top">CNN_BO</th><th valign="top">Fuzzy fractal</th></tr></thead><tbody><tr><td valign="top">US</td><td valign="top">20023.27</td><td valign="top">26415.24</td><td valign="top">15181.05</td><td valign="top">27609.68</td></tr><tr><td valign="top">UK</td><td valign="top">164.8403</td><td valign="top">193.7</td><td valign="top">180.567</td><td valign="top">3494.91</td></tr><tr><td valign="top">Turkey</td><td valign="top">99.43</td><td valign="top">115.42</td><td valign="top">240.66</td><td valign="top">27.303</td></tr><tr><td valign="top">Spain</td><td valign="top">2320.7</td><td valign="top">2273.54</td><td valign="top">2269.22</td><td valign="top">1398.52</td></tr><tr><td valign="top">Mexico</td><td valign="top">2511.54</td><td valign="top">2825.99</td><td valign="top">2781.7</td><td valign="top">3069.18</td></tr><tr><td valign="top">Italy</td><td valign="top">126.71</td><td valign="top">298.89</td><td valign="top">173.7</td><td valign="top">168.08</td></tr><tr><td valign="top">Iran</td><td valign="top">243.015</td><td valign="top">417.944</td><td valign="top">198.11</td><td valign="top">5135.7</td></tr><tr><td valign="top">Germany</td><td valign="top">395.75</td><td valign="top">537.7</td><td valign="top">436.9</td><td valign="top">333.42</td></tr><tr><td valign="top">France</td><td valign="top">1035.42</td><td valign="top">910.24</td><td valign="top">894.56</td><td valign="top">782.001</td></tr><tr><td valign="top">Belgium</td><td valign="top">230.52</td><td valign="top">369.39</td><td valign="top">208.2</td><td valign="top">312.61</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl0007"><label>Table 7</label><caption><p>The performance of all methods in terms of Mean SMAPE, Mean MAPE, Mean RMSE, Rank SMAPE, Rank MAPE, rank RMSE (the best results are marked bold) on Dataset 1.</p></caption><alt-text id="alt0033">Table 7</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Method</th><th valign="top">ATT_BO</th><th valign="top">LSTM_BO</th><th valign="top">CNN_BO</th><th valign="top">Fuzzy fractal</th></tr></thead><tbody><tr><td valign="top">Mean SMAPE</td><td valign="top">0.2606</td><td valign="top">0.3051</td><td valign="top">0.2474</td><td valign="top">0.7052</td></tr><tr><td valign="top">Mean MAPE</td><td valign="top">0.2157</td><td valign="top">0.2883</td><td valign="top">0.2385</td><td valign="top">0.5557</td></tr><tr><td valign="top">Mean RMSE</td><td valign="top">2715.12</td><td valign="top">3435.80</td><td valign="top">2256.47</td><td valign="top">4233.14</td></tr><tr><td valign="top">Rank SMAPE</td><td valign="top">2.1</td><td valign="top">3</td><td valign="top">2.2</td><td valign="top">2.7</td></tr><tr><td valign="top">Rank MAPE</td><td valign="top">2</td><td valign="top">3</td><td valign="top">2.4</td><td valign="top">2.6</td></tr><tr><td valign="top">Rank RMSE</td><td valign="top">2</td><td valign="top">3.3</td><td valign="top">2.1</td><td valign="top">2.6</td></tr></tbody></table></table-wrap></p>
                  <p id="para0037"><xref rid="tbl0005" ref-type="table">Table 5</xref> illustrates the results of all models in terms of MAPE. The best result for each country is denoted using the boldface. Deep learning models achieve the best results for 6 countries compared to the fuzzy fractal model that obtains the best results in 4 countries. In terms of MAPE, ATT_BO model outperforms the fuzzy fractal model in 6 countries. Compared to the fuzzy fractal model, CNN and LSTM archives better results in 5 and 4 countries, respectively. Also, in terms of Mean MAPE as seen in <xref rid="tbl0007" ref-type="table">Table 7</xref>, all deep learning methods outperform the fuzzy fractal method. Besides, ATT_BO reaches the first Rank MAPE.</p>
                  <p id="para0038">Looking at the results in terms of RMSE, as illustrated in <xref rid="tbl0005" ref-type="table">Table 5</xref> it is seen that the ATT_BO model performs better than the fuzzy fractal method in 6 cases out of 10 countries including US, UK, Mexico, Italy, Iran, and Belgium. Also, CNN_BO model has similar performance to the fuzzy fractal as both methods give better results in 5 countries. Furthermore, LSTM_BO reaches a lower RMSE in 4 countries compared to the fuzzy fractal. The Mean RMSE and Rank RMSE measures are provided in <xref rid="tbl0007" ref-type="table">Table 7</xref>. We see that all deep learning models outperform the fuzzy fractal model in terms of Mean RMSE. Besides, the ATT_BO obtains the first Rank RMSE.</p>
                  <p id="para0039">The overall results provided in <xref rid="tbl0007" ref-type="table">Table 7</xref> indicate that all proposed models perform significantly better in terms of Mean SMAPE, Mean MAPE, and Mean RMSE. The results demonstrate the performance of deep learning methods for COVID-19 forecasting. The better forecasting performance of the deep learning methods mainly attributed to their inherent characteristics in handling sequence data.</p>
                  <p id="para0040">To illustrate the performance of methods, in <xref rid="fig0007" ref-type="fig">Figs. 7</xref>
–<xref rid="fig0016" ref-type="fig">16</xref>, we also visualize the forecasted and actual cases for each country with the best models achieved from the deep learning models as well as the fuzzy fractal method. In all of the following figures, the black line indicates the real values, the green line corresponds to the forecasted cases using the best deep learning model, and the red line plot the forecasted cases with the fuzzy fractal.<fig id="fig0007"><label>Fig. 7</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for US.</p></caption><alt-text id="alt0007">Fig. 7</alt-text><graphic xlink:href="gr7_lrg"/></fig></p>
                  <p id="para0041"><xref rid="fig0007" ref-type="fig">Fig. 7</xref> shows the forecast of confirmed cases for US, where the difference between the deep learning model (the green line) and the fuzzy fractal method (the red line) is clear. The forecasted cases with the deep learning model are very close to the real values. <xref rid="fig0008" ref-type="fig">Fig. 8</xref>
shows the forecasted values for UK, where the difference between the deep learning model and the benchmarking model is apparent. <xref rid="fig0009" ref-type="fig">Fig. 9</xref>
illustrates similarly the predicted values for Turkey, where the forecasted values using both the deep learning model and the benchmarking model are very close to the real values. <xref rid="fig0010" ref-type="fig">Fig. 10</xref>
plots the forecasted values for Spain, where the benchmark model slightly predicts better than the deep learning model. <xref rid="fig0011" ref-type="fig">Figs. 11</xref>
–<xref rid="fig0013" ref-type="fig">13</xref>
show the predicted values for Mexico, Iran, and Italy respectively, where the forecasted values using the deep learning method are very close to the actual ones. The plots for Germany and France are illustrated in <xref rid="fig0014" ref-type="fig">Figs. 14</xref>
and <xref rid="fig0015" ref-type="fig">15</xref>
, respectively, which indicate the fuzzy fractal model predicted slightly better than the deep learning model. <xref rid="fig0016" ref-type="fig">Fig. 16</xref>
illustrates the forecasted values for Belgium, where our proposed method predicts values as close as the actual value.<fig id="fig0008"><label>Fig. 8</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for UK.</p></caption><alt-text id="alt0008">Fig. 8</alt-text><graphic xlink:href="gr8_lrg"/></fig><fig id="fig0009"><label>Fig. 9</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for Turkey.</p></caption><alt-text id="alt0009">Fig. 9</alt-text><graphic xlink:href="gr9_lrg"/></fig><fig id="fig0010"><label>Fig. 10</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for Spain.</p></caption><alt-text id="alt0010">Fig. 10</alt-text><graphic xlink:href="gr10_lrg"/></fig><fig id="fig0011"><label>Fig. 11</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for Mexico.</p></caption><alt-text id="alt0011">Fig. 11</alt-text><graphic xlink:href="gr11_lrg"/></fig><fig id="fig0012"><label>Fig. 12</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for Italy.</p></caption><alt-text id="alt0012">Fig. 12</alt-text><graphic xlink:href="gr12_lrg"/></fig><fig id="fig0013"><label>Fig. 13</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for Iran.</p></caption><alt-text id="alt0013">Fig. 13</alt-text><graphic xlink:href="gr13_lrg"/></fig><fig id="fig0014"><label>Fig. 14</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for Germany.</p></caption><alt-text id="alt0014">Fig. 14</alt-text><graphic xlink:href="gr14_lrg"/></fig><fig id="fig0015"><label>Fig. 15</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for France.</p></caption><alt-text id="alt0015">Fig. 15</alt-text><graphic xlink:href="gr15_lrg"/></fig><fig id="fig0016"><label>Fig. 16</label><caption><p>The actual and predicted number of cases for 10 days (22 Jul to 1 August) for Belguim.</p></caption><alt-text id="alt0016">Fig. 16</alt-text><graphic xlink:href="gr16_lrg"/></fig></p>
                  <p id="para0042">Analyzing the figures indicates that for the majority of countries, the best deep learning model archives better performance than the fuzzy fractal model. For all countries, it is apparent that the fuzzy fractal model fits a linear model to predict the confirmed cases. Analyzing the figures indicates that for the majority of countries, the best deep learning model archives better performance than the fuzzy fractal model. For all countries, it is apparent that the fuzzy fractal model fits a linear model to predict the confirmed cases. Also, as the figures display, the deep learning model was able to capture both linear and nonlinear patterns, which enhances its accuracy. The results confirm the suitability of the proposed model for COVID-19 time series forecasting.</p>
                </sec>
                <sec id="sec0015">
                  <label>4.5.2</label>
                  <title>Results of the second set of experiments on Dataset 2</title>
                  <p id="para0043">After validating the effectiveness of the deep learning-based model on a shorter-window forecasting task, in this section, we perform the second set of experiments on Dataset 2 to examine the performance of the proposed models in longer-horizon forecasting. Longer-horizon forecasting reveals the trend of the pandemic in the long term and thus help governments to make appropriate decisions. To conduct experiments on Dataset 2, we adopt the hold-out method and split each COVID-19 time series into two parts: train set (80%) and test set (out-of-sample (20%)). The model building process is accomplished on the train set. The test set is used for evaluating the obtained models throughout the experiments. Also, for each time series, 20% of the train set is considered as the validation set data that is used in the hyperparameter identification process. As mentioned before, we adopt a multi-output forecasting strategy, so we set the output size=7. Therefore, the proposed model can forecast the number of cases for 7 next days.</p>
                  <p id="para0044">The results of experiments in terms of SMAPE are provided in <xref rid="tbl0008" ref-type="table">Table 8</xref>
. For Dataset 2, ATT_BO achieves the best SMAPE for US, South Africa, and Chile. Also, LSTM_BO exhibits a significant performance and obtains the best SMAPE for 6 countries including India, Russia, Mexico, Peru, Columbia and Iran. CNN performs worse among these three methods and obtains the best performance only for Brazil.<table-wrap position="float" id="tbl0008"><label>Table 8</label><caption><p>The performance of the proposed methods in terms of SMAPE on Dataset 2 (The best results are marked bold).</p></caption><alt-text id="alt0034">Table 8</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Country</th><th valign="top">ATT_BO</th><th valign="top">LSTM_BO</th><th valign="top">CNN_BO</th></tr></thead><tbody><tr><td valign="top">US</td><td valign="top"><bold>0.6914</bold></td><td valign="top">0.8117</td><td valign="top">0.9946</td></tr><tr><td valign="top">Brazil</td><td valign="top">4.1811</td><td valign="top">3.4828</td><td valign="top"><bold>3.0081</bold></td></tr><tr><td valign="top">India</td><td valign="top">0.8735</td><td valign="top"><bold>0.7711</bold></td><td valign="top">1.1117</td></tr><tr><td valign="top">Russia</td><td valign="top">0.7723</td><td valign="top"><bold>0.4747</bold></td><td valign="top">1.7461</td></tr><tr><td valign="top">South Africa</td><td valign="top"><bold>8.0334</bold></td><td valign="top">8.1889</td><td valign="top">9.4018</td></tr><tr><td valign="top">Mexico</td><td valign="top">1.1996</td><td valign="top"><bold>1.1139</bold></td><td valign="top">1.5866</td></tr><tr><td valign="top">Peru</td><td valign="top">4.3358</td><td valign="top"><bold>3.5406</bold></td><td valign="top">3.5637</td></tr><tr><td valign="top">Chile</td><td valign="top"><bold>1.87</bold></td><td valign="top">2.4096</td><td valign="top">3.2176</td></tr><tr><td valign="top">Colombia</td><td valign="top">4.8034</td><td valign="top"><bold>4.233</bold></td><td valign="top">4.2347</td></tr><tr><td valign="top">Iran</td><td valign="top">1.0407</td><td valign="top"><bold>0.8953</bold></td><td valign="top">1.4831</td></tr></tbody></table></table-wrap></p>
                  <p id="para0045"><xref rid="tbl0009" ref-type="table">Table 9</xref>
shows the results of experiments with respect to the MAPE measure. Similar to the results given in <xref rid="tbl0008" ref-type="table">Table 8</xref>, LSTM_BO, ATT_BO, and CNN_BO achieve the best performance in 6, 3, and 1 countries, respectively.<table-wrap position="float" id="tbl0009"><label>Table 9</label><caption><p>The performance of the proposed methods in terms of MAPE on Dataset 2 (the best results are marked bold).</p></caption><alt-text id="alt0035">Table 9</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Country</th><th valign="top">ATT_BO</th><th valign="top">LSTM_BO</th><th valign="top">CNN_BO</th></tr></thead><tbody><tr><td valign="top">US</td><td valign="top"><bold>0.6901</bold></td><td valign="top">0.8105</td><td valign="top">0.9883</td></tr><tr><td valign="top">Brazil</td><td valign="top">4.2974</td><td valign="top">3.5924</td><td valign="top"><bold>3.0692</bold></td></tr><tr><td valign="top">India</td><td valign="top">0.878</td><td valign="top"><bold>0.7748</bold></td><td valign="top">1.08</td></tr><tr><td valign="top">Russia</td><td valign="top">0.7681</td><td valign="top"><bold>0.4732</bold></td><td valign="top">1.7688</td></tr><tr><td valign="top">South Africa</td><td valign="top"><bold>8.6522</bold></td><td valign="top">8.8127</td><td valign="top">10.2508</td></tr><tr><td valign="top">Mexico</td><td valign="top">1.1919</td><td valign="top"><bold>1.1055</bold></td><td valign="top">1.5692</td></tr><tr><td valign="top">Peru</td><td valign="top">4.21</td><td valign="top"><bold>3.4325</bold></td><td valign="top">3.4734</td></tr><tr><td valign="top">Chile</td><td valign="top"><bold>1.8376</bold></td><td valign="top">2.3693</td><td valign="top">3.147</td></tr><tr><td valign="top">Colombia</td><td valign="top">4.9383</td><td valign="top"><bold>4.3337</bold></td><td valign="top">4.3363</td></tr><tr><td valign="top">Iran</td><td valign="top">1.0485</td><td valign="top"><bold>0.9017</bold></td><td valign="top">1.4977</td></tr></tbody></table></table-wrap></p>
                  <p id="para0046">The results of models in terms of RMSE are given in <xref rid="tbl0010" ref-type="table">Table 10</xref>
. We observe that regarding RMSE, LSTM_BO achieves the lowest RMSE in 5 cases. Also, the second-best performing method is the ATT_BO, which obtains the lowest RMSE in 3 countries. CNN_BO obtains the best forecasting only for Brazil.<table-wrap position="float" id="tbl0010"><label>Table 10</label><caption><p>The performance of the proposed methods in terms of RMSE on Dataset 2 (the best results are marked bold).</p></caption><alt-text id="alt0036">Table 10</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Country</th><th valign="top">ATT_BO</th><th valign="top">LSTM_BO</th><th valign="top">CNN_BO</th></tr></thead><tbody><tr><td valign="top">US</td><td valign="top"><bold>31661.82</bold></td><td valign="top">36223.39</td><td valign="top">43230.38</td></tr><tr><td valign="top">Brazil</td><td valign="top">110229.9</td><td valign="top">98053.65</td><td valign="top"><bold>75718.32</bold></td></tr><tr><td valign="top">India</td><td valign="top">13834.01</td><td valign="top"><bold>13194</bold></td><td valign="top">16290.89</td></tr><tr><td valign="top">Russia</td><td valign="top">7054.7</td><td valign="top"><bold>4275.18</bold></td><td valign="top">15662.22</td></tr><tr><td valign="top">South Africa</td><td valign="top"><bold>55269.28</bold></td><td valign="top">55611.48</td><td valign="top">65740.78</td></tr><tr><td valign="top">Mexico</td><td valign="top">5360.93</td><td valign="top"><bold>4935.58</bold></td><td valign="top">7080.47</td></tr><tr><td valign="top">Peru</td><td valign="top">20003.09</td><td valign="top">17376.54</td><td valign="top"><bold>16049.06</bold></td></tr><tr><td valign="top">Chile</td><td valign="top"><bold>7438.9</bold></td><td valign="top">9388.29</td><td valign="top">13168.58</td></tr><tr><td valign="top">Colombia</td><td valign="top">12356.65</td><td valign="top"><bold>10721.77</bold></td><td valign="top">10936.55</td></tr><tr><td valign="top">Iran</td><td valign="top">3279.91</td><td valign="top"><bold>3143.49</bold></td><td valign="top">4802.84</td></tr></tbody></table></table-wrap></p>
                  <p id="para0047">To gain a more understanding of the overall performance of the proposed methods and their rank across all countries, we calculate Mean SMAPE, Mean MAPE, Mean RMSE, Rank SMAPE, Rank MAPE, Rank RMSE over all 10 countries data (as seen in <xref rid="tbl0011" ref-type="table">Table 11</xref>
). The results demonstrate that the LSTM_BO method outperforms ATT_BO and CNN_BO in terms of all overall performance measures and is a suitable choice for a longer horizon forecasting task.<table-wrap position="float" id="tbl0011"><label>Table 11</label><caption><p>The performance of all methods in terms of Mean SMAPE, Mean MAPE, Mean RMSE, Rank SMAPE, Rank MAPE, rank RMSE on Dataset 2 (the best results are marked bold).</p></caption><alt-text id="alt0037">Table 11</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Method</th><th valign="top">ATT_BO</th><th valign="top">LSTM_BO</th><th valign="top">CNN_BO</th></tr></thead><tbody><tr><td valign="top">Mean SMAPE</td><td valign="top">2.7801</td><td valign="top"><bold>2.5922</bold></td><td valign="top">3.0348</td></tr><tr><td valign="top">Mean MAPE</td><td valign="top">2.8512</td><td valign="top"><bold>2.6606</bold></td><td valign="top">3.1181</td></tr><tr><td valign="top">Mean RMSE</td><td valign="top">26648.92</td><td valign="top"><bold>25292.337</bold></td><td valign="top">26868.01</td></tr><tr><td valign="top">Rank SMAPE</td><td valign="top">2</td><td valign="top"><bold>1.4</bold></td><td valign="top">2.6</td></tr><tr><td valign="top">Rank MAPE</td><td valign="top">2</td><td valign="top"><bold>1.4</bold></td><td valign="top">2.6</td></tr><tr><td valign="top">Rank RMSE</td><td valign="top">2</td><td valign="top"><bold>1.5</bold></td><td valign="top">2.5</td></tr></tbody></table></table-wrap></p>
                  <p id="para0048">To further illustrate the forecasting power of the deep learning-based methods on dataset 2, in <xref rid="fig0017" ref-type="fig">Figs. 17</xref>
–<xref rid="fig0026" ref-type="fig">26</xref>, we also visualize the actual and predicted cases for each country with the results of the best model obtained from the deep learning models. In <xref rid="fig0017" ref-type="fig">Figs. 17</xref>–<xref rid="fig0026" ref-type="fig">26</xref>, the red line indicates the actual values, and the green line corresponds to the forecasted cases using the best deep learning model. As <xref rid="fig0017" ref-type="fig">Figs. 17</xref>, <xref rid="fig0019" ref-type="fig">19</xref>, <xref rid="fig0020" ref-type="fig">20</xref>, <xref rid="fig0022" ref-type="fig">22</xref>, and <xref rid="fig0026" ref-type="fig">26</xref> show, the forecasted cases for countries including US, India, Russia, Mexico, and Iran are very close to the actual values. Besides, for these countries, in most of the time points, the forecasted values overlap the actual ones. The results confirm the power of deep learning models in COVID-19 time series forecasting. Moreover, for countries such as Brazil, South Africa, Peru, Chile, and Columbia as shown in <xref rid="fig0018" ref-type="fig">Figs. 18</xref>
, <xref rid="fig0021" ref-type="fig">21</xref>
, <xref rid="fig0023" ref-type="fig">23</xref>
, <xref rid="fig0024" ref-type="fig">24</xref>
, and <xref rid="fig0025" ref-type="fig">25</xref>
, respectively, the differences between the actual and predicted number of cases are not significant and at some points, the actual and predicted values are very close.<fig id="fig0017"><label>Fig. 17</label><caption><p>The actual and predicted number of cases for test set-US.</p></caption><alt-text id="alt0017">Fig. 17</alt-text><graphic xlink:href="gr17_lrg"/></fig><fig id="fig0018"><label>Fig. 18</label><caption><p>The actual and predicted number of cases for test set-Brazil.</p></caption><alt-text id="alt0018">Fig. 18</alt-text><graphic xlink:href="gr18_lrg"/></fig><fig id="fig0019"><label>Fig. 19</label><caption><p>The actual and predicted number of cases for test set-India.</p></caption><alt-text id="alt0019">Fig. 19</alt-text><graphic xlink:href="gr19_lrg"/></fig><fig id="fig0020"><label>Fig. 20</label><caption><p>The actual and predicted number of cases for test set-Russia.</p></caption><alt-text id="alt0020">Fig. 20</alt-text><graphic xlink:href="gr20_lrg"/></fig><fig id="fig0021"><label>Fig. 21</label><caption><p>The actual and predicted number of cases for test set- South Africa.</p></caption><alt-text id="alt0021">Fig. 21</alt-text><graphic xlink:href="gr21_lrg"/></fig><fig id="fig0022"><label>Fig. 22</label><caption><p>The actual and predicted number of cases for test set-Mexico.</p></caption><alt-text id="alt0022">Fig. 22</alt-text><graphic xlink:href="gr22_lrg"/></fig><fig id="fig0023"><label>Fig. 23</label><caption><p>The actual and predicted number of cases for test set-Peru.</p></caption><alt-text id="alt0023">Fig. 23</alt-text><graphic xlink:href="gr23_lrg"/></fig><fig id="fig0024"><label>Fig. 24</label><caption><p>The actual and predicted number of cases for test set-Chile.</p></caption><alt-text id="alt0024">Fig. 24</alt-text><graphic xlink:href="gr24_lrg"/></fig><fig id="fig0025"><label>Fig. 25</label><caption><p>The actual and predicted number of cases for test set-Colombia.</p></caption><alt-text id="alt0025">Fig. 25</alt-text><graphic xlink:href="gr25_lrg"/></fig><fig id="fig0026"><label>Fig. 26</label><caption><p>The actual and predicted number of cases for test set-Iran.</p></caption><alt-text id="alt0026">Fig. 26</alt-text><graphic xlink:href="gr26_lrg"/></fig></p>
                </sec>
              </sec>
            </sec>
            <sec id="sec0016">
              <label>5</label>
              <title>Conclusion</title>
              <p id="para0049">In this study, three methods based on combining the deep learning models such as multi-head attention, CNN, and LSTM with the Bayesian optimization algorithm were developed to forecast COVID-19 time-series data. The main advantage of the proposed methods is their ability in processing the sequence data. Also, as another advantage, the design of the devised models is based on the multi-output forecasting strategy that allows forecasting multiple next days. The proposed methods were applied on the COVID-19 time series data considering two settings, the short-term forecasting, and the long horizon forecasting. For short-term forecasting, we adopted the fuzzy fractal method as the benchmarking model. the best deep learning model outperforms the fuzzy fractal model in 6 countries out of 10 countries. The significant result is that in terms of all overall measures such as Mean SMAPE, Rank SMAPE, Mean MAPE, Rank MAPE, Mean RMSE, and Rank RMSE, the three proposed methods perform significantly better than the benchmark model. Also, as the long-horizon forecasting is beneficial for long-term decision making on COVID-19 interventions, we explored the ability of the proposed methods on a longer horizon forecasting. The results of experiments indicated that among the three proposed models, the LSTM_BO achieves the best SMAPE in 6 countries. Besides, in terms of the performance measures computed across all countries, LSTM_BO outperformed ATT_BO and CNN_BO. Moreover, visualizing the actual and forecasted values demonstrated the effectiveness of the proposed methods in COVID-19 time series forecasting. As future work, we aim to extend the proposed methods by extracting the informative features from time series and incorporating them into the deep learning models.</p>
            </sec>
            <sec id="sec0016a">
              <title>CRediT authorship contribution statement</title>
              <p id="para0049a"><bold>Hossein Abbasimehr:</bold> Conceptualization, Methodology, Writing - original draft, Writing - review &amp; editing. <bold>Reza Paki:</bold> Software, Data curation, Visualization.</p>
            </sec>
            <sec sec-type="COI-statement">
              <title>Declaration of Competing Interest</title>
              <p id="para0052">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
            </sec>
          </body>
          <back>
            <ref-list id="cebibl1">
              <title>Reference</title>
              <ref id="bib0001">
                <label>1</label>
                <element-citation publication-type="journal" id="sbref0001">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gorbalenya</surname>
                      <given-names>AE</given-names>
                    </name>
                    <name>
                      <surname>Baker</surname>
                      <given-names>SC</given-names>
                    </name>
                    <name>
                      <surname>Baric</surname>
                      <given-names>RS</given-names>
                    </name>
                    <name>
                      <surname>de Groot</surname>
                      <given-names>RJ</given-names>
                    </name>
                    <name>
                      <surname>Drosten</surname>
                      <given-names>C</given-names>
                    </name>
                    <name>
                      <surname>Gulyaeva</surname>
                      <given-names>AA</given-names>
                    </name>
                  </person-group>
                  <article-title>The species severe acute respiratory syndrome-related coronavirus: classifying 2019-nCoV and naming it SARS-CoV-2</article-title>
                  <source>Nat Microbiol</source>
                  <volume>5</volume>
                  <year>2020</year>
                  <fpage>536</fpage>
                  <lpage>544</lpage>
                  <pub-id pub-id-type="doi">10.1038/s41564-020-0695-z</pub-id>
                  <pub-id pub-id-type="pmid">32123347</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0002">
                <label>2</label>
                <element-citation publication-type="journal" id="sbref0002">
                  <person-group person-group-type="author">
                    <name>
                      <surname>İ</surname>
                      <given-names>Kırbaş</given-names>
                    </name>
                    <name>
                      <surname>A</surname>
                      <given-names>Sözen</given-names>
                    </name>
                    <name>
                      <surname>Tuncer</surname>
                      <given-names>AD</given-names>
                    </name>
                    <name>
                      <surname>FŞ</surname>
                      <given-names>Kazancıoğlu</given-names>
                    </name>
                  </person-group>
                  <article-title>Comparative analysis and forecasting of COVID-19 cases in various European countries with ARIMA, NARNN and LSTM approaches</article-title>
                  <source>Chaos Solitons Fractals</source>
                  <volume>138</volume>
                  <year>2020</year>
                  <object-id pub-id-type="publisher-id">110015</object-id>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110015</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0003">
                <label>3</label>
                <element-citation publication-type="journal" id="sbref0003">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Torrealba-Rodriguez</surname>
                      <given-names>O</given-names>
                    </name>
                    <name>
                      <surname>Conde-Gutiérrez</surname>
                      <given-names>R</given-names>
                    </name>
                    <name>
                      <surname>Hernández-Javier</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <article-title>Modeling and prediction of COVID-19 in Mexico applying mathematical and computational models</article-title>
                  <source>Chaos Solitons Fractals</source>
                  <year>2020</year>
                  <object-id pub-id-type="publisher-id">109946</object-id>
                </element-citation>
              </ref>
              <ref id="bib0004">
                <label>4</label>
                <element-citation publication-type="journal" id="sbref0004">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Flaxman</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Mishra</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Gandy</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Unwin</surname>
                      <given-names>HJT</given-names>
                    </name>
                    <name>
                      <surname>Mellan</surname>
                      <given-names>TA</given-names>
                    </name>
                    <name>
                      <surname>Coupland</surname>
                      <given-names>H</given-names>
                    </name>
                  </person-group>
                  <article-title>Estimating the effects of non-pharmaceutical interventions on COVID-19 in Europe</article-title>
                  <source>Nature</source>
                  <volume>584</volume>
                  <year>2020</year>
                  <fpage>257</fpage>
                  <lpage>261</lpage>
                  <pub-id pub-id-type="doi">10.1038/s41586-020-2405-7</pub-id>
                  <pub-id pub-id-type="pmid">32512579</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0005">
                <label>5</label>
                <mixed-citation publication-type="other" id="sbref0005">Critical Trends: Tracking critical data. <ext-link ext-link-type="uri" xlink:href="https://www.coronavirus.jhu.edu/data" id="interref0002">https://coronavirus.jhu.edu/data</ext-link>; 2020 [accessed 2020/06/01].</mixed-citation>
              </ref>
              <ref id="bib0006">
                <label>6</label>
                <element-citation publication-type="journal" id="sbref0006">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Leila</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Mozhgan</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Marziyeh Sadat</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>exponentially increasing trend of infected patients with COVID-19 in Iran: a comparison of neural network and ARIMA forecasting models</article-title>
                  <source>Iran J Public Health</source>
                  <volume>49</volume>
                  <year>2020</year>
                  <pub-id pub-id-type="doi">10.18502/ijph.v49iS1.3675</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0007">
                <label>7</label>
                <element-citation publication-type="journal" id="sbref0007">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Al-Qaness</surname>
                      <given-names>MA</given-names>
                    </name>
                    <name>
                      <surname>Ewees</surname>
                      <given-names>AA</given-names>
                    </name>
                    <name>
                      <surname>Fan</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Abd El Aziz</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <article-title>Optimization method for forecasting confirmed cases of COVID-19 in China</article-title>
                  <source>J Clin Med</source>
                  <volume>9</volume>
                  <year>2020</year>
                  <fpage>674</fpage>
                </element-citation>
              </ref>
              <ref id="bib0008">
                <label>8</label>
                <element-citation publication-type="journal" id="sbref0008">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Castillo</surname>
                      <given-names>O</given-names>
                    </name>
                    <name>
                      <surname>Melin</surname>
                      <given-names>P.</given-names>
                    </name>
                  </person-group>
                  <article-title>Forecasting of COVID-19 time series for countries in the world based on a hybrid approach combining the fractal dimension and fuzzy logic</article-title>
                  <source>Chaos Solitons Fractals</source>
                  <year>2020</year>
                  <object-id pub-id-type="publisher-id">110242</object-id>
                </element-citation>
              </ref>
              <ref id="bib0009">
                <label>9</label>
                <element-citation publication-type="journal" id="sbref0009">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Melin</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Monica</surname>
                      <given-names>JC</given-names>
                    </name>
                    <name>
                      <surname>Sanchez</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Castillo</surname>
                      <given-names>O</given-names>
                    </name>
                  </person-group>
                  <article-title>Multiple ensemble neural network models with fuzzy response aggregation for predicting COVID-19 time series: the case of Mexico</article-title>
                  <source>Healthcare (Basel, Switzerland)</source>
                  <volume>8</volume>
                  <year>2020</year>
                  <fpage>181</fpage>
                  <pub-id pub-id-type="doi">10.3390/healthcare8020181</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0010">
                <label>10</label>
                <element-citation publication-type="journal" id="sbref0010">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Arora</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Kumar</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Panigrahi</surname>
                      <given-names>BK</given-names>
                    </name>
                  </person-group>
                  <article-title>Prediction and analysis of COVID-19 positive cases using deep learning models: A descriptive case study of India</article-title>
                  <source>Chaos Solitons Fractals</source>
                  <volume>139</volume>
                  <year>2020</year>
                  <object-id pub-id-type="publisher-id">110017</object-id>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110017</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0011">
                <label>11</label>
                <element-citation publication-type="journal" id="sbref0011">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Shahid</surname>
                      <given-names>F</given-names>
                    </name>
                    <name>
                      <surname>Zameer</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Muneeb</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <article-title>Predictions for COVID-19 with deep learning models of LSTM, GRU and Bi-LSTM</article-title>
                  <source>Chaos Solitons Fractals</source>
                  <volume>140</volume>
                  <year>2020</year>
                  <object-id pub-id-type="publisher-id">110212</object-id>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110212</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0012">
                <label>12</label>
                <element-citation publication-type="journal" id="sbref0012">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Wang</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Zheng</surname>
                      <given-names>X</given-names>
                    </name>
                    <name>
                      <surname>Ai</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Liu</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Zhu</surname>
                      <given-names>B</given-names>
                    </name>
                  </person-group>
                  <article-title>Time series prediction for the epidemic trends of COVID-19 using the improved LSTM deep learning method: case studies in Russia, Peru and Iran</article-title>
                  <source>Chaos Solitons Fractals</source>
                  <volume>140</volume>
                  <year>2020</year>
                  <object-id pub-id-type="publisher-id">110214</object-id>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110214</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0013">
                <label>13</label>
                <mixed-citation publication-type="other" id="sbref0013">Olah C. Understanding lstm networks, 2015. URL <ext-link ext-link-type="uri" xlink:href="http://www.colah.github.io/posts/2015-08-Understanding-LSTMs" id="interref0006">http://colah.github.io/posts/2015-08-Understanding-LSTMs</ext-link>. 2015.</mixed-citation>
              </ref>
              <ref id="bib0014">
                <label>14</label>
                <element-citation publication-type="book" id="sbref0014">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Li</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Tu</surname>
                      <given-names>Z</given-names>
                    </name>
                    <name>
                      <surname>Yang</surname>
                      <given-names>B</given-names>
                    </name>
                    <name>
                      <surname>Lyu</surname>
                      <given-names>MR</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>T</given-names>
                    </name>
                  </person-group>
                  <chapter-title>Multi-head attention with disagreement regularization</chapter-title>
                  <source>2018 Conference on Empirical Methods in Natural Language Processing. Brussels</source>
                  <year>2018</year>
                  <publisher-name>Belgium: Association for Computational Linguistics</publisher-name>
                  <fpage>2897</fpage>
                  <lpage>2903</lpage>
                </element-citation>
              </ref>
              <ref id="bib0015">
                <label>15</label>
                <element-citation publication-type="book" id="sbref0015">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Goodfellow</surname>
                      <given-names>I</given-names>
                    </name>
                    <name>
                      <surname>Bengio</surname>
                      <given-names>Y</given-names>
                    </name>
                    <name>
                      <surname>Courville</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <chapter-title>Deep learning</chapter-title>
                  <year>2016</year>
                  <publisher-name>MIT press</publisher-name>
                </element-citation>
              </ref>
              <ref id="bib0016">
                <label>16</label>
                <element-citation publication-type="journal" id="sbref0016">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Greff</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Srivastava</surname>
                      <given-names>RK</given-names>
                    </name>
                    <name>
                      <surname>Koutník</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Steunebrink</surname>
                      <given-names>BR</given-names>
                    </name>
                    <name>
                      <surname>Schmidhuber</surname>
                      <given-names>J</given-names>
                    </name>
                  </person-group>
                  <article-title>LSTM: a search space odyssey</article-title>
                  <source>IEEE Trans Neural Netw Learn Syst</source>
                  <volume>28</volume>
                  <year>2017</year>
                  <fpage>2222</fpage>
                  <lpage>2232</lpage>
                  <pub-id pub-id-type="doi">10.1109/TNNLS.2016.2582924</pub-id>
                  <pub-id pub-id-type="pmid">27411231</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0017">
                <label>17</label>
                <element-citation publication-type="journal" id="sbref0017">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Law</surname>
                      <given-names>T</given-names>
                    </name>
                    <name>
                      <surname>Shawe-Taylor</surname>
                      <given-names>J.</given-names>
                    </name>
                  </person-group>
                  <article-title>Practical Bayesian support vector regression for financial time series prediction and market condition change detection</article-title>
                  <source>Quant Finance</source>
                  <volume>17</volume>
                  <year>2017</year>
                  <fpage>1403</fpage>
                  <lpage>1416</lpage>
                </element-citation>
              </ref>
              <ref id="bib0018">
                <label>18</label>
                <element-citation publication-type="journal" id="sbref0018">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ben Taieb</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Sorjamaa</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Bontempi</surname>
                      <given-names>G</given-names>
                    </name>
                  </person-group>
                  <article-title>Multiple-output modeling for multi-step-ahead time series forecasting</article-title>
                  <source>Neurocomputing</source>
                  <volume>73</volume>
                  <year>2010</year>
                  <fpage>1950</fpage>
                  <lpage>1957</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neucom.2009.11.030</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0019">
                <label>19</label>
                <mixed-citation publication-type="other" id="sbref0019">Jia L, Li K, Jiang Y, Guo X. Prediction and analysis of Coronavirus Disease 2019. arXiv preprint arXiv:200305447. 2020.</mixed-citation>
              </ref>
              <ref id="bib0020">
                <label>20</label>
                <element-citation publication-type="journal" id="sbref0020">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Castorina</surname>
                      <given-names>P</given-names>
                    </name>
                    <name>
                      <surname>Iorio</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Lanteri</surname>
                      <given-names>D</given-names>
                    </name>
                  </person-group>
                  <article-title>Data analysis on Coronavirus spreading by macroscopic growth laws</article-title>
                  <source>Int J Mod Phys C</source>
                  <year>2020</year>
                  <object-id pub-id-type="publisher-id">2050103</object-id>
                </element-citation>
              </ref>
              <ref id="bib0021">
                <label>21</label>
                <element-citation publication-type="journal" id="sbref0021">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ntakaris</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Mirone</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Kanniainen</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Gabbouj</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Iosifidis</surname>
                      <given-names>A</given-names>
                    </name>
                  </person-group>
                  <article-title>Feature engineering for mid-price prediction with deep learning</article-title>
                  <source>IEEE Access</source>
                  <volume>7</volume>
                  <year>2019</year>
                  <fpage>82390</fpage>
                  <lpage>82412</lpage>
                </element-citation>
              </ref>
              <ref id="bib0022">
                <label>22</label>
                <element-citation publication-type="journal" id="sbref0022">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sangeetha</surname>
                      <given-names>K</given-names>
                    </name>
                    <name>
                      <surname>Prabha</surname>
                      <given-names>D.</given-names>
                    </name>
                  </person-group>
                  <article-title>Sentiment analysis of student feedback using multi-head attention fusion model of word and context embedding for LSTM</article-title>
                  <source>J Ambient Intell Hum Comput</source>
                  <year>2020</year>
                  <fpage>1</fpage>
                  <lpage>10</lpage>
                </element-citation>
              </ref>
              <ref id="bib0023">
                <label>23</label>
                <mixed-citation publication-type="other" id="sbref0023">Brochu E, Cora VM, De Freitas N. A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. arXiv preprint arXiv:10122599. 2010.</mixed-citation>
              </ref>
              <ref id="bib0024">
                <label>24</label>
                <element-citation publication-type="journal" id="sbref0024">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Cornejo-Bueno</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Garrido-Merchán</surname>
                      <given-names>EC</given-names>
                    </name>
                    <name>
                      <surname>Hernández-Lobato</surname>
                      <given-names>D</given-names>
                    </name>
                    <name>
                      <surname>Salcedo-Sanz</surname>
                      <given-names>S</given-names>
                    </name>
                  </person-group>
                  <article-title>Bayesian optimization of a hybrid system for robust ocean wave features prediction</article-title>
                  <source>Neurocomputing</source>
                  <volume>275</volume>
                  <year>2018</year>
                  <fpage>818</fpage>
                  <lpage>828</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.neucom.2017.09.025</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0025">
                <label>25</label>
                <element-citation publication-type="journal" id="sbref0025">
                  <person-group person-group-type="author">
                    <name>
                      <surname>He</surname>
                      <given-names>F</given-names>
                    </name>
                    <name>
                      <surname>Zhou</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Z-k</surname>
                      <given-names>Feng</given-names>
                    </name>
                    <name>
                      <surname>Liu</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Yang</surname>
                      <given-names>Y</given-names>
                    </name>
                  </person-group>
                  <article-title>A hybrid short-term load forecasting model based on variational mode decomposition and long short-term memory networks considering relevant factors with Bayesian optimization algorithm</article-title>
                  <source>Appl Energy</source>
                  <volume>237</volume>
                  <year>2019</year>
                  <fpage>103</fpage>
                  <lpage>116</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.apenergy.2019.01.055</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0026">
                <label>26</label>
                <element-citation publication-type="journal" id="sbref0026">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Vaswani</surname>
                      <given-names>A</given-names>
                    </name>
                    <name>
                      <surname>Shazeer</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Parmar</surname>
                      <given-names>N</given-names>
                    </name>
                    <name>
                      <surname>Uszkoreit</surname>
                      <given-names>J</given-names>
                    </name>
                    <name>
                      <surname>Jones</surname>
                      <given-names>L</given-names>
                    </name>
                    <name>
                      <surname>Gomez</surname>
                      <given-names>AN</given-names>
                    </name>
                  </person-group>
                  <article-title>Attention is all you need</article-title>
                  <source>Adv Neural Inf Process Syst</source>
                  <year>2017</year>
                  <fpage>5998</fpage>
                  <lpage>6008</lpage>
                </element-citation>
              </ref>
              <ref id="bib0027">
                <label>27</label>
                <element-citation publication-type="journal" id="sbref0027">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hochreiter</surname>
                      <given-names>S</given-names>
                    </name>
                    <name>
                      <surname>Schmidhuber</surname>
                      <given-names>J.</given-names>
                    </name>
                  </person-group>
                  <article-title>Long short-term memory</article-title>
                  <source>Neural Comput</source>
                  <volume>9</volume>
                  <year>1997</year>
                  <fpage>1735</fpage>
                  <lpage>1780</lpage>
                  <pub-id pub-id-type="pmid">9377276</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0028">
                <label>28</label>
                <element-citation publication-type="journal" id="sbref0028">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Abbasimehr</surname>
                      <given-names>H</given-names>
                    </name>
                    <name>
                      <surname>Shabani</surname>
                      <given-names>M</given-names>
                    </name>
                    <name>
                      <surname>Yousefi</surname>
                      <given-names>M</given-names>
                    </name>
                  </person-group>
                  <article-title>An optimized model using LSTM network for demand forecasting</article-title>
                  <source>Comput Ind Eng</source>
                  <year>2020</year>
                  <object-id pub-id-type="publisher-id">106435</object-id>
                  <pub-id pub-id-type="doi">10.1016/j.cie.2020.106435</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0029">
                <label>29</label>
                <mixed-citation publication-type="other" id="sbref0029">Generating sequences with recurrent neural networks. https://arxiv.org/; 2013 [accessed January 10, 2020].</mixed-citation>
              </ref>
              <ref id="bib0030">
                <label>30</label>
                <element-citation publication-type="journal" id="sbref0030">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Rawat</surname>
                      <given-names>W</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>Z.</given-names>
                    </name>
                  </person-group>
                  <article-title>Deep convolutional neural networks for image classification: a comprehensive review</article-title>
                  <source>Neural Comput</source>
                  <volume>29</volume>
                  <year>2017</year>
                  <fpage>2352</fpage>
                  <lpage>2449</lpage>
                  <pub-id pub-id-type="pmid">28599112</pub-id>
                </element-citation>
              </ref>
              <ref id="bib0031">
                <label>31</label>
                <mixed-citation publication-type="other" id="sbref0031">Novel Coronavirus (COVID-19) Cases Data. <ext-link ext-link-type="uri" xlink:href="https://www.data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases" id="interref0012">https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases</ext-link>; 2020</mixed-citation>
              </ref>
              <ref id="bib0032">
                <label>32</label>
                <mixed-citation publication-type="other" id="sbref0032">Keras. <ext-link ext-link-type="uri" xlink:href="https://www.github.com/fchollet/keras" id="interref0013">https://github.com/fchollet/keras</ext-link>; 2015 [accessed January 12, 2020].</mixed-citation>
              </ref>
              <ref id="bib0033">
                <label>33</label>
                <element-citation publication-type="book" id="sbref0033">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Prechelt</surname>
                      <given-names>L.</given-names>
                    </name>
                  </person-group>
                  <chapter-title>Early stopping — but when?</chapter-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Montavon</surname>
                      <given-names>G</given-names>
                    </name>
                    <name>
                      <surname>Orr</surname>
                      <given-names>GB</given-names>
                    </name>
                    <name>
                      <surname>Müller</surname>
                      <given-names>K-R</given-names>
                    </name>
                  </person-group>
                  <source>Neural Networks: Tricks of the Trade</source>
                  <edition>Second ed</edition>
                  <year>2012</year>
                  <publisher-name>Springer Berlin Heidelberg</publisher-name>
                  <publisher-loc>Berlin, Heidelberg</publisher-loc>
                  <fpage>53</fpage>
                  <lpage>67</lpage>
                </element-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
