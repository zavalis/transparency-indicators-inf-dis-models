<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2022-03-11T00:48:15Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:8523546" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:8523546</identifier>
        <datestamp>2021-10-20</datestamp>
        <setSpec>pheelsevier</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3-mathml3.xsd" article-type="research-article" dtd-version="1.3">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Neurocomputing</journal-id>
              <journal-id journal-id-type="iso-abbrev">Neurocomputing</journal-id>
              <journal-title-group>
                <journal-title>Neurocomputing</journal-title>
              </journal-title-group>
              <issn pub-type="ppub">0925-2312</issn>
              <issn pub-type="epub">0925-2312</issn>
              <publisher>
                <publisher-name>Elsevier B.V.</publisher-name>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC8523546</article-id>
              <article-id pub-id-type="pmcid">PMC8523546</article-id>
              <article-id pub-id-type="pmc-uid">8523546</article-id>
              <article-id pub-id-type="pmid">34690432</article-id>
              <article-id pub-id-type="pii">S0925-2312(21)01515-0</article-id>
              <article-id pub-id-type="doi">10.1016/j.neucom.2021.10.035</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Article</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Time series predicting of COVID-19 based on deep learning</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" id="au005">
                  <name>
                    <surname>Alassafi</surname>
                    <given-names>Madini O.</given-names>
                  </name>
                </contrib>
                <contrib contrib-type="author" id="au010">
                  <name>
                    <surname>Jarrah</surname>
                    <given-names>Mutasem</given-names>
                  </name>
                </contrib>
                <contrib contrib-type="author" id="au015">
                  <name>
                    <surname>Alotaibi</surname>
                    <given-names>Reem</given-names>
                  </name>
                  <xref rid="cor1" ref-type="corresp">⁎</xref>
                </contrib>
                <aff id="af005">Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia</aff>
              </contrib-group>
              <author-notes>
                <corresp id="cor1"><label>⁎</label>Corresponding author.</corresp>
              </author-notes>
              <pub-date pub-type="pmc-release">
                <day>19</day>
                <month>10</month>
                <year>2021</year>
              </pub-date>
              <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
              <pub-date pub-type="ppub">
                <day>11</day>
                <month>1</month>
                <year>2022</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>19</day>
                <month>10</month>
                <year>2021</year>
              </pub-date>
              <volume>468</volume>
              <fpage>335</fpage>
              <lpage>344</lpage>
              <history>
                <date date-type="received">
                  <day>15</day>
                  <month>8</month>
                  <year>2021</year>
                </date>
                <date date-type="rev-recd">
                  <day>28</day>
                  <month>9</month>
                  <year>2021</year>
                </date>
                <date date-type="accepted">
                  <day>5</day>
                  <month>10</month>
                  <year>2021</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2021 Elsevier B.V. All rights reserved.</copyright-statement>
                <copyright-year>2021</copyright-year>
                <copyright-holder>Elsevier B.V.</copyright-holder>
                <license>
                  <license-p>Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.</license-p>
                </license>
              </permissions>
              <abstract id="ab005">
                <p>COVID-19 was declared a global pandemic by the World Health Organisation (WHO) on 11th March 2020. Many researchers have, in the past, attempted to predict a COVID outbreak and its effect. Some have regarded time-series variables as primary factors which can affect the onset of infectious diseases like influenza and severe acute respiratory syndrome (SARS). In this study, we have used public datasets provided by the European Centre for Disease Prevention and Control for developing a prediction model for the spread of the COVID-19 outbreak to and throughout Malaysia, Morocco and Saudi Arabia. We have made use of certain effective deep learning (DL) models for this purpose. We assessed some specific major features for predicting the trend of the existing COVID-19 outbreak in these three countries. In this study, we also proposed a DL approach that includes recurrent neural network (RNN) and long short-term memory (LSTM) networks for predicting the probable numbers of COVID-19 cases. The LSTM models showed a 98.58% precision accuracy while the RNN models showed a 93.45% precision accuracy. Also, this study compared the number of coronavirus cases and the number of resulting deaths in Malaysia, Morocco and Saudi Arabia. Thereafter, we predicted the number of confirmed COVID-19 cases and deaths for a subsequent seven days. In this study, we presented their predictions using the data that was available up to December 3rd, 2020.</p>
              </abstract>
              <kwd-group id="kg005">
                <title>Keywords</title>
                <kwd>Prediction</kwd>
                <kwd>RNN</kwd>
                <kwd>LSTM</kwd>
                <kwd>COVID-19</kwd>
                <kwd>Time series</kwd>
              </kwd-group>
            </article-meta>
            <notes>
              <p id="ms005">Communicated by Zidong Wang</p>
            </notes>
          </front>
          <body>
            <sec id="s0005">
              <label>1</label>
              <title>Introduction</title>
              <p id="p0005">The COVID-19 virus has been responsible for ≥113 million confirmed cases and ≥2.5 million deaths across the world. This virus has severely affected the economy and the public health status of the people in various countries. COVID-19 is a new form of coronavirus which has affected many people. They are called ‘corona’ viruses because when observed under the electron microscope, they showed the presence of a ‘solar corona’-like image. In the past, these viruses had triggered many outbreaks, such as the Extreme Acute Respiratory Syndrome Coronavirus (SARS-CoV) in China and the Middle East Respiratory Syndrome Coronavirus (MERS-CoV) in the Middle Eastern countries. COVID-19 is seen to be an infectious disease which is caused by Severe Acute Respiratory Coronavirus 2 (SARS-CoV-2) <xref rid="b0005" ref-type="bibr">[1]</xref>, <xref rid="b0010" ref-type="bibr">[2]</xref>. The COVID-19 virus was initially identified in China in December 2019, after which it spread across all the countries in the world when people started coming in contact with the infected people and then travelled to different regions. It severely affects the lungs and other organs of the respiratory system in the body.</p>
              <p id="p0010">The WHO declared this disease as a pandemic during the initial phases of its transmission, indicating that it is a very severe and deadly disease <xref rid="b0015" ref-type="bibr">[3]</xref>. It is noted that the coronavirus significantly affects the health of people and even causes death, either directly or through exacerbating pre-existing health problems. As a large proportion of people have been affected by the COVID-19 pandemic throughout the world, and there is no cure available for the disease, it becomes important to estimate the number of potential cases that may occur using available data.</p>
              <p id="p0015">Many researchers, including data scientists, have been working intensely to determine ways to eradicate this disease. Data scientists can effectively contribute to the research by designing prediction models that highlight the probable activities of this virus, which can further help in accurately predicting the spread of this virus. Hence, deep learning (DL) models are regarded as accurate tools which can help in developing prediction models. Though many neural networks (NNs) have been described in the past, the recurrent neural network (RNN) and the long short-term memory (LSTM) are investigated in the forecasting of COVID-19 as they can use temporal data <xref rid="b0020" ref-type="bibr">[4]</xref>.</p>
              <p id="p0020">In this study, RNN and LSTM deep-learning networks have been used. These networks were selected as they could analyse the time series data and accurately predict future trends <xref rid="b0020" ref-type="bibr">[4]</xref>. These two models showed considerable success in forecasting temporal data among other traditional methods. Firstly, RNNs have been used for processing the time series and the sequential data, which are also helpful in modelling sequence data. Derived from feedforward networks, RNNs exhibit similar behaviour to how the human brain functions. Simply put, RNNs produce predictive results in sequential data that other algorithms cannot. Then, LSTMs, which have a sophisticated gated memory unit designed to handle the vanishing gradient problems in simple RNNs limiting the efficiency, have been used <xref rid="b0025" ref-type="bibr">[5]</xref>, <xref rid="b0030" ref-type="bibr">[6]</xref>, <xref rid="b0035" ref-type="bibr">[7]</xref>, <xref rid="b0040" ref-type="bibr">[8]</xref>, <xref rid="b0045" ref-type="bibr">[9]</xref>, <xref rid="b0050" ref-type="bibr">[10]</xref>.</p>
              <p id="p0025">The main contribution of this paper is that it proposes DL prediction models which can present the best results related to the prediction of confirmed positive COVID-19 cases and cases of death attributed to COVID-19 in Malaysia, Morocco and Saudi Arabia using past and current data. This study uses the Rectified Linear Unit (ReLU) activation function existing in LSTMs <xref rid="b0055" ref-type="bibr">[11]</xref>; along with tanh and sigmoid activation functions presented in the RNN models <xref rid="b0060" ref-type="bibr">[12]</xref>. It further predicts the number of coronavirus cases and the deaths directly resulting from this disease using NNs. These NNs used the existing datasets that contained all available data related to the COVID-19 pandemic in countries such as Saudi Arabia, Morocco and Malaysia.</p>
              <p id="p0030">This paper is structured as follows: after this introduction, the second section covers the main objectives. <xref rid="s0015" ref-type="sec">Section 3</xref> covers related works on predicting COVID-19. This is followed by an explanation of the data and the research methodology in the fourth and fifth sections. The experiment set-up and the analysis of the results are introduced in <xref rid="s0045" ref-type="sec">6</xref>, <xref rid="s0050" ref-type="sec">7</xref>, respectively. <xref rid="s0055" ref-type="sec">Section 8</xref> discusses the results and, finally, the conclusion is given in <xref rid="s0060" ref-type="sec">Section 9</xref>.</p>
            </sec>
            <sec id="s0010">
              <label>2</label>
              <title>Objectives</title>
              <p id="p0035">This research paper aims to fulfil the following objectives:<list list-type="simple" id="l0005"><list-item id="o0005"><label>1.</label><p id="p0040">To compare and assess the performance of two NN prediction models, i.e., RNN and LSTM, for understanding which model shows a better performance while predicting the number of positive COVID-19 cases, COVID-recovered cases, and the level of mortality caused by the disease.</p></list-item><list-item id="o0010"><label>2.</label><p id="p0045">To use an effective activation function that helps in achieving the best acceptable performance.</p></list-item><list-item id="o0015"><label>3.</label><p id="p0050">To estimate the number of potential coronavirus cases for a subsequent seven days.</p></list-item></list>
</p>
            </sec>
            <sec id="s0015">
              <label>3</label>
              <title>Related works</title>
              <p id="p0055">Dechter stated that the concept of DL was a complement of machine learning (ML) <xref rid="b0045" ref-type="bibr">[9]</xref>. Deep learning was seen to be a subset of machine learning and even artificial intelligence (AI). The AI technique allows computers to imitate human behaviour, while ML displays similar behaviour after using data-driven algorithms. On the other hand, deep learning is regarded as the component of machine learning which is influenced by the human brain structure. This framework is called an artificial neural network (ANN). While training the model using ML, we need to determine all features which are considered by the model while differentiating between two objects. On the other hand, in DL, these features were derived by the neural networks without requiring any human interference. This degree of independence was only achieved after using a large data volume for training the machines.</p>
              <p id="p0060">For predicting the number of people who would succumb to the COVID-19 virus in the subsequent ten days, we made use of the RNN and LSTM algorithms. In an earlier study, we thoroughly reviewed the prevailing COVID-19 daily cases that used LSTM, RNN, and Gated Recurrent Unit (GRU) and successfully predicted the approximate number of deaths over the next ten days <xref rid="b0065" ref-type="bibr">[13]</xref>. As an alternative, Zeroual, A. et al., <xref rid="b0070" ref-type="bibr">[14]</xref> used a technique using RNN, LSTM, Bidirectional LSTM (Bi-LSTM), and GRUs that required the daily number of confirmed COVID-19 cases as the input value. This approach considered the predicted number of new contaminated and recovered cases. In another study, the researchers <xref rid="b0075" ref-type="bibr">[15]</xref> analysed the confirmed and fatal COVID-19 cases to predict the next month’s number of cases and deaths using RNN, Stacked LSTM, Bi-LSTM and Convolutional LSTM. However, the researchers in <xref rid="b0080" ref-type="bibr">[16]</xref> proposed an effective COVID-19 prediction model based on LSTM for the data for daily confirmed cases in both national and provincial levels in Iran. The model was able to predict the cases for a subsequent 21 days and it performed better than the other methods. Abbasimehr and Paki <xref rid="b0085" ref-type="bibr">[17]</xref> presented a forecast of the pandemic based on LSTM and CNN with the Bayesian optimization algorithm. The model’s effectiveness was evaluated using symmetric mean absolute percentage error (SMAPE) which were 0.25 and 2.59 for the short-term (ten days ahead) and for long-term forecasting, respectively. A different forecasting model for COVID-19 was also proposed by Wang et al. using LSTM for predicting cases over the next 30 days <xref rid="b0090" ref-type="bibr">[18]</xref>.</p>
              <p id="p0065">A few machine learning algorithms were also suggested by the Shahid, F., et al., such as autoregressive integrated moving average (ARIMA), SVR and deep learning algorithms such as LSTM and Bi-LSTM to be used for forecasting cases and deaths associated with COVID-19 where the accuracy accomplished for each model revealed that Bi-LSTM generated lowest MAE and RMSE values of 0.0070 and 0.0077, respectively. <xref rid="b0095" ref-type="bibr">[19]</xref>. The LSTM network and fully connected layer proposed by Kai-chaoMiao, et al. the network framework consists of an LSTM network and fully connected layer. In order to make the proposed LSTM framework work, the meteorological element observation data returned hourly is transferred into time series data <xref rid="b0100" ref-type="bibr">[20]</xref>. Kai and et. al used deep supervised learning using self-adaptive auxiliary loss for COVID-19 diagnosis from imbalanced CT images <xref rid="b0105" ref-type="bibr">[21]</xref>. <xref rid="t0005" ref-type="table">Table 1</xref>
below summarises the related work.<table-wrap position="float" id="t0005"><label>Table 1</label><caption><p>Summarizes of the related work.</p></caption><table frame="hsides" rules="groups"><thead><tr><th><bold>Study</bold></th><th><bold>Year</bold></th><th><bold>Technique</bold></th><th><bold>Input</bold></th><th><bold>Output</bold></th><th><bold>Accuracy</bold></th></tr></thead><tbody><tr><td>Time series forecasting of COVID-19 transmission in Asia Pacific countries using deep neural networks.</td><td>January 2021</td><td>LSTM, RNN, and GRU</td><td>Daily Confirmed Cases</td><td>Next 10 days</td><td>More than 90%</td></tr><tr><td>Deep learning methods for forecasting COVID-19 time-series data: A comparative study.</td><td>November 2020</td><td>RNN, LSTM, BiLSTM, GRUs algorithms</td><td>Daily confirmed and recovered cases collected from six countries namely Italy, Spain, France, China, USA, and Australia.</td><td>Forecasting of the number of new contaminated and recovered cases</td><td>VAE achieved MAPE values of 5.90%, 2.19%, 1.88%, 0.128%, 0.236%, and 2.04% respectively</td></tr><tr><td>Time series forecasting of Covid-19 using deep learning models: India-USA comparative case study.</td><td>November 2020</td><td>RNN, Stacked LSTM, Bi-LSTM and Convolutional LSTM</td><td>Confirmed cases and deaths</td><td>Next month</td><td>Two models with error rate ranges from 2.0 to 3.3 percent</td></tr><tr><td>COVID-19 Infection forecasting based on deep learning in Iran.</td><td>November 2020</td><td>LSTM</td><td>Daily confirmed cases in both national and province levels, in Iran</td><td>Next 21 days</td><td>LSTM model performed better than the other methods</td></tr><tr><td>Prediction of COVID-19 confirmed cases combining deep learning methods and Bayesian optimization.</td><td>January 2021</td><td>Multi-head attention, LSTM, and CNN with the Bayesian optimization algorithm</td><td>Confirmed cases and deaths</td><td>10 days ahead</td><td>The mean SMAPE model is 0.25 for the short-term forecasting with a long horizon mean SMAPE of 2.59</td></tr><tr><td>Time series prediction for the epidemic trends of COVID-19 using the improved LSTM deep learning method: Case studies in Russia, Peru and Iran.</td><td>November 2020</td><td>LSTM</td><td>Daily confirmed cases</td><td>Next 30 days</td><td>The proposed method can accurately analyse the trend of the epidemic.</td></tr><tr><td>Predictions for COVID-19 with deep learning models of LSTM, GRU and Bi-LSTM.</td><td>November 2020</td><td>ARIMA, SVR, LSTM and Bi-LSTM</td><td>Daily confirmed cases and deaths</td><td>Prediction of confirmed cases and deaths</td><td>Bi-LSTM generates lowest MAE and RMSE values of 0.0070 and 0.0077, respectively</td></tr><tr><td>Application of LSTM for short-term fog forecasting based on meteorological elements</td><td>September 2020</td><td>LSTM network and fully connected layer</td><td>Meteorological elements (temperature (TEMP), air pressure (AIP), wind speed (WS) …)</td><td>Fog forecasting</td><td>The proposed LSTM framework achieved 1.1%, 11%, 3%, and 11% higher performance than the best traditional machine learning algorithm.</td></tr><tr><td>Deep supervised learning using self-adaptive auxiliary loss for COVID-19 diagnosis from imbalanced CT images</td><td>October 2021</td><td>Deep supervised learning with a self-adaptive auxiliary loss (DSN-SAAL)</td><td>Chest CT</td><td>Diagnosis of COVID-19</td><td>Outperforms the state-of-the-art methods and is effective for the predictions relating to COVID-19 in varying degrees of data imbalance.</td></tr></tbody></table></table-wrap></p>
            </sec>
            <sec id="s0020">
              <label>4</label>
              <title>Dataset description</title>
              <p id="p0070">This research used daily confirmed cases and deaths data from Saudi Arabia, Morocco and Malaysia, which were available from the European Centre for Disease Prevention and Control<xref rid="fn1" ref-type="fn">1</xref>
. Firstly, this research used data from March 15, 2020, as the date of the first reported case until December 3, 2020. It contained of 816 records and its total size was 4.5 MB. The data for that period was used as follows: 80% for training and 20% for testing <xref rid="b0110" ref-type="bibr">[22]</xref> of models to find the appropriate parameters. After training, the next step was testing. The pattern of daily confirmed cases for Saudi Arabia, Malaysia, and Morocco - COVID-19 are presented in <xref rid="f0005" ref-type="fig">Fig. 1</xref>, <xref rid="f0010" ref-type="fig">Fig. 2</xref>
shows the pattern of daily deaths cases for the three countries.<fig id="f0005"><label>Fig. 1</label><caption><p>Daily confirmed cases for Saudi Arabia, Malaysia, and Morocco - COVID-19.</p></caption><graphic xlink:href="gr1_lrg"/></fig><fig id="f0010"><label>Fig. 2</label><caption><p>Daily deaths for Saudi Arabia, Malaysia, and Morocco - COVID-19.</p></caption><graphic xlink:href="gr2_lrg"/></fig></p>
            </sec>
            <sec id="s0025">
              <label>5</label>
              <title>Methods and models</title>
              <p id="p0075">Deep neural networks are seen to be an effective technique, which could be used for automatically learning the arbitrary complex mappings from inputs to outputs. These processes support multiple inputs and outputs. Furthermore, these processes are robust to non-linear, multivariate or noisy inputs and multi-step forecasts <xref rid="b0115" ref-type="bibr">[23]</xref>. <xref rid="f0015" ref-type="fig">Fig. 3</xref>
summarises the general research methodology used in this paper to provide COVID-19 predictions using deep neural networks. The special features of this study are also described below:<list list-type="simple" id="l0010"><list-item id="o0020"><label>1.</label><p id="p0080">All COVID-19 datasets were considered for training and testing the predictive models <xref rid="b0120" ref-type="bibr">[24]</xref>.</p></list-item><list-item id="o0025"><label>2.</label><p id="p0085">To predict the confirmed cases and deaths related to COVID-19, we have used two types of DL-NN, i.e., RNNs and LSTMs. We estimated and compared the performances of the prediction models using the above NNs.</p></list-item><list-item id="o0030"><label>3.</label><p id="p0090">We determined the performances of the RNNs and the LSTMs networks, using three types of activation functions, i.e., Relu, tanh, and sigmoid.</p></list-item><list-item id="o0035"><label>4.</label><p id="p0095">The drawbacks of using a simple RNN have been presented below.</p></list-item><list-item id="o0040"><label>5.</label><p id="p0100">The results indicated that the LSTM showed a better performance in predicting COVID-19 cases.</p></list-item></list>
<fig id="f0015"><label>Fig. 3</label><caption><p>The general research methodology used in this paper.</p></caption><graphic xlink:href="gr3_lrg"/></fig></p>
              <sec id="s0030">
                <label>5.1</label>
                <title>Recurrent neural networks (RNNs)</title>
                <p id="p0105">RNNs have been used for processing the time series and the sequential data <xref rid="b0025" ref-type="bibr">[5]</xref>. The RNN structure included three layers, i.e., an input layer (x), output layer (y), and a hidden layer (h). The advanced feed-forward NNs are generally called RNNs since the information in the simple feed-forward NNs moves in one direction, i.e., it is transmitted from the input to the hidden layer and finally to the output layer. This information never moves in the reverse direction <xref rid="b0030" ref-type="bibr">[6]</xref>.</p>
                <p id="p0110">However, some ties in the RNNs point backwards and show that the information can move in both the forward and the backward directions <xref rid="b0035" ref-type="bibr">[7]</xref>. These parameters are shared by the RNNs using different time-steps. They consist of loops within the layers, which indicate that a neuron can receive inputs and generate outputs for transmitting the outputs again back to itself. Thus, the RNNs use two forms of input, i.e., existing input which is indicated by xt and another input which is described as yt-1 and is generated from the outputs of the earlier time-steps <xref rid="b0005" ref-type="bibr">[1]</xref>.</p>
                <p id="p0115">In this study, we have used RNNs to model time series data associated with the COVID-19 cases occurring in three countries for a period ranging between March and December 2020. RNNs are supported by their characteristic feature of using the time series data for making future predictions. Here, we have outlined their proposed model for creating an accurate prediction model. In this section, we have investigated the process for predicting new COVID-19 cases and associated deaths for the subsequent seven days in three countries: Morocco, Malaysia and Saudi Arabia. <xref rid="f0020" ref-type="fig">Fig. 4</xref>
describes the proposed model and all steps undertaken for producing the model based on RNN and the exponential moving average (EMA). The major steps implemented in this model are shown in Algorithm 1.<table-wrap position="float" id="t0025"><table frame="hsides" rules="groups"><thead><tr><th><bold>Algorithm 1</bold></th></tr></thead><tbody><tr><td><bold>Input:</bold> Load dataset for pre-processing to remove the noise using EMA</td></tr><tr><td><bold>Output:</bold> Positive COVID-19 cases and deaths over seven days</td></tr><tr><td>Normalize the dataset into values from 0 to 1</td></tr><tr><td> <bold>Initialize</bold> the network</td></tr><tr><td><bold>Set</bold> the no. of RNN blocks and input activation function</td></tr><tr><td> <bold>Select</bold> training window size</td></tr><tr><td>  <bold>for</bold> n epochs and batch size <bold>do</bold></td></tr><tr><td>   Train the network</td></tr><tr><td>  <bold>end for</bold></td></tr><tr><td><bold>Run</bold> Predictions</td></tr><tr><td><bold>Calculate</bold> the loss function, MSE, MAE, MAPE and RMSE</td></tr></tbody></table></table-wrap>
<xref rid="f0020" ref-type="fig">Fig. 4</xref> presents an overview of the RNN framework. Here, the model can assist in determining the number of newCOVID-19 cases and the resulting deaths due to COVID-19. Step 1, i.e., EMA is implemented for assessing the number of confirmed COVID-19 cases using the time series for removing all noise. In Step 2, the data is categorised into two parts, and the data normalisation technique is used. Here, we carried out data normalisation for adjusting the numerical values within the dataset based on a standard scale, while ensuring that the differences within the value range were not distorted.<fig id="f0020"><label>Fig. 4</label><caption><p>Framework for the RNN model.</p></caption><graphic xlink:href="gr4_lrg"/></fig></p>
                <p id="p0120">Thereafter, Step 3 reshapes the 1-D array in a matrix. This matrix can again be converted to form an array. Finally, it is important to initialise the network, i.e., properly set the outputs for the neurons which are initially hidden. The RNN is initialised with the 0-state value, which is also known as the steady state. With regards to the dynamic system recognition, all the above initialisation steps indicate that the system that requires modelling is in a steady state.</p>
              </sec>
              <sec id="s0035">
                <label>5.2</label>
                <title>Long short-term memory networks (LSTMs)</title>
                <p id="p0125">RNNs cause the disappearance of the vanishing gradient point error <xref rid="b0040" ref-type="bibr">[8]</xref>, which leads to the development of a novel model called the long short-term memory (LSTM) that can handle this issue. These NNs can record the information for a longer period of time. The LSTM networks were first developed in 1997 by Horchreiter and Schmidhuber. They possess a chain-like structure having multiple repeating modules. It was noted that this RNN learning technique could effectively tolerate the avoidance of the vanishing gradient and explosion of the gradient errors by using the LSTMs-RNN process <xref rid="b0045" ref-type="bibr">[9]</xref>. However, even this special RNN group could resolve these issues <xref rid="b0050" ref-type="bibr">[10]</xref>.</p>
                <p id="p0130">After we collected the weak results generated from the model that was based on the simple RNN technique, we implemented the LSTM-based prediction model for predicting the COVID-19 cases in the three countries. LSTMs possess certain cell states which can either selectively forget or remember things. Three gates are applicable for a cell state. The first forget gate removes all information from a cell state that it does not need. The second input gate adds vital information to a cell state. The third output gate helps in selecting all vital information and generating output <xref rid="b0125" ref-type="bibr">[25]</xref>. The cell can store values from a random time interval, while the three gates control the complete information flow into and out of the cell. <xref rid="f0025" ref-type="fig">Fig. 5</xref>
describes the LSTM gates <xref rid="b0130" ref-type="bibr">[26]</xref> while <xref rid="t0010" ref-type="table">Table 2</xref>
presents the formulae used for every component at the time step, <italic>t</italic>.<fig id="f0025"><label>Fig. 5</label><caption><p>LSTM gates.</p></caption><graphic xlink:href="gr5_lrg"/></fig><table-wrap position="float" id="t0010"><label>Table 2</label><caption><p>List of formulae used for every component at the time step, <italic>t</italic><xref rid="b0130" ref-type="bibr">[26]</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Component</th><th>Formula</th><th>Purpose</th></tr></thead><tbody><tr><td>Input Gate</td><td><inline-formula><mml:math id="M1" altimg="si1.svg"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = σ (<inline-formula><mml:math id="M2" altimg="si2.svg"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. [<inline-formula><mml:math id="M3" altimg="si3.svg"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>] + <inline-formula><mml:math id="M4" altimg="si4.svg"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>)</td><td>Control level of cell state update</td></tr><tr><td>Forget Gate</td><td><inline-formula><mml:math id="M5" altimg="si5.svg"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td>Control level of cell state reset (forget)</td></tr><tr><td>Cell Candidate</td><td><inline-formula><mml:math id="M6" altimg="si6.svg"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td>Add information to cell state</td></tr><tr><td>Output Gate</td><td><inline-formula><mml:math id="M7" altimg="si7.svg"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td>Control level of cell state added to a hidden state</td></tr></tbody></table></table-wrap></p>
                <p id="p0135"><xref rid="f0030" ref-type="fig">Fig. 6</xref> below presents the prediction model framework that was based on the LSTM and EMA processes.<fig id="f0030"><label>Fig. 6</label><caption><p>Framework of the LSTM model proposed in this study.</p></caption><graphic xlink:href="gr6_lrg"/></fig></p>
                <p id="p0140">Algorithm 2 shows the important steps that were implemented in the LSTM model as the pseudocode below.<table-wrap position="float" id="t0030"><table frame="hsides" rules="groups"><thead><tr><th><bold>Algorithm 2</bold></th></tr></thead><tbody><tr><td><bold>Input:</bold> Historical Confirmed Covid-19 cases</td></tr><tr><td><bold>Output:</bold> Predicted next seven days for n Data Points</td></tr><tr><td>Data ≤ Historical Confirmed Covid-19 cases</td></tr><tr><td><bold>Function</bold> Pre-processing (Confirmed cases, sequence_length)</td></tr><tr><td><bold>Input:</bold> Confirmed cases (Dataset)</td></tr><tr><td><bold>Output:</bold> The Data is normalised and split to Train and Test</td></tr><tr><td>Data_windows ≤ windows(Confirmed cases, sequence_length)</td></tr><tr><td><bold>Function</bold> Normalise(Data_windows) Normalised_data = []</td></tr><tr><td>For i in Data_windows:</td></tr><tr><td>Normalised_window = [((float(p)/float (i[0])) − 1) <bold>for</bold> p in i]</td></tr><tr><td>Normalised_data.append(Normalised_window)</td></tr><tr><td><bold>Return</bold> Normalised_data</td></tr><tr><td> row ≤ 90% of the shape of normalised data</td></tr><tr><td> Train_data ≤ [: row, : −1]</td></tr><tr><td> Train_label ≤ [: row, −1] <italic>//as sequence prediction is done the same data is divided to</italic></td></tr><tr><td> Test_data ≤  [row:, : −1]//<italic>train_data, train_label, test_data and test_label.</italic></td></tr><tr><td>Test_label ≤ [row:, −1]</td></tr><tr><td><bold>Function</bold> model(a, b, epoch, batch_size)</td></tr><tr><td><bold>Input:</bold> a and b are the Train_Data and Train_label respectively.</td></tr><tr><td><bold>Output:</bold> the Trained model is obtained.</td></tr><tr><td>Network = <bold>sequential ()</bold></td></tr><tr><td>Network<bold>.add</bold>(LSTM(input, output, dropout)) <italic>//Input Layer of LSTM RNN</italic></td></tr><tr><td>Network<bold>.add</bold>(LSTM(cells, activation, dropout))</td></tr><tr><td>Network<bold>.add</bold> (LSTM(cells, activation, dropout))</td></tr><tr><td>Network<bold>.add</bold>(LSTM(cells, activation, dropout))n <italic>//Hidden Layers</italic></td></tr><tr><td>Network<bold>.add</bold>(LSTM(output, output_activation) <italic>//Output Layer</italic></td></tr><tr><td>Network<bold>.compile</bold>(loss_function, optimizer) <italic>//Defining Optimisation of the model</italic></td></tr><tr><td>Network<bold>.fit</bold>(a, b, epoch, batch_size, validation) <italic>//Training the model</italic></td></tr></tbody></table></table-wrap>
</p>
              </sec>
              <sec id="s0040">
                <label>5.3</label>
                <title>Evaluation metrics</title>
                <p id="p0145">We evaluated the results of the above experiments using different metrics, i.e., accuracy, mean squared error (MSE), mean absolute error (MAE), mean absolute percentage error (MAPE) and root mean squared error (RMSE) <xref rid="b0135" ref-type="bibr">[27]</xref>. Accuracy helps in calculating how often the prediction was similar to the actual label. MAE and MSE help in computing the mean absolute error value and mean squared error that is noted between the y_true and y_pred, respectively. Lastly, MAPE is defined as the measure of the prediction accuracy of the forecasting technique used in statistics, such as trend estimation. It is also used as the loss function for regression problems in ML processes.</p>
              </sec>
            </sec>
            <sec id="s0045">
              <label>6</label>
              <title>Experimental setting</title>
              <p id="p0150">In this work, we have investigated the best parameter settings such as number of epochs, batch size, and neurons to achieve good prediction result for cases of and death from COVID-19 over a subsequent seven-say period. These parameters are described as follows:<list list-type="simple" id="l0015"><list-item id="o0045"><label>•</label><p id="p0155">Epochs: The number of epochs is a factor that defines the number of times that the learning method will function through the whole training dataset. The number of epochs is the number of full passes through the dataset of the training.</p></list-item><list-item id="o0050"><label>•</label><p id="p0160">Batch size: The size of batch is a factor that defines the number of samples to work with prior to updating the variables of the internal model. The batch size refers to the number of samples processed ahead of the updating of the model.</p></list-item><list-item id="o0055"><label>•</label><p id="p0165">Neurons: The number of neurons impacts the network’s learning capacity. In general, the greater the number of neurons, the greater the learning of the problem structure at the expense of a longer learning period. Greater capacity for learning also results in potential problem of overfitting the data used for training <xref rid="b0140" ref-type="bibr">[28]</xref>.</p></list-item></list>
</p>
              <p id="p0170"><xref rid="t0015" ref-type="table">Table 3</xref> shows the MAE, MSE, RMSE and MAPE under various numbers of parameters such as numbers of epochs, batch size and neurons for RNN and LSTM. A benchmark dataset has been used to conduct experiments and identify the appropriate variables. The dataset was obtained from the Kaggle website<xref rid="fn2" ref-type="fn">2</xref>
. The results show that 50 epochs with 40 batch sizes for RNN, and 70 epochs with 56 batch sizes and 7 neurons for LSTM provide adequate training. This means the training process becomes stable, and there is no benefit in increasing the number of epochs. We looked at the validation and training losses and track their values. If the validation loss increases, that means overfitting can happen. Thus, we should set the number of epochs as high as possible to avoid overfitting.<table-wrap position="float" id="t0015"><label>Table 3</label><caption><p>Experiments parameters for different models with different activation functions. Bold values indicate the best results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Experiment</th><th>Alg.</th><th>Epochs</th><th>Batch size</th><th>Neurons</th><th>MAE</th><th>MSE</th><th>RMSE</th><th>MAPE%</th></tr></thead><tbody><tr><td>1</td><td rowspan="5">RNN using Sigmoid</td><td>10</td><td>8</td><td>–</td><td align="char">5.217</td><td align="char">4.579</td><td align="char">7.672</td><td align="char">85.49%</td></tr><tr><td>2</td><td>20</td><td>16</td><td>–</td><td align="char">6.489</td><td align="char">5.241</td><td align="char">8.468</td><td align="char">91.61%</td></tr><tr><td>3</td><td>30</td><td>24</td><td>–</td><td align="char">3.689</td><td align="char">5.487</td><td align="char">8.568</td><td align="char">96.33%</td></tr><tr><td>4</td><td>40</td><td>32</td><td>–</td><td align="char">5.345</td><td align="char">6.023</td><td align="char">7.469</td><td align="char">85.51%</td></tr><tr><td><bold>5</bold></td><td><bold>50</bold></td><td><bold>40</bold></td><td>–</td><td align="char"><bold>2.121</bold></td><td align="char"><bold>1.477</bold></td><td align="char"><bold>1.917</bold></td><td align="char"><bold>97.34%</bold></td></tr><tr><td>6</td><td rowspan="5">RNN using Tanh</td><td>60</td><td>48</td><td>–</td><td align="char">3.814</td><td align="char">6.948</td><td align="char">7.861</td><td align="char">89.01%</td></tr><tr><td>7</td><td>70</td><td>56</td><td>–</td><td align="char">3.373</td><td align="char">2.326</td><td align="char">1.812</td><td align="char">96.27%</td></tr><tr><td>8</td><td>80</td><td>64</td><td>–</td><td align="char">2.932</td><td align="char">7.804</td><td align="char">7.743</td><td align="char">90.95%</td></tr><tr><td>9</td><td>90</td><td>72</td><td>–</td><td align="char">2.511</td><td align="char">8.302</td><td align="char">7.714</td><td align="char">92.35%</td></tr><tr><td>10</td><td>100</td><td>80</td><td>–</td><td align="char">2.763</td><td align="char">8.766</td><td align="char">7.625</td><td align="char">93.32%</td></tr><tr><td colspan="9">  </td></tr><tr><td>1</td><td rowspan="10">LSTM using ReLU</td><td>10</td><td>8</td><td>1</td><td align="char">3.541</td><td align="char">1.852</td><td align="char">1.412</td><td align="char">97.09%</td></tr><tr><td>2</td><td>20</td><td>16</td><td>2</td><td align="char">4.234</td><td align="char">1.894</td><td align="char">1.521</td><td align="char">98.75%</td></tr><tr><td>3</td><td>30</td><td>24</td><td>3</td><td align="char">2.402</td><td align="char">2.636</td><td align="char">1.701</td><td align="char">98.15%</td></tr><tr><td>4</td><td>40</td><td>32</td><td>4</td><td align="char">2.253</td><td align="char">3.378</td><td align="char">2.516</td><td align="char">96.75%</td></tr><tr><td><bold>5</bold></td><td>50</td><td>40</td><td>5</td><td align="char">1.683</td><td align="char">4.121</td><td align="char">1.411</td><td align="char">97.34%</td></tr><tr><td>6</td><td>60</td><td>48</td><td>6</td><td align="char">1.114</td><td align="char">4.862</td><td align="char">1.798</td><td align="char">98.01%</td></tr><tr><td>7</td><td><bold>70</bold></td><td><bold>56</bold></td><td><bold>7</bold></td><td align="char"><bold>0.544</bold></td><td align="char"><bold>1.604</bold></td><td align="char"><bold>0.726</bold></td><td align="char"><bold>99.27%</bold></td></tr><tr><td>8</td><td>80</td><td>64</td><td>8</td><td align="char">2.024</td><td align="char">4.346</td><td align="char">1.301</td><td align="char">98.95%</td></tr><tr><td>9</td><td>90</td><td>72</td><td>9</td><td align="char">2.594</td><td align="char">3.088</td><td align="char">1.612</td><td align="char">97.05%</td></tr><tr><td>10</td><td>100</td><td>80</td><td>10</td><td align="char">1.163</td><td align="char">4.831</td><td align="char">1.704</td><td align="char">97.12%</td></tr></tbody></table></table-wrap></p>
            </sec>
            <sec id="s0050">
              <label>7</label>
              <title>Results</title>
              <p id="p0175">In this section, we have presented the experimental results that were generated after the implementation and analysis of RNN and LSTM with EMA proposed prediction models. RNN and LSTM have been adopted for predicting the two parameters associated with COVID-19 cases in three countries. We determined the number of a) Confirmed COVID cases, and the b) Resultant COVID-related deaths.</p>
              <p id="p0180">We initially implemented the simple RNN model, however, it was soon discarded as it performed poorly. Thereafter, we used the LSTM-based prediction model for predicting the COVID-19 cases derived from the datasets. The LSTMs consist of cell states and actively forget or remember information. The three gates which worked in the cell state included the forget gate, input and output gates. Hence, we used these gates for developing three layers, i.e., the LSTM layer, the Dropout layer and the Dense layer for developing the LSTM model. Here, we implemented two different steps compared to simple RNN. Initially, we set a fixed random seed for reproducibility and used a rectified linear activation function (ReLU). Using the ReLU, we estimated the Keras metrics for the LSTM and derived the best results. Furthermore, we also decreased the vanishing gradient point error.</p>
              <p id="p0185"><xref rid="t0020" ref-type="table">Table 4</xref> presents the results of the RNN- and the LSTM-based prediction models. <xref rid="f0035" ref-type="fig">Fig. 7</xref>, <xref rid="f0040" ref-type="fig">Fig. 8</xref>, <xref rid="f0045" ref-type="fig">Fig. 9</xref>, <xref rid="f0050" ref-type="fig">Fig. 10</xref>, <xref rid="f0055" ref-type="fig">Fig. 11</xref>, <xref rid="f0060" ref-type="fig">Fig. 12</xref>, <xref rid="f0065" ref-type="fig">Fig. 13</xref>, <xref rid="f0070" ref-type="fig">Fig. 14</xref>, <xref rid="f0075" ref-type="fig">Fig. 15</xref>, <xref rid="f0080" ref-type="fig">Fig. 16</xref>, <xref rid="f0085" ref-type="fig">Fig. 17</xref>, <xref rid="f0090" ref-type="fig">Fig. 18</xref>
depict the graphical representation of the results. The results indicated that the LSTM-based prediction model showed a 98.53% accuracy, which was 5.13% better compared to the accuracy displayed by the RNN model.<table-wrap position="float" id="t0020"><label>Table 4</label><caption><p>Results of the various metrics used for determining the efficacy of the RNN- and LSTM-based prediction models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Country</th><th>Algorithm</th><th/><th/><th><bold>Day1</bold></th><th><bold>Day2</bold></th><th><bold>Day3</bold></th><th><bold>Day4</bold></th><th><bold>Day5</bold></th><th><bold>Day6</bold></th><th><bold>Day7</bold></th><th><bold>MAE</bold></th><th><bold>MSE</bold></th><th><bold>RMSE</bold></th><th><bold>MAPE %</bold></th></tr></thead><tbody><tr><td rowspan="3">Saudi Arabia</td><td/><td/><td>Actual</td><td>293</td><td>295</td><td>281</td><td>269</td><td>262</td><td>262</td><td>260</td><td/><td/><td/><td/></tr><tr><td>RNN</td><td rowspan="2">Cases</td><td>Predicted</td><td>307</td><td>308</td><td>295</td><td>283</td><td>276</td><td>276</td><td>274</td><td align="char">13.750</td><td align="char">189.128</td><td align="char">13.752</td><td align="char">0.950</td></tr><tr><td>LSTM</td><td>Predicted</td><td>291</td><td>298</td><td>296</td><td>270</td><td>260</td><td>256</td><td>262</td><td align="char">4.617</td><td align="char">41.746</td><td align="char">6.461</td><td align="char">0.983</td></tr><tr><td colspan="15">  </td></tr><tr><td rowspan="3">Saudi Arabia</td><td/><td/><td>Actual</td><td>16</td><td>16</td><td>15</td><td>15</td><td>14</td><td>14</td><td>13</td><td/><td/><td/><td/></tr><tr><td>RNN</td><td rowspan="2">Deaths</td><td>Predicted</td><td>16</td><td>16</td><td>14</td><td>15</td><td>14</td><td>14</td><td>13</td><td align="char">0.161</td><td align="char">0.026</td><td align="char">0.161</td><td align="char">0.969</td></tr><tr><td>LSTM</td><td>Predicted</td><td>16</td><td>16</td><td>15</td><td>14</td><td>14</td><td>14</td><td>13</td><td align="char">0.161</td><td align="char">0.026</td><td align="char">0.161</td><td align="char">0.969</td></tr><tr><td colspan="15">  </td></tr><tr><td rowspan="3">Malaysia</td><td/><td/><td>Actual</td><td>935</td><td>1109</td><td>1315</td><td>1309</td><td>1212</td><td>1472</td><td>851</td><td/><td/><td/><td/></tr><tr><td>RNN</td><td rowspan="2">Cases</td><td>Predicted</td><td>957</td><td>1119</td><td>1303</td><td>1298</td><td>1213</td><td>1437</td><td>876</td><td align="char">16.481</td><td align="char">381.864</td><td align="char">19.541</td><td align="char">0.955</td></tr><tr><td>LSTM</td><td>Predicted</td><td>942</td><td>1111</td><td>1323</td><td>1310</td><td>1210</td><td>1485</td><td>859</td><td align="char">5.857</td><td align="char">50.714</td><td align="char">7.121</td><td align="char">0.994</td></tr><tr><td colspan="15">  </td></tr><tr><td rowspan="3">Malaysia</td><td/><td/><td>Actual</td><td>3</td><td>2</td><td>1</td><td>7</td><td>3</td><td>3</td><td>2</td><td/><td/><td/><td/></tr><tr><td>RNN</td><td rowspan="2">Deaths</td><td>Predicted</td><td>2</td><td>2</td><td>1</td><td>6</td><td>2</td><td>2</td><td>2</td><td align="char">0.571</td><td align="char">0.571</td><td align="char">0.755</td><td align="char">0.836</td></tr><tr><td>LSTM</td><td>Predicted</td><td>3</td><td>2</td><td>2</td><td>7</td><td>3</td><td>3</td><td>2</td><td align="char">0.142</td><td align="char">0.142</td><td align="char">0.377</td><td align="char">0.857</td></tr><tr><td colspan="15">  </td></tr><tr><td rowspan="3">Morocco</td><td/><td/><td>Actual</td><td>4178</td><td>4592</td><td>4412</td><td>4115</td><td>2533</td><td>3508</td><td>4346</td><td/><td/><td/><td/></tr><tr><td>RNN</td><td rowspan="2">Cases</td><td>Predicted</td><td>4094</td><td>4474</td><td>4310</td><td>4035</td><td>2509</td><td>3462</td><td>4249</td><td align="char">78.244</td><td align="char">7063.968</td><td align="char">84.047</td><td align="char">0.981</td></tr><tr><td>LSTM</td><td>Predicted</td><td>4182</td><td>4582</td><td>4415</td><td>4121</td><td>2562</td><td>3518</td><td>4341</td><td align="char">9.571</td><td align="char">161.0</td><td align="char">12.688</td><td align="char">0.997</td></tr><tr><td colspan="15">  </td></tr><tr><td rowspan="3">Morocco</td><td/><td/><td>Actual</td><td>80</td><td>70</td><td>50</td><td>50</td><td>57</td><td>69</td><td>70</td><td/><td/><td/><td/></tr><tr><td>RNN</td><td rowspan="2">Deaths</td><td>Predicted</td><td>78</td><td>69</td><td>50</td><td>50</td><td>57</td><td>68</td><td>69</td><td align="char">0.714</td><td align="char">1.012</td><td align="char">1.021</td><td align="char">0.991</td></tr><tr><td>LSTM</td><td>Predicted</td><td>82</td><td>71</td><td>51</td><td>51</td><td>57</td><td>70</td><td>70</td><td align="char">0.857</td><td align="char">1.142</td><td align="char">1.069</td><td align="char">0.986</td></tr></tbody></table></table-wrap><fig id="f0035"><label>Fig. 7</label><caption><p>Saudi Arabia cases (RNN).</p></caption><graphic xlink:href="gr7_lrg"/></fig><fig id="f0040"><label>Fig. 8</label><caption><p>Saudi Arabia cases (LSTM).</p></caption><graphic xlink:href="gr8_lrg"/></fig><fig id="f0045"><label>Fig. 9</label><caption><p>Saudi Arabia Deaths (RNN).</p></caption><graphic xlink:href="gr9_lrg"/></fig><fig id="f0050"><label>Fig. 10</label><caption><p>Saudi Arabia Deaths (LSTM).</p></caption><graphic xlink:href="gr10_lrg"/></fig><fig id="f0055"><label>Fig. 11</label><caption><p>Malaysia cases (RNN).</p></caption><graphic xlink:href="gr11_lrg"/></fig><fig id="f0060"><label>Fig. 12</label><caption><p>Malaysia cases (LSTM).</p></caption><graphic xlink:href="gr12_lrg"/></fig><fig id="f0065"><label>Fig. 13</label><caption><p>Malaysia Deaths (RNN).</p></caption><graphic xlink:href="gr13_lrg"/></fig><fig id="f0070"><label>Fig. 14</label><caption><p>Malaysia Deaths (LSTM).</p></caption><graphic xlink:href="gr14_lrg"/></fig><fig id="f0075"><label>Fig. 15</label><caption><p>Morocco cases (RNN).</p></caption><graphic xlink:href="gr15_lrg"/></fig><fig id="f0080"><label>Fig. 16</label><caption><p>Morocco cases (LSTM).</p></caption><graphic xlink:href="gr16_lrg"/></fig><fig id="f0085"><label>Fig. 17</label><caption><p>Morocco Deaths (RNN).</p></caption><graphic xlink:href="gr17_lrg"/></fig><fig id="f0090"><label>Fig. 18</label><caption><p>Morocco Deaths (LSTM).</p></caption><graphic xlink:href="gr18_lrg"/></fig></p>
            </sec>
            <sec id="s0055">
              <label>8</label>
              <title>Discussion</title>
              <p id="p0190">According to the results obtained in the previous section, it became clear to us that the technique used in the proposed prediction model (LSTM) achieved an accuracy of 98.58%, and this result is better than the second model (RNN) where there was an improvement in accuracy by 5.13% and by comparing the results of the proposed model with other studies, this can be put down to several reasons.<list list-type="simple" id="l0020"><list-item id="o0060"><label>•</label><p id="p0195">Gradient vanishing and exploding problems.</p></list-item><list-item id="o0065"><label>•</label><p id="p0200">Training RNN is a very difficult task.</p></list-item><list-item id="o0070"><label>•</label><p id="p0205">It cannot process very long sequences if using <italic>tanh</italic> or <italic>relu</italic> as an activation function <xref rid="b0145" ref-type="bibr">[29]</xref>.</p></list-item></list>
</p>
              <p id="p0210">Also, we found that the proposed LSTM model achieved better results, and this was due to the presence of three types of memory, the first - the Input Gate: decides which values from the input to update the memory state (take the input from tanh and input weight and apply the Sigmoid activation, then the output 0 or 1). Second, the Forget Gate decides what information to throw away from the block. The third is the Output Gate that decides what to output based on input and the memory of the block.</p>
              <p id="p0215">To improve the forecast results and what was concluded during the analysis, we noticed through the literature survey that the process of removing noise in any data depends on time (time series), as many researchers had not paid specific attention to this and ignored this step, and accordingly, some inaccurate results may appear. This caught our attention and prompted us to use the exponential moving average technique to get rid of the confusion in the data, and the results of the experiments showed better accuracy.</p>
            </sec>
            <sec id="s0060">
              <label>9</label>
              <title>Conclusion</title>
              <p id="p0220">The COVID-19 pandemic has severely affected the lives of people in every country across the globe. This condition is getting worse in certain areas. Currently, there is no cure for this disease and even the odds of predicting the severity of this pandemic are small. Hence, deep learning models have been applied to make predictions about this disease. For this purpose, we used the time series datasets, collected from all COVID-19-affected countries, for proposing two DL-based prediction models. Two NN-based prediction models, RNN and LSTM, have been evaluated using time series data from three datasets. We used the Python language for developing and implementing the NNs. In step 1, we applied the simple RNN-based prediction model to the datasets. However, we noted that the results of the metrics varied for every execution, which led to an unstable outcome. Whenever implementing the RNN model, we noted different results, which led to a vanishing gradient point error. Thereafter, we applied the LSTM-NN process for developing another prediction model. Their results for the metrics were very promising and stable, which did not change even after numerous executions. The proposed LSTM prediction model showed a 98.53% accuracy with regards to the number of confirmed COVID-19 cases and resultant deaths. This model also decreased the vanishing gradient point error value. In future, we aim to extend this model for predicting the numbers of COVID-related cases and deaths in individual countries. We also wish to compare the DL-based and ML-based prediction models for the COVID-19 pandemic.</p>
            </sec>
            <sec id="s0065">
              <title>CRediT authorship contribution statement</title>
              <p id="p0225"><bold>Madini O. Alassafi:</bold> Conceptualization, Formal analysis, Investigation, Visualization, Methodology, Software, Writing - review &amp; editing, Writing – original draft. <bold>Mutasem Jarrah:</bold> Conceptualization, Formal analysis, Investigation, Visualization, Methodology, Software, Writing - review &amp; editing, Writing – original draft. <bold>Reem Alotaibi:</bold> Conceptualization, Formal analysis, Investigation, Visualization, Methodology, Software, Writing - review &amp; editing, Writing – original draft.</p>
            </sec>
            <sec sec-type="COI-statement">
              <title>Declaration of Competing Interest</title>
              <p id="p0230">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
            </sec>
          </body>
          <back>
            <ref-list id="bi005">
              <title>References</title>
              <ref id="b0005">
                <label>1</label>
                <element-citation publication-type="journal" id="h0005">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hosseiny</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Kooraki</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Gholamrezanezhad</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Reddy</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Myers</surname>
                      <given-names>L.</given-names>
                    </name>
                  </person-group>
                  <article-title>Radiology perspective of coronavirus disease 2019 (COVID-19): lessons from severe acute respiratory syndrome and Middle East respiratory syndrome</article-title>
                  <source>Am. J. Roentgenol.</source>
                  <volume>214</volume>
                  <issue>5</issue>
                  <year>2020</year>
                  <fpage>1078</fpage>
                  <lpage>1082</lpage>
                  <pub-id pub-id-type="pmid">32108495</pub-id>
                </element-citation>
              </ref>
              <ref id="b0010">
                <label>2</label>
                <element-citation publication-type="book" id="h0010">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kumari</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Sood</surname>
                      <given-names>M.</given-names>
                    </name>
                  </person-group>
                  <part-title>Implementation of SimpleRNN and LSTMs based prediction model for coronavirus disease (Covid-19)</part-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Editor</surname>
                    </name>
                  </person-group>
                  <source>Book Implementation of SimpleRNN and LSTMs Based Prediction Model for Coronavirus Disease (Covid-19)</source>
                  <year>2021</year>
                  <publisher-name>IOP Publishing</publisher-name>
                  <comment>pp. 012015</comment>
                </element-citation>
              </ref>
              <ref id="b0015">
                <label>3</label>
                <element-citation publication-type="journal" id="h0015">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Jamal</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Shah</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Almarzooqi</surname>
                      <given-names>S.H.</given-names>
                    </name>
                    <name>
                      <surname>Aber</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Khawaja</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>El Abed</surname>
                      <given-names>R.</given-names>
                    </name>
                    <name>
                      <surname>Alkhatib</surname>
                      <given-names>Z.</given-names>
                    </name>
                    <name>
                      <surname>Samaranayake</surname>
                      <given-names>L.P.</given-names>
                    </name>
                  </person-group>
                  <article-title>Overview of transnational recommendations for COVID-19 transmission control in dental care settings</article-title>
                  <source>Oral Dis.</source>
                  <volume>27</volume>
                  <issue>S3</issue>
                  <year>2021</year>
                  <fpage>655</fpage>
                  <lpage>664</lpage>
                  <pub-id pub-id-type="pmid">32428372</pub-id>
                </element-citation>
              </ref>
              <ref id="b0020">
                <label>4</label>
                <element-citation publication-type="journal" id="h0020">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Apaydin</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Feizi</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Sattari</surname>
                      <given-names>M.T.</given-names>
                    </name>
                    <name>
                      <surname>Colak</surname>
                      <given-names>M.S.</given-names>
                    </name>
                    <name>
                      <surname>Shamshirband</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Chau</surname>
                      <given-names>K.-W.</given-names>
                    </name>
                  </person-group>
                  <article-title>Comparative analysis of recurrent neural network architectures for reservoir inflow forecasting</article-title>
                  <source>Water</source>
                  <volume>12</volume>
                  <issue>5</issue>
                  <year>2020</year>
                  <fpage>1500</fpage>
                  <pub-id pub-id-type="doi">10.3390/w12051500</pub-id>
                </element-citation>
              </ref>
              <ref id="b0025">
                <label>5</label>
                <mixed-citation publication-type="other" id="h0025">A. Agarwal, A. Mishra, P. Sharma, S. Jain, S. Ranjan, R. Manchanda, Using LSTM for the Prediction of Disruption in ADITYA Tokamak, arXiv preprint arXiv:2007.06230, 2020.</mixed-citation>
              </ref>
              <ref id="b0030">
                <label>6</label>
                <element-citation publication-type="journal" id="h0030">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Song</surname>
                      <given-names>X.</given-names>
                    </name>
                    <name>
                      <surname>Liu</surname>
                      <given-names>Y.</given-names>
                    </name>
                    <name>
                      <surname>Xue</surname>
                      <given-names>L.</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Jiang</surname>
                      <given-names>L.</given-names>
                    </name>
                    <name>
                      <surname>Cheng</surname>
                      <given-names>Z.</given-names>
                    </name>
                  </person-group>
                  <article-title>Time-series well performance prediction based on Long Short-Term Memory (LSTM) neural network model</article-title>
                  <source>J. Petrol. Sc. Eng.</source>
                  <volume>186</volume>
                  <year>2020</year>
                  <fpage>106682</fpage>
                  <pub-id pub-id-type="doi">10.1016/j.petrol.2019.106682</pub-id>
                </element-citation>
              </ref>
              <ref id="b0035">
                <label>7</label>
                <element-citation publication-type="journal" id="h0035">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Van Houdt</surname>
                      <given-names>G.</given-names>
                    </name>
                    <name>
                      <surname>Mosquera</surname>
                      <given-names>C.</given-names>
                    </name>
                    <name>
                      <surname>Nápoles</surname>
                      <given-names>G.</given-names>
                    </name>
                  </person-group>
                  <article-title>A review on the long short-term memory model</article-title>
                  <source>Artif. Intell. Rev.</source>
                  <volume>53</volume>
                  <issue>8</issue>
                  <year>2020</year>
                  <fpage>5929</fpage>
                  <lpage>5955</lpage>
                </element-citation>
              </ref>
              <ref id="b0040">
                <label>8</label>
                <element-citation publication-type="journal" id="h0040">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zhang</surname>
                      <given-names>R.</given-names>
                    </name>
                    <name>
                      <surname>Li</surname>
                      <given-names>G.</given-names>
                    </name>
                    <name>
                      <surname>Ma</surname>
                      <given-names>Z.</given-names>
                    </name>
                  </person-group>
                  <article-title>A deep learning based hybrid framework for day-ahead electricity price forecasting</article-title>
                  <source>IEEE Access</source>
                  <volume>8</volume>
                  <year>2020</year>
                  <fpage>143423</fpage>
                  <lpage>143436</lpage>
                </element-citation>
              </ref>
              <ref id="b0045">
                <label>9</label>
                <element-citation publication-type="journal" id="h0045">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kumar</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Goomer</surname>
                      <given-names>R.</given-names>
                    </name>
                    <name>
                      <surname>Singh</surname>
                      <given-names>A.K.</given-names>
                    </name>
                  </person-group>
                  <article-title>Long short term memory recurrent neural network (LSTM-RNN) based workload forecasting model for cloud datacenters</article-title>
                  <source>Procedia Comput. Sci.</source>
                  <volume>125</volume>
                  <year>2018</year>
                  <fpage>676</fpage>
                  <lpage>682</lpage>
                </element-citation>
              </ref>
              <ref id="b0050">
                <label>10</label>
                <element-citation publication-type="journal" id="h0050">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sagheer</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Kotb</surname>
                      <given-names>M.</given-names>
                    </name>
                  </person-group>
                  <article-title>Time series forecasting of petroleum production using deep LSTM recurrent networks</article-title>
                  <source>Neurocomputing</source>
                  <volume>323</volume>
                  <year>2019</year>
                  <fpage>203</fpage>
                  <lpage>213</lpage>
                </element-citation>
              </ref>
              <ref id="b0055">
                <label>11</label>
                <element-citation publication-type="journal" id="h0055">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Li</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Zhao</surname>
                      <given-names>D.</given-names>
                    </name>
                    <name>
                      <surname>Li</surname>
                      <given-names>Q.</given-names>
                    </name>
                  </person-group>
                  <article-title>‘A Framework for predicting network security situation based on the improved LSTM</article-title>
                  <source>EAI Endorsed Trans. Collab. Comput.</source>
                  <volume>4</volume>
                  <issue>13</issue>
                  <year>2020</year>
                  <fpage>165278</fpage>
                  <pub-id pub-id-type="doi">10.4108/eai.12-6-2020.165278</pub-id>
                </element-citation>
              </ref>
              <ref id="b0060">
                <label>12</label>
                <mixed-citation publication-type="other" id="h0060">J. Kim, H. Kim, The impact of activation functions applying to recurrent neural network on Intrusion Detection.</mixed-citation>
              </ref>
              <ref id="b0065">
                <label>13</label>
                <element-citation publication-type="journal" id="h0065">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zeroual</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Harrou</surname>
                      <given-names>F.</given-names>
                    </name>
                    <name>
                      <surname>Dairi</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Sun</surname>
                      <given-names>Y.</given-names>
                    </name>
                  </person-group>
                  <article-title>Deep learning methods for forecasting COVID-19 time-series data: a comparative study</article-title>
                  <source>Chaos, Solitons Fractals</source>
                  <volume>140</volume>
                  <year>2020</year>
                  <fpage>110121</fpage>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110121</pub-id>
                  <pub-id pub-id-type="pmid">32834633</pub-id>
                </element-citation>
              </ref>
              <ref id="b0070">
                <label>14</label>
                <element-citation publication-type="journal" id="h0070">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Shastri</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Singh</surname>
                      <given-names>K.</given-names>
                    </name>
                    <name>
                      <surname>Kumar</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Kour</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Mansotra</surname>
                      <given-names>V.</given-names>
                    </name>
                  </person-group>
                  <article-title>Time series forecasting of Covid-19 using deep learning models: India-USA comparative case study</article-title>
                  <source>Chaos, Solitons Fractals</source>
                  <volume>140</volume>
                  <year>2020</year>
                  <fpage>110227</fpage>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110227</pub-id>
                  <pub-id pub-id-type="pmid">32843824</pub-id>
                </element-citation>
              </ref>
              <ref id="b0075">
                <label>15</label>
                <mixed-citation publication-type="other" id="h0075">M. Azarafza, M. Azarafza, J. Tanha, Covid-19 infection forecasting based on deep learning in iran, medRxiv, 2020.</mixed-citation>
              </ref>
              <ref id="b0080">
                <label>16</label>
                <element-citation publication-type="journal" id="h0080">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Abbasimehr</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Paki</surname>
                      <given-names>R.</given-names>
                    </name>
                  </person-group>
                  <article-title>Prediction of COVID-19 confirmed cases combining deep learning methods and Bayesian optimization</article-title>
                  <source>Chaos, Solitons Fractals</source>
                  <volume>142</volume>
                  <year>2021</year>
                  <fpage>110511</fpage>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110511</pub-id>
                  <pub-id pub-id-type="pmid">33281305</pub-id>
                </element-citation>
              </ref>
              <ref id="b0085">
                <label>17</label>
                <element-citation publication-type="journal" id="h0085">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Wang</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Zheng</surname>
                      <given-names>X.</given-names>
                    </name>
                    <name>
                      <surname>Ai</surname>
                      <given-names>G.</given-names>
                    </name>
                    <name>
                      <surname>Liu</surname>
                      <given-names>D.</given-names>
                    </name>
                    <name>
                      <surname>Zhu</surname>
                      <given-names>B.</given-names>
                    </name>
                  </person-group>
                  <article-title>‘Time series prediction for the epidemic trends of COVID-19 using the improved LSTM deep learning method: Case studies in Russia, Peru and Iran</article-title>
                  <source>Chaos, Solitons Fractals</source>
                  <volume>140</volume>
                  <year>2020</year>
                  <fpage>110214</fpage>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110214</pub-id>
                  <pub-id pub-id-type="pmid">32839643</pub-id>
                </element-citation>
              </ref>
              <ref id="b0090">
                <label>18</label>
                <element-citation publication-type="journal" id="h0090">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Shahid</surname>
                      <given-names>F.</given-names>
                    </name>
                    <name>
                      <surname>Zameer</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Muneeb</surname>
                      <given-names>M.</given-names>
                    </name>
                  </person-group>
                  <article-title>‘Predictions for COVID-19 with deep learning models of LSTM, GRU and Bi-LSTM</article-title>
                  <source>Chaos, Solitons Fractals</source>
                  <volume>140</volume>
                  <year>2020</year>
                  <fpage>110212</fpage>
                  <pub-id pub-id-type="doi">10.1016/j.chaos.2020.110212</pub-id>
                  <pub-id pub-id-type="pmid">32839642</pub-id>
                </element-citation>
              </ref>
              <ref id="b0095">
                <label>19</label>
                <element-citation publication-type="journal" id="h0095">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Kim</surname>
                      <given-names>M.H.</given-names>
                    </name>
                    <name>
                      <surname>Kim</surname>
                      <given-names>J.H.</given-names>
                    </name>
                    <name>
                      <surname>Lee</surname>
                      <given-names>K.</given-names>
                    </name>
                    <name>
                      <surname>Gim</surname>
                      <given-names>G.-Y.</given-names>
                    </name>
                  </person-group>
                  <article-title>The prediction of COVID-19 using LSTM algorithms</article-title>
                  <source>Int. J. Networked Distrib. Comput.</source>
                  <volume>9</volume>
                  <issue>1</issue>
                  <year>2021</year>
                  <fpage>19</fpage>
                  <pub-id pub-id-type="doi">10.2991/ijndc.k.201218.003</pub-id>
                </element-citation>
              </ref>
              <ref id="b0100">
                <label>20</label>
                <element-citation publication-type="journal" id="h0100">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Miao</surname>
                      <given-names>K.-C.</given-names>
                    </name>
                    <name>
                      <surname>Han</surname>
                      <given-names>T.-T.</given-names>
                    </name>
                    <name>
                      <surname>Yao</surname>
                      <given-names>Y.-Q.</given-names>
                    </name>
                    <name>
                      <surname>Lu</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Chen</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>B.</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>J.</given-names>
                    </name>
                  </person-group>
                  <article-title>Application of LSTM for short term fog forecasting based on meteorological elements</article-title>
                  <source>Neurocomputing</source>
                  <volume>408</volume>
                  <year>2020</year>
                  <fpage>285</fpage>
                  <lpage>291</lpage>
                </element-citation>
              </ref>
              <ref id="b0105">
                <label>21</label>
                <element-citation publication-type="journal" id="h0105">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hu</surname>
                      <given-names>K.</given-names>
                    </name>
                    <name>
                      <surname>Huang</surname>
                      <given-names>Y.</given-names>
                    </name>
                    <name>
                      <surname>Huang</surname>
                      <given-names>W.</given-names>
                    </name>
                    <name>
                      <surname>Tan</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Chen</surname>
                      <given-names>Z.</given-names>
                    </name>
                    <name>
                      <surname>Zhong</surname>
                      <given-names>Z.</given-names>
                    </name>
                    <name>
                      <surname>Li</surname>
                      <given-names>X.</given-names>
                    </name>
                    <name>
                      <surname>Zhang</surname>
                      <given-names>Y.</given-names>
                    </name>
                    <name>
                      <surname>Gao</surname>
                      <given-names>X.</given-names>
                    </name>
                  </person-group>
                  <article-title>Deep supervised learning using self-adaptive auxiliary loss for COVID-19 diagnosis from imbalanced CT images</article-title>
                  <source>Neurocomputing</source>
                  <volume>458</volume>
                  <year>2021</year>
                  <fpage>232</fpage>
                  <lpage>245</lpage>
                  <pub-id pub-id-type="pmid">34121811</pub-id>
                </element-citation>
              </ref>
              <ref id="b0110">
                <label>22</label>
                <element-citation publication-type="journal" id="h0110">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Wu</surname>
                      <given-names>C.-T.</given-names>
                    </name>
                    <name>
                      <surname>Chang</surname>
                      <given-names>H.-T.</given-names>
                    </name>
                    <name>
                      <surname>Wu</surname>
                      <given-names>C.-Y.</given-names>
                    </name>
                    <name>
                      <surname>Chen</surname>
                      <given-names>S.-W.</given-names>
                    </name>
                    <name>
                      <surname>Huang</surname>
                      <given-names>S.-Y.</given-names>
                    </name>
                    <name>
                      <surname>Huang</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Pan</surname>
                      <given-names>Y.-T.</given-names>
                    </name>
                    <name>
                      <surname>Bradbury</surname>
                      <given-names>P.</given-names>
                    </name>
                    <name>
                      <surname>Chou</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Yen</surname>
                      <given-names>H.-W.</given-names>
                    </name>
                  </person-group>
                  <article-title>Machine learning recommends affordable new Ti alloy with bone-like modulus</article-title>
                  <source>Mater. Today</source>
                  <volume>34</volume>
                  <year>2020</year>
                  <fpage>41</fpage>
                  <lpage>50</lpage>
                </element-citation>
              </ref>
              <ref id="b0115">
                <label>23</label>
                <mixed-citation publication-type="other" id="h0115">H. Bansal, G. Bhatt, P. Malhotra, Systematic Generalization in Neural Networks-based Multivariate Time Series Forecasting Models, arXiv preprint arXiv:2102.05602, 2021.</mixed-citation>
              </ref>
              <ref id="b0120">
                <label>24</label>
                <mixed-citation publication-type="other" id="h0120">European Centre for Disease Prevention and Control. &lt;<ext-link ext-link-type="uri" xlink:href="https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide" id="ir015">https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide</ext-link>&gt;, (last accessed on 26/9/2021).</mixed-citation>
              </ref>
              <ref id="b0125">
                <label>25</label>
                <mixed-citation publication-type="other" id="h0125">R. Chandra, A. Jain,D.S. Chauhan, Deep learning via LSTM models for COVID-19 infection forecasting in India, arXiv preprint arXiv:2101.11881, 2021.</mixed-citation>
              </ref>
              <ref id="b0130">
                <label>26</label>
                <element-citation publication-type="book" id="h0130">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lin</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Tian</surname>
                      <given-names>H.</given-names>
                    </name>
                  </person-group>
                  <part-title>Short-term metro passenger flow prediction based on random forest and LSTM’</part-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Editor</surname>
                    </name>
                  </person-group>
                  <source>Book Short-Term Metro Passenger Flow Prediction Based on Random Forest and LSTM</source>
                  <year>2020</year>
                  <publisher-name>IEEE</publisher-name>
                  <fpage>2520</fpage>
                  <lpage>2526</lpage>
                </element-citation>
              </ref>
              <ref id="b0135">
                <label>27</label>
                <element-citation publication-type="book" id="h0135">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Datta</surname>
                      <given-names>R.K.</given-names>
                    </name>
                    <name>
                      <surname>Sajid</surname>
                      <given-names>S.W.</given-names>
                    </name>
                    <name>
                      <surname>Moon</surname>
                      <given-names>M.H.</given-names>
                    </name>
                    <name>
                      <surname>Abedin</surname>
                      <given-names>M.Z.</given-names>
                    </name>
                  </person-group>
                  <part-title>Foreign currency exchange rate prediction using bidirectional long short term memory</part-title>
                  <source>The Big Data-Driven Digital Economy Artificial and Computational Intelligence</source>
                  <year>2021</year>
                  <publisher-name>Springer</publisher-name>
                  <fpage>213</fpage>
                  <lpage>227</lpage>
                </element-citation>
              </ref>
              <ref id="b0140">
                <label>28</label>
                <element-citation publication-type="book" id="h0140">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Yadav</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Bharadwaj</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Bhatt</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Rawal</surname>
                      <given-names>A.</given-names>
                    </name>
                  </person-group>
                  <part-title>Question–answer system on episodic data using recurrent neural networks (RNN)</part-title>
                  <source>Data Management Analytics and Innovation</source>
                  <year>2020</year>
                  <publisher-name>Springer</publisher-name>
                  <fpage>555</fpage>
                  <lpage>568</lpage>
                </element-citation>
              </ref>
              <ref id="b0145">
                <label>29</label>
                <element-citation publication-type="book" id="h0145">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Ribeiro</surname>
                      <given-names>A.H.</given-names>
                    </name>
                    <name>
                      <surname>Tiels</surname>
                      <given-names>K.</given-names>
                    </name>
                    <name>
                      <surname>Aguirre</surname>
                      <given-names>L.A.</given-names>
                    </name>
                    <name>
                      <surname>Schön</surname>
                      <given-names>T.</given-names>
                    </name>
                  </person-group>
                  <part-title>Beyond exploding and vanishing gradients: analysing RNN training using attractors and smoothness</part-title>
                  <person-group person-group-type="editor">
                    <name>
                      <surname>Editor</surname>
                    </name>
                  </person-group>
                  <source>Book Beyond Exploding and Vanishing Gradients: Analysing RNN Training using Attractors and Smoothness</source>
                  <year>2020</year>
                  <publisher-name>PMLR</publisher-name>
                  <fpage>2370</fpage>
                  <lpage>2380</lpage>
                </element-citation>
              </ref>
            </ref-list>
            <bio>
              <graphic xlink:href="fx1_lrg"/>
              <p><bold>Dr. Madini O. Alassafi</bold> received his B.S. degree in Computer Science from King Abdulaziz University, Saudi Arabia in 2006, and received M.S. degree in Computer Science from California Lutheran University, United State of America in 2013. He has been awarded the PhD qualification in “Security Cloud Computing” in February 2018 from University of Southampton, United Kingdom. He is currently work as an assistant professor of Information Technology department in the Faculty of Computing and Information Technology at King Abdulaziz University. His research interests span mainly around Cloud Computing and Security, Distributed Systems, Internet of Things (IoT) Security issues, Cloud Security Adoption, Risks, Cloud Migration Project Management, Cloud of Things and Security Threats. He is now Vice dean of Faculty of Computing and Information Technology at King Abdulaziz University, Jeddah, Saudi Arabia.</p>
            </bio>
            <bio>
              <graphic xlink:href="fx2_lrg"/>
              <p><bold>Dr. Mutasem Jarrah</bold> is currently an Assistant Professor in the Faculty of Computing and Information Technology. He received a B.S. from Philadelphia university in computer science - Jordan and an M.S. from the AL Balqa Applied university, in the Fuzzy logic thesis track. He received his Ph.D. from UTM in stock market prediction based on deep learning and news. His research interests span mainly Deep Learning, Machine Learning, Predictions, Classification, Regression and Time Series. <ext-link ext-link-type="uri" xlink:href="https://scholar.google.com/citations?hl=en%26user=DSlWGXQAAAAJ%26view_op=list_works%26sortby=pubdate" id="ir020">https://scholar.google.com/citations?hl=en&amp;user=DSlWGXQAAAAJ&amp;view_op=list_works&amp;sortby=pubdate</ext-link>.</p>
            </bio>
            <bio>
              <p><bold>Dr. Reem Alotaibi</bold> is an assistant professor at the Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia. Currently, she is the supervisor of the Information Technology department. Dr.Alotaibi received her PhD in computer science from University of Bristol, Bristol, U.K., in 2017. During 2017-2018 she was a visiting lecturer at the Intelligent Systems Laboratory, University of Bristol. Her research interests include Artificial Intelligence, Machine earning, Data mining and Crowd management. Dr. Alotaibi’s research has been funded by several sources in Saudi Arabia including Deputyship for Research &amp; Innovation, Ministry of Education, King Abdulaziz City for Science and Technology (KACST) and Deanship of Scientifc Research (DSR), King Abdulaziz University.</p>
            </bio>
            <ack id="ak005">
              <title>Acknowledgment</title>
              <p id="p0235">The authors extend their appreciation to the Deputyship for Research &amp; Innovation, Ministry of Education in Saudi Arabia for funding this research work through the project number IFPHI-157-612-2020 and King Abdulaziz University, DSR, Jeddah, Saudi Arabia.</p>
            </ack>
            <fn-group>
              <fn id="fn1">
                <label>1</label>
                <p id="np005"><ext-link ext-link-type="uri" xlink:href="https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide" id="ir005"><underline>https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide</underline></ext-link>.</p>
              </fn>
              <fn id="fn2">
                <label>2</label>
                <p id="np010"><ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset/version/151" id="ir010"><underline>https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset/version/151</underline></ext-link>.</p>
              </fn>
            </fn-group>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
