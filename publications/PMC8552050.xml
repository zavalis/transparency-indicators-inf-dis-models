<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2022-03-11T00:47:30Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:8552050" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:8552050</identifier>
        <datestamp>2021-11-09</datestamp>
        <setSpec>wopenres</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" dtd-version="1.3" xml:lang="en" article-type="research-article">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Wellcome Open Res</journal-id>
              <journal-id journal-id-type="iso-abbrev">Wellcome Open Res</journal-id>
              <journal-title-group>
                <journal-title>Wellcome Open Research</journal-title>
              </journal-title-group>
              <issn pub-type="epub">2398-502X</issn>
              <publisher>
                <publisher-name>F1000 Research Limited</publisher-name>
                <publisher-loc>London, UK</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC8552050</article-id>
              <article-id pub-id-type="pmcid">PMC8552050</article-id>
              <article-id pub-id-type="pmc-uid">8552050</article-id>
              <article-id pub-id-type="pmid">34761122</article-id>
              <article-id pub-id-type="doi">10.12688/wellcomeopenres.16466.2</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Software Tool Article</subject>
                </subj-group>
                <subj-group>
                  <subject>Articles</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Reproducible parallel inference and simulation of stochastic state space models using odin, dust, and mcstate</article-title>
                <fn-group content-type="pub-status">
                  <fn>
                    <p>[version 2; peer review: 2 approved]</p>
                  </fn>
                </fn-group>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>FitzJohn</surname>
                    <given-names>Richard G.</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Conceptualization</role>
                  <role content-type="http://credit.niso.org/">Data Curation</role>
                  <role content-type="http://credit.niso.org/">Investigation</role>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Supervision</role>
                  <role content-type="http://credit.niso.org/">Validation</role>
                  <role content-type="http://credit.niso.org/">Visualization</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Knock</surname>
                    <given-names>Edward S.</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Conceptualization</role>
                  <role content-type="http://credit.niso.org/">Data Curation</role>
                  <role content-type="http://credit.niso.org/">Investigation</role>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Validation</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Whittles</surname>
                    <given-names>Lilith K.</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Conceptualization</role>
                  <role content-type="http://credit.niso.org/">Data Curation</role>
                  <role content-type="http://credit.niso.org/">Investigation</role>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Validation</role>
                  <role content-type="http://credit.niso.org/">Visualization</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8913-0391</contrib-id>
                  <xref rid="a1" ref-type="aff">1</xref>
                  <xref rid="a2" ref-type="aff">2</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Perez-Guzman</surname>
                    <given-names>Pablo N.</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Data Curation</role>
                  <role content-type="http://credit.niso.org/">Investigation</role>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Validation</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Bhatia</surname>
                    <given-names>Sangeeta</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6525-101X</contrib-id>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Guntoro</surname>
                    <given-names>Fernando</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Watson</surname>
                    <given-names>Oliver J.</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2374-0741</contrib-id>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Whittaker</surname>
                    <given-names>Charles</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Ferguson</surname>
                    <given-names>Neil M.</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Funding Acquisition</role>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Supervision</role>
                  <role content-type="http://credit.niso.org/">Validation</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Cori</surname>
                    <given-names>Anne</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Data Curation</role>
                  <role content-type="http://credit.niso.org/">Funding Acquisition</role>
                  <role content-type="http://credit.niso.org/">Investigation</role>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Supervision</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Baguelin</surname>
                    <given-names>Marc</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Conceptualization</role>
                  <role content-type="http://credit.niso.org/">Data Curation</role>
                  <role content-type="http://credit.niso.org/">Funding Acquisition</role>
                  <role content-type="http://credit.niso.org/">Investigation</role>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Supervision</role>
                  <role content-type="http://credit.niso.org/">Validation</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="a1" ref-type="aff">1</xref>
                  <xref rid="a3" ref-type="aff">3</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Lees</surname>
                    <given-names>John A.</given-names>
                  </name>
                  <role content-type="http://credit.niso.org/">Conceptualization</role>
                  <role content-type="http://credit.niso.org/">Data Curation</role>
                  <role content-type="http://credit.niso.org/">Formal Analysis</role>
                  <role content-type="http://credit.niso.org/">Investigation</role>
                  <role content-type="http://credit.niso.org/">Methodology</role>
                  <role content-type="http://credit.niso.org/">Software</role>
                  <role content-type="http://credit.niso.org/">Supervision</role>
                  <role content-type="http://credit.niso.org/">Validation</role>
                  <role content-type="http://credit.niso.org/">Visualization</role>
                  <role content-type="http://credit.niso.org/">Writing – Original Draft Preparation</role>
                  <role content-type="http://credit.niso.org/">Writing – Review &amp; Editing</role>
                  <xref rid="c1" ref-type="corresp">a</xref>
                  <xref rid="a1" ref-type="aff">1</xref>
                </contrib>
                <aff id="a1"><label>1</label>MRC Centre for Global Infectious Disease Analysis; and the Abdul Latif Jameel Institute for Disease and Emergency Analytics (J-IDEA), School of Public Health, Imperial College London, London, W2 1PG, UK</aff>
                <aff id="a2"><label>2</label>Modelling and Economics Unit, National Infection Service, Public Health England, London, UK</aff>
                <aff id="a3"><label>3</label>Department of Infectious Disease Epidemiology, London School of Hygiene &amp; Tropical Medicine, London, WC1E 8HT, UK</aff>
              </contrib-group>
              <author-notes>
                <corresp id="c1">
                  <label>a</label>
                  <email xlink:href="mailto:j.lees@imperial.ac.uk">j.lees@imperial.ac.uk</email>
                </corresp>
                <fn fn-type="COI-statement">
                  <p>No competing interests were disclosed.</p>
                </fn>
              </author-notes>
              <pub-date pub-type="epub">
                <day>10</day>
                <month>6</month>
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2020</year>
              </pub-date>
              <volume>5</volume>
              <elocation-id>288</elocation-id>
              <history>
                <date date-type="accepted">
                  <day>7</day>
                  <month>6</month>
                  <year>2021</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>Copyright: © 2021 FitzJohn RG et al.</copyright-statement>
                <copyright-year>2021</copyright-year>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p>This is an open access article distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
                </license>
              </permissions>
              <self-uri content-type="pdf" xlink:href="wellcomeopenres-5-18728.pdf"/>
              <abstract>
                <p>State space models, including compartmental models, are used to model physical, biological and social phenomena in a broad range of scientific fields. A common way of representing the underlying processes in these models is as a system of stochastic processes which can be simulated forwards in time. Inference of model parameters based on observed time-series data can then be performed using sequential Monte Carlo techniques. However, using these methods for routine inference problems can be made difficult due to various engineering considerations: allowing model design to change in response to new data and ideas, writing model code which is highly performant, and incorporating all of this with up-to-date statistical techniques. Here, we describe a suite of packages in the R programming language designed to streamline the design and deployment of state space models, targeted at infectious disease modellers but suitable for other domains. Users describe their model in a familiar domain-specific language, which is converted into parallelised C++ code. A fast, parallel, reproducible random number generator is then used to run large numbers of model simulations in an efficient manner. We also provide standard inference and prediction routines, though the model simulator can be used directly if these do not meet the user’s needs. These packages provide guarantees on reproducibility and performance, allowing the user to focus on the model itself, rather than the underlying computation. The ability to automatically generate high-performance code that would be tedious and time-consuming to write and verify manually, particularly when adding further structure to compartments, is crucial for infectious disease modellers. Our packages have been critical to the development cycle of our ongoing real-time modelling efforts in the COVID-19 pandemic, and have the potential to do the same for models used in a number of different domains.</p>
              </abstract>
              <kwd-group kwd-group-type="author">
                <kwd>Epidemiology</kwd>
                <kwd>Infectious diseases</kwd>
                <kwd>Compartmental models</kwd>
                <kwd>State space model</kwd>
                <kwd>Particle filter</kwd>
                <kwd>SMC</kwd>
                <kwd>MCMC</kwd>
              </kwd-group>
              <funding-group>
                <award-group id="fund-1">
                  <funding-source>National Institute for Health Research</funding-source>
                  <award-id>NIHR200908</award-id>
                </award-group>
                <award-group id="fund-2" xlink:href="http://dx.doi.org/10.13039/501100007155">
                  <funding-source>Medical Research Council</funding-source>
                  <award-id>MR/R015600/1</award-id>
                </award-group>
                <award-group id="fund-3">
                  <funding-source>UK Foreign, Commonwealth &amp; Development Office</funding-source>
                  <award-id>MR/R015600/1</award-id>
                </award-group>
                <award-group id="fund-4" xlink:href="http://dx.doi.org/10.13039/100004440">
                  <funding-source>Wellcome</funding-source>
                  <award-id>219699/Z/19/Z</award-id>
                </award-group>
                <funding-statement>JAL was funded by Wellcome [219699]. This work was also supported by the NIHR HPRU in Modelling and Health Economics, a partnership between PHE, Imperial College London and LSHTM (grant code NIHR200908); and acknowledges funding from the MRC Centre for Global Infectious Disease Analysis (reference MR/R015600/1), jointly funded by the UK Medical Research Council (MRC) and the UK Foreign, Commonwealth \&amp; Development Office (FCDO), under the MRC/FCDO Concordat agreement and is also part of the EDCTP2 programme supported by the European Union. The views expressed are those of the authors and not necessarily those of the United Kingdom (UK) Department of Health and Social Care, the National Health Service, the National Institute for Health Research (NIHR), or Public Health England (PHE).</funding-statement>
                <funding-statement>
                  <italic toggle="yes">The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</italic>
                </funding-statement>
              </funding-group>
            </article-meta>
            <notes notes-type="version-changes">
              <sec sec-type="version-changes">
                <label>Revised</label>
                <title>Amendments from Version 1</title>
                <p>We have added four new pieces of functionality to the code suggested by the reviewers: - The iterated filtering algorithm of Ionides et al. - More flexible parallelisation over both chains and particles in pMCMC. - The ability to add arbitrary C++ code snippets to odin models. - A simulate function, to more easily run models across a whole time series. We document these features both in the updated text, and in a number of new package vignettes. In the text, we now include the sections on maximum likelihood inference (rather than entirely operating within a Bayesian framework), and a discussion on how to use these techniques for model criticism. We have also added a section on performing prior predictive checks within our framework. Finally, we have made numerous small changes to improve the clarity of the manuscript, including a new figure which gives an overview of our packages and how they operate together.</p>
              </sec>
            </notes>
          </front>
          <body>
            <sec sec-type="intro">
              <title>Introduction</title>
              <p>To mathematically model a physical or biological process one must develop and test a model, combine it with potentially noisy or poor quality data, and then produce high-quality reproducible results in a computationally efficient manner. This constitutes a multi-disciplinary challenge
<sup><xref rid="ref-1" ref-type="bibr">1</xref>,
<xref rid="ref-2" ref-type="bibr">2</xref></sup>. Frameworks which automate common computational and statistical methods can facilitate some of the complex steps in the process, and come with guarantees of efficiency and reproducibility
<sup><xref rid="ref-3" ref-type="bibr">3</xref>,
<xref rid="ref-4" ref-type="bibr">4</xref></sup> – a necessity in modern science, particularly when this science is used in real time to support policy making
<sup><xref rid="ref-5" ref-type="bibr">5</xref>–
<xref rid="ref-7" ref-type="bibr">7</xref>
</sup>. </p>
              <p>When designing these frameworks, it is generally fair to assume that a typical multi-disciplinary modeller is a domain expert and technically minded, but should not have to become a software engineer in order to develop an efficient implementation
<sup><xref rid="ref-3" ref-type="bibr">3</xref></sup>. Therefore, as developers of computational frameworks, we should aim to lower the barriers of entry by using a programming language favoured by researchers in the targeted domain, designing a clear and well-documented application-programmer interface (API), and making installation, use and reuse as painless and portable as possible. We can enhance uptake by combining sensible software engineering choices with carefully designed statistical and computational methods. This make design advantages such as speed, unit-tested code and reproducible random number generation as broadly accessible as possible.</p>
              <p>With these aims in mind, we describe the development of three libraries in the R programming language
<sup><xref rid="ref-8" ref-type="bibr">8</xref></sup>, designed to make the implementation of state space models as easy and reliable as possible. R-like code in the odin domain-specific language (DSL) is automatically transpiled (converted between two high-level programming languages) into C++. This C++ code is then compiled into a dynamic library (loaded only when needed) with an R interface. The resulting code is portable, and the generated libraries are lightweight and computationally efficient. This procedure offers the performance and careful memory management of compiled code, without requiring the user to have any specialist programming knowledge. Additionally, we include an R package, mcstate, which provides routines for common inference and prediction tasks. Compiled models also link with functions directly callable from R, so users are free to develop more flexible uses and inference procedures using R programming. An overview of these packages and how they interact is shown in
<xref rid="f1" ref-type="fig">Figure 1</xref>. We provided detailed examples of applying these tools to simple stochastic epidemic models, both here and in the package documentation.</p>
              <fig position="float" fig-type="figure" id="f1">
                <label>Figure 1. </label>
                <caption>
                  <title>Overview of the odin.dust, dust and mcstate packages.</title>
                  <p>For a typical user, a model will be written in the odin DSL, and the odin.dust package used to convert this into a dust model (which is an R object). This object can be used directly with functions provided by the dust package to run the model forward across a time series. With simulated or observational data, the mcstate package can be used to fit the model to this data using various techniques based around sequential Monte Carlo (particle filters).</p>
                </caption>
                <graphic xlink:href="wellcomeopenres-5-18728-g0000" position="float"/>
              </fig>
              <p>As single-threaded code, our packages run at around the same speed to two existing high-performance packages with similar functionality, pomp
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup> and libBi
<sup><xref rid="ref-10" ref-type="bibr">10</xref></sup>. On top of this, we have paid particular attention to development of the odin DSL which makes models easy to develop and modify, a close interface with R which simplifies the flow of data in and out of models, and added efficient parallelisation which decreases runtimes while simulating stochastic models correctly.</p>
            </sec>
            <sec sec-type="methods">
              <title>Methods</title>
              <sec>
                <title>Implementation</title>
                <p>State space models relate input, output and state over time using a probabilistic model linking states at subsequent time steps, and can be used to model a broad range of processes. Below we describe how four major components of our framework, bundled as packages for the R programming language, can be used to implement these models. All of the packages require 100% code coverage of tests, and include unit tests designed by software engineers and integration testing (of entire analysis pipelines) designed by statisticians and epidemiologists. Code to reproduce this analysis and all of the plots in this paper can be found at
<ext-link xlink:href="https://github.com/mrc-ide/odin-dust-plots" ext-link-type="uri">https://github.com/mrc-ide/odin-dust-plots</ext-link>.</p>
              </sec>
              <sec>
                <title>odin – A DSL for R programmers to write efficient state space models</title>
                <p>Packages which allow users to implement their own model code straddle a difficult dichotomy: making models fast and efficient to use, and making models fast and efficient to develop. Using an intermediary DSL is one approach to this issue, also applied in the popular JAGS and stan packages, as this offers a bridge between the more familiar language style used to develop models, and the compiled languages preferred for running large models
<sup><xref rid="ref-11" ref-type="bibr">11</xref></sup>. Compared to writing directly in a compiled language, DSLs have the further advantage that we can design error messages which are domain specific, rather than the sometimes convoluted errors from compilers (which are necessary due to their generality). </p>
                <p>odin is a DSL we have been developing since 2016, and has been used to model both continuous and discrete time models. odin is syntactically similar to R, and by taking advantage of R’s ‘non-standard evaluation’
<sup><xref rid="ref-12" ref-type="bibr">12</xref></sup> presents users with a simple interface for describing sets of equations. The general approach of the package is that the user expresses their problems as a set of mathematical relationships, modelled as assignments to form a directed acyclic graph (DAG). odin then sorts that graph and transpiles the equations to code in a chosen target language. Users can therefore write their equations in any order, which is more similar to mathematical formalism than declarative programming. </p>
                <p>For use with ordinary differential equations (ODEs), odin transpiles to C code (
<ext-link xlink:href="https://mrc-ide.github.io/odin/" ext-link-type="uri">https://mrc-ide.github.io/odin/</ext-link>) or JavaScript (
<ext-link xlink:href="https://mrc-ide.github.io/odin.js" ext-link-type="uri">https://mrc-ide.github.io/odin.js</ext-link>). For the models in this paper, we focus on transpilation of discrete time stochastic models into C++ using a framework (dust) that we describe below. In both cases, odin has an R interface, allowing its standalone use, or inclusion in R packages.</p>
                <p>By eliminating logic and ‘general programming’ (such as defining types, writing loops), the models become relatively simple sets of mathematical truths that map closely to the scientific domain, yet remain efficient to solve. In addition to scalar relationships, odin provides a syntax designed to easily add structure to compartments - for example to represent age or transmission classes and the interaction between these without requiring explicitly written loops. Arrays representing structure classes are written implicitly with indices, meaning models can easily be extended. An example of adding age structure is shown in the Use Cases. </p>
                <p>Specific functions available to the user beyond basic arithmetic include the random number generation functions detailed below, and optimised sums over state items. We include most of the functions available in the Rmath library
<sup><xref rid="ref-8" ref-type="bibr">8</xref></sup> in odin, which are documented at
<ext-link xlink:href="https://mrc-ide.github.io/odin/articles/functions.html" ext-link-type="uri">https://mrc-ide.github.io/odin/articles/functions.html</ext-link>. A subset of these functions are currently available for dust, and we intend to continue to expand this support. If a required function is not available in odin, it is possible to write user-supplied C++ functions to be included in the model code. The only requirement for these functions is that they must return a scalar, and cannot modify the data they are passed. This is similar to the Csnippet approach taken by the pomp package.</p>
              </sec>
              <sec>
                <title>mcstate – An R package implementing common SMC inference techniques, using odin models</title>
                <p>The odin DSL gives modellers the ability to write a fast state space model in R, and interact with it in a number of fundamental ways. While some users may wish to implement their own inference techniques using these building blocks, we expect that most will use the standard methods we provide and test in the mcstate R package, as mcstate provides all the necessary routines for statistical inference from these models.</p>
                <p>The key additional programmatic elements that mcstate provides for state space modelling are the definition of some observed data, and an observation function, which defines the log-likelihood of the observed data given the underlying model state. As the observation function is written directly in R, the user is free to define this however they choose, as long as it accepts the model state and some data as arguments. This may therefore use the state history stored in R, for example to compute the change in sizes of compartments and take advantage of large library of built-in functions. Some typical observation functions are described in the Use Cases below.</p>
                <p>The mcstate package provides a particle filter implementation, also known as SMC (Sequential Monte Carlo)
<sup><xref rid="ref-13" ref-type="bibr">13</xref>,
<xref rid="ref-14" ref-type="bibr">14</xref></sup>, which enables efficient parameter inference with high-variance model runs. A dust model is run forwards in time for a number of particles (
<italic toggle="yes">n</italic>). At each step where observations are available these are compared to the data, and a likelihood weight computed for each particle. The
<italic toggle="yes">n</italic> particles at observation time step
<italic toggle="yes">j</italic> are then resampled with replacement, with probabilities corresponding to their likelihood weight, to select
<italic toggle="yes">n</italic> particles to be run to observation time step
<italic toggle="yes">j</italic>+1
<sup><xref rid="ref-15" ref-type="bibr">15</xref></sup>. This SMC process runs the update function for all particles, resamples, and continues until the final observation is reached. This final state is sometimes referred to as a ‘nowcast’. A function is provided to convert observational data into the correct format for the particle filter. </p>
                <p>With this technique for combining potentially stochastic observations with a stochastic model, a marginal likelihood given model parameters can be produced. We can use the log-likelihood derived from the particle filter to perform Bayesian inference on model parameters. To do this, mcstate uses Markov Chain Monte Carlo (MCMC) over runs of the particles filter, known as pMCMC
<sup><xref rid="ref-16" ref-type="bibr">16</xref>,
<xref rid="ref-17" ref-type="bibr">17</xref></sup>. Currently mcstate supports standard Metropolis-Hastings MCMC:
<italic toggle="yes">m
<sub>c</sub>
</italic> independent chains are run, with care taken to ensure independent random number streams. The user provides prior distributions as functions in R, and a variance-covariance matrix for the proposals. Proposals at each step are drawn from a multivariate normal distribution, are reflected if outside of a specified minimum or maximum, and discretised if required. Alternatively, users can choose to apply iterated filtering, known as IF2
<sup><xref rid="ref-18" ref-type="bibr">18</xref></sup>. This algorithm moves parameters in a random walk at each step in the time series, using the same weighting as the particle filter to select parameters for the next step. Over the course of the time series, and multiple iterations of this algorithm, this maximises the likelihood, and parameters approach values most compatible with the data.</p>
                <p>We also support forecasting from the final observation position. The estimate of the posterior distribution produced by an MCMC run is sampled from by sampling particles with replacement. These runs extend the original model run by applying to state update functions until the time has reached the required length, picking up from the final random number generator (RNG) state of the particle. If further forecasts are required, a new RNG state is seeded from R’s internal state, to avoid producing identical forecasts from the same streams of pseudorandom numbers.</p>
              </sec>
              <sec>
                <title>dust – A C++ template library for driving parallel stochastic models from R</title>
                <p>The above statistical techniques are computationally demanding, particularly as models become more complex, and to run them in a reasonable time-frame we needed an efficient engine to run stochastic models. Noting that between each observation step every particle is independent, we designed a system that could simulate the particles in parallel, so that we could take advantage of the increasing availability of multi-core CPUs. Our solution is implemented in the R package dust. The dust code itself is written in C++ with an R interface, which being a compiled language is typically faster to execute, and allows more careful memory management. To interface with dust, users must provide an update function, which is the core of the model, and we provide some examples below. While the user can write this in C++, most easily by modifying one of the included model examples, we expect most users to use odin.dust to generate this code automatically. </p>
                <p>dust uses two main abstractions to represent and run state space models: Particle and Dust. A Particle object is a single trajectory simulated from the model and a Dust object is a collection of
<italic toggle="yes">n
<sub>P</sub>
</italic> Particles with the same model parameters and initial conditions, but different trajectories due to the inherent stochasticity of the system being simulated. Internally, Particles within a Dust object can be shuffled and sampled, to support particle filtering methods. A Dust object can be run forward in discrete steps, moving all Particles forward the same number of steps. This is the main computation in dust, and is parallelised on up to
<italic toggle="yes">n
<sub>P</sub>
</italic> CPU cores using OpenMP
<sup><xref rid="ref-19" ref-type="bibr">19</xref></sup>. Using the static schedule to evenly distribute particles across cores gave close to linear increase in performance with the number of cores with long running models described in the Use Cases (
<xref rid="f2" ref-type="fig">Figure 2</xref>). We designed dust with these abstractions as this design has the advantage of having a high-level R interface directly designed to work with particle filters, but still allowing control of individual particles in the lower-level C++ interface to develop new methods which operate on trajectories in different ways. This was useful when developing a ‘simulate’ method to run projections forward where every particle has a different set of parameters. For a technical audience, the “design” vignette describes why these decisions were made from a developer perspective.</p>
                <fig position="float" fig-type="figure" id="f2">
                  <label>Figure 2. </label>
                  <caption>
                    <title>Speedup of dust simulations as number of threads increases, on a log-log scale.</title>
                    <p>Models are described in the Use Cases. Speedup is defined as the ratio of wall time (total program time) taken to the wall time using a single thread. Here, a straight line along y = x would signify reaching the theoretical optimum of 100% parallelisation efficiency. The closer to the straight line, the closer to full efficiency at that number of cores. The models were run for 5 × 10
<sup>5 </sup> steps using
<italic toggle="yes">n
<sub>P</sub>
</italic> = 10
<sup>3 </sup> to artificially increase the amount of computation. The SIRS model has an additional R to S transition to make the infection endemic, otherwise the infection dies out, and no significant processing is used. The ‘SIR (short)’ model demonstrates a fall in performance for short running models, in this case with 10
<sup>3</sup> steps and
<italic toggle="yes">n
<sub>P</sub>
</italic> = 10
<sup>2 </sup>. We also ran the SIRCOVID model inference with
<italic toggle="yes">n
<sub>P</sub>
</italic> = 10
<sup>2 </sup> for 10
<sup>3</sup> MCMC steps. The consistent speedup demonstrates that the multicore use is effective, even when running a full pipeline with a particle filter and evaluation of a log-likelihood in R.</p>
                  </caption>
                  <graphic xlink:href="wellcomeopenres-5-18728-g0001" position="float"/>
                </fig>
                <p>In addition, we tested the speedup of a large SEIR (susceptible-exposed-infected-recovered) model for COVID-19 transmission in the UK, implemented using the
<monospace>odin</monospace> DSL, using
<monospace>dust</monospace> and
<monospace>mcstate</monospace> to infer its parameters. Due to 19 age-classes which add structure to most of the model compartments, the model has around 1000 compartments in total. The computation time of running simulations of this model is therefore dominated by many random number draws, and so can be efficiently parallelised using the techniques described above. We confirmed this using a CPU profiler, finding that at least 61% of processing time being spent in the rbinom() function (described below). This dust model and its interface is named
<monospace>sircovid</monospace>
<sup><xref rid="ref-20" ref-type="bibr">20</xref></sup>, and its code and documentation can be found at
<ext-link xlink:href="https://mrc-ide.github.io/sircovid" ext-link-type="uri">https://mrc-ide.github.io/sircovid</ext-link>. Running with
<italic toggle="yes">n
<sub>P</sub>
</italic> = 100 for 2000 steps, one MCMC chain on a laptop took around 1 hour with a single core, and showed roughly linear speedup with number of cores when used for either extra particles or extra chains. </p>
                <p>On a personal computer, users can employ up to
<italic toggle="yes">p</italic> cores to run the
<italic toggle="yes">n
<sub>P</sub>
</italic> particles of dust objects, or use these cores to run the
<italic toggle="yes">m
<sub>c</sub>
</italic> chains of mcstate, as long as
<italic toggle="yes">n
<sub>P</sub>m
<sub>c</sub> &lt;</italic>=
<italic toggle="yes">p</italic>. On distributed infrastructure with disconnected nodes each with many cores, memory is shared on a node, but not between nodes. In this case, the optimal use of resources is typically to run
<italic toggle="yes">n
<sub>P</sub>
</italic> particles on a single node, using all
<italic toggle="yes">p</italic> of its cores. The
<italic toggle="yes">m
<sub>c</sub>
</italic> chains, or parameter sets, can be independently run on up to
<italic toggle="yes">m
<sub>c</sub>
</italic> separate nodes, and their results combined using the provided functions. In some cases, parallelisation over particles is less efficient than over whole particle filters, for example when varying initial conditions and RNG seeds, on operating systems with poor OpenMP performance, or when evaluating model likelihoods at over a range of parameters sets. This can easily be automated in the pMCMC by using multiple ‘workers’ in mcstate, to parallelise
<italic toggle="yes">m
<sub>c</sub>
</italic> chains first, then use remaining threads to parallelise particles within these. Further flexibility is available to parallelise particle filters over multiple nodes, and collect results at the end, so users can pick a parallelisation mode that is most efficient for their problem. This is detailed in the ‘parallelisation’ vignette in the mcstate package.</p>
                <p>The C++ source of the package exists largely as a header-only template library. This has the advantage that no platform-specific library code is needed for the generation of models, simplifying the installation process and giving wider support across operating systems and hardware architectures. Furthermore, compiling and optimising is always done using the whole model code in a single unit. The compilation is launched from within R, and once finished gives a shared object with R methods to run, shuffle and extract state from the underlying particles.</p>
                <p>If writing a model directly in C++ there are some minimal interface requirements, which constrain the types of model which can be run through dust. Specifically, the user must provide a model class to dust with the following functions:</p>
                <list list-type="bullet">
                  <list-item>
                    <p><monospace>initial()</monospace> – Loads data passed from R to set the initial state and model parameters.</p>
                  </list-item>
                  <list-item>
                    <p><monospace>size()</monospace> – Computes the size of the model state for a single particle (number of compartments).</p>
                  </list-item>
                  <list-item>
                    <p><monospace>update()</monospace> – Updates the model for a single timestep. This may only depend on the previous state i.e. it must be Markovian. The function has access to the model parameters, timestep and random number generator functions.</p>
                  </list-item>
                </list>
                <p>More flexible simulation runs than provided by mcstate, for example from running counterfactuals, are straightforwardly supported by direct use of the dust object in R, while providing alternative parameter sets.</p>
              </sec>
              <sec>
                <title>Random number generation</title>
                <p>Generating random numbers from common distributions is a cornerstone of designing the model update function for many epidemiological models. This is also true computationally – when profiling a complex compartmental model for COVID-19 transmission, we found that at least 61% of program time was spent computing random deviates. R’s default number generator is not able to operate in parallel, which meant that using the standard library functions for generating random deviates from common distributions was not an option. We therefore took particular care with the design of a parallel random number generator used by dust. </p>
                <p>Random number generation on a computer produces a stream of pseudorandom numbers, usually integers in a specified interval, which are uncorrelated, but deterministic given a set starting point (the ‘seed’). For stochastic model simulations there are two main considerations: running independent model realisations, and making results reproducible. Using the same seed for different particles will give identical results, and will break the assumptions of downstream inference methods
<sup><xref rid="ref-21" ref-type="bibr">21</xref></sup>. However, using the same seed for an entire set of particles is desirable, so results can be reproduced. We also wish for our RNG implementation to ‘play-fair’, which means that results are independent of the specific hardware used, and the degree of parallelisation
<sup><xref rid="ref-22" ref-type="bibr">22</xref></sup>. This is needed for scientific reproduciblity and effective debugging – knowing a change in results is attributable to a change in model, and not a change in the sequence of random number draws used to simulate the model is vital for model development. </p>
                <p>The simplest solution, which is the default in R, is to run particles serially with each subsequent particle continuing from a single random number stream. However, serial particles places a limit on parallelisability. A frequent way around this is to make
<italic toggle="yes">m</italic> RNGs for each parallel thread, and seed each one with a new but pre-specified seed. However, as the state space of the RNGs is highly non-linear and chaotic, it isn’t possible to predict at which point a given seed will enter the stream, shared between all RNGs with the same design. For even modest simulation lengths and levels of parallelism, this can lead to correlated streams of random numbers, again breaking downstream inference assumptions. </p>
                <p>One solution is to create
<italic toggle="yes">p</italic> RNGs which can be advanced or ‘jumped’ a set number of steps. If each thread’s RNG consumes
<italic toggle="yes">k</italic> random numbers, then advancing each RNG
<italic toggle="yes">p
<sub>i</sub>
</italic> by
<italic toggle="yes">ik</italic> steps before running will ensure independent streams for each process. If
<italic toggle="yes">k</italic> is not known, this becomes more difficult. The approach we follow here uses a new class of RNGs known as Xoshiro (XOR, shift, rotate)
<sup><xref rid="ref-23" ref-type="bibr">23</xref></sup>. These generate a stream of pseudorandom integers in the interval [0,2
<sup>64</sup>) with a period 2
<sup>256</sup>. Generation is very fast, but importantly also implements a
<monospace>jump()</monospace> function which advances the generator by 2
<sup>128 </sup>steps in a time comparable to a single random number draw. Applying this allows the initialisation of up to 2
<sup>128 </sup> RNGs, each capable of drawing a stream of up to 2
<sup>128 </sup>pseudorandom numbers before correlating. These concepts are summarised in
<xref rid="f3" ref-type="fig">Figure 3</xref>.</p>
                <fig position="float" fig-type="figure" id="f3">
                  <label>Figure 3. </label>
                  <caption>
                    <title>Top: parallel random number streams with the same seed are identical.</title>
                    <p>Middle: parallel random number streams with different streams can quickly become correlated. Bottom: using the
<monospace>jump()</monospace> function of the Xoshiro generator moves forward 2
<sup>128</sup> steps, giving evenly spaced, uncorrelated streams of random numbers.</p>
                  </caption>
                  <graphic xlink:href="wellcomeopenres-5-18728-g0002" position="float"/>
                </fig>
                <p>Random number streams should not vary based on the number of threads used in a specific run, and should instead always be reproducible from the same single seed. Therefore every particle
<italic toggle="yes">p</italic> has its own RNG, rather than every thread; this is feasible given the relatively small state (256 bits) used by Xoshiro compared with generators such as Mersenne Twister (2560 bits)
<sup><xref rid="ref-24" ref-type="bibr">24</xref></sup>. A single 64-bit integer seed is passed from R, with the remaining three chunks of 64-bits-of-state set pseudo-randomly from this using the splitmix64 algorithm
<sup><xref rid="ref-25" ref-type="bibr">25</xref></sup>. These 256 bits are used to set the initial state of a
<monospace>xoshiro256**</monospace> generator. The RNG state for particle
<italic toggle="yes">i</italic> begins with this state, after applying the
<monospace>jump()</monospace> function
<italic toggle="yes">i</italic> times. </p>
                <p>Many off-the-shelf parallel random number generators are aimed at repeated generation from a distribution with the same parameters, including those in the C++ standard library. This is ill-suited to state space models, where distribution parameters typically change between every generation, and between every particle. The TensorFlow
<sup><xref rid="ref-26" ref-type="bibr">26</xref></sup> code base contains suitable implementations, but would be a large and complex dependency, difficult to make fully compatible with R. Therefore, we added code which uses the Xoshiro generator to transform into random deviates from statistical distributions:</p>
                <list list-type="bullet">
                  <list-item>
                    <p>runif(
<italic toggle="yes">a</italic>,
<italic toggle="yes">b</italic>) - A uniformly distributed real number in the interval [
<italic toggle="yes">a</italic>,
<italic toggle="yes">b</italic>), by dividing RNG state by its maximum value of 2
<sup>64</sup>.</p>
                  </list-item>
                  <list-item>
                    <p>rnorm(
<italic toggle="yes">µ</italic>,
<italic toggle="yes">σ</italic>) - A normally distributed real number with mean
<italic toggle="yes">µ</italic> and variance
<italic toggle="yes">σ</italic>
<sup>2</sup>, by applying the Box-Muller transform to runif(0, 1)
<sup><xref rid="ref-27" ref-type="bibr">27</xref></sup>.</p>
                  </list-item>
                  <list-item>
                    <p>rbinom(
<italic toggle="yes">n</italic>,
<italic toggle="yes">p</italic>) - A binomially distributed integer given
<italic toggle="yes">n</italic> trials and a probability of success
<italic toggle="yes">p</italic>. Uses inversion transform sampling with exponentiation by squaring if
<italic toggle="yes">np</italic> &lt; 10
<sup><xref rid="ref-28" ref-type="bibr">28</xref></sup>, or transformed rejection sampling with the ‘BTRS’ algorithm otherwise
<sup><xref rid="ref-29" ref-type="bibr">29</xref></sup>.</p>
                  </list-item>
                  <list-item>
                    <p>rpois(
<italic toggle="yes">λ</italic>) - A Poisson distributed integer given rate
<italic toggle="yes">λ</italic>. Uses Knuth’s algorithm for
<italic toggle="yes">λ &lt; </italic>10
<sup><xref rid="ref-30" ref-type="bibr">30</xref></sup>, and transformed rejection sampling otherwise
<sup><xref rid="ref-31" ref-type="bibr">31</xref></sup>.</p>
                  </list-item>
                </list>
                <p>All of these methods are optimised for when the parameters of the distribution change every sample, as expected with stochastic state space models. We plan to add other random number distributions as required, though these were sufficient for all models currently tested. This is all implemented using C++ to be bundled with dust, and can directly be accessed from R.</p>
              </sec>
              <sec>
                <title>Operation</title>
                <p>Given a model which is known to be a good description for the data under study, we provide an overview of the typical workflow runs through these packages in sequence. Steps 1 and 2 are model simulation, 3 to 7 for model inference, and 8 for forecasting. In cases where models are not being fitted to data, a dust generator can be used directly to simulate from the model with given parameters, and this process ends after the second step. If any model parameters are being inferred from the data steps 1–7 are required, with step 8 an optional addition if a further forecast using the inferred values is needed. Users with more complex needs not met by an odin model may also skip step 1, and write a dust target in C++ directly, while still using the dust RNG library and functions if required.</p>
                <list list-type="simple">
                  <list-item>
                    <label>1. </label>
                    <p><italic toggle="yes">Write a model in the odin DSL</italic>. Markov models will define a set of
<monospace>update()</monospace> functions which together give the state at
<italic toggle="yes">t</italic> +1 by operating on the state at
<italic toggle="yes">t</italic>.</p>
                  </list-item>
                  <list-item>
                    <label>2. </label>
                    <p><italic toggle="yes">Compile the model into a dust object</italic>. Using odin.dust, this will create a shared library and R interface. This will turn the odin code into a single
<monospace>update()</monospace> update function usable by dust. This step may be performed iteratively within an interactive session for rapid development, or by creating an R package for more robust development.</p>
                  </list-item>
                  <list-item>
                    <label>3. </label>
                    <p><italic toggle="yes">Write an observation function</italic>. This will compare model simulations to data, and calculate the log-likelihood of the model run given the data. Users are free to implement this however they wish, and can leverage any R function or package to do so.</p>
                  </list-item>
                  <list-item>
                    <label>4. </label>
                    <p><italic toggle="yes">Load observed data</italic>. Typically this will be time series data in R, as a
<monospace>data.frame.</monospace> Use the included functions in mcstate to convert this into input for the particle filter, potentially adding an offset and intermediate steps without observations.</p>
                  </list-item>
                  <list-item>
                    <label>5. </label>
                    <p><italic toggle="yes">Create a particle filter object</italic>. This uses the dust generator, observation function and observed data.</p>
                  </list-item>
                  <list-item>
                    <label>6. </label>
                    <p><italic toggle="yes">Set parameters</italic>. Define prior functions and pMCMC jump size for unknown parameters; set the values of known parameters.</p>
                  </list-item>
                  <list-item>
                    <label>7. </label>
                    <p><italic toggle="yes">Run a pMCMC</italic>. Using parameters and the particle filter, this will return posterior density estimates for each unknown parameter.</p>
                  </list-item>
                  <list-item>
                    <label>8. </label>
                    <p><italic toggle="yes">Forecast trajectories</italic>. If a forecast is required, run the
<monospace>predict()</monospace> function in mcstate after the pMCMC, which will create simulated trajectories for each particles past the end of the data, while sampling parameters from the posterior.</p>
                  </list-item>
                </list>
                <p>In some cases, users will want to first undertake model criticism, where possible models are compared in their ability to describe the data being studied, and iteratively improved. This may also be used as a replacement where the computational demands of a full pMCMC run are too great. In this case, steps 1–5 are the same, but then a maximum likelihood method replaces subsequent steps, and priors are only optionally specified:</p>
                <list list-type="bullet">
                  <list-item>
                    <p>6a.
<italic toggle="yes">Investigate model specification</italic>. Use maximum-likelihood estimation with IF2 to determine features of the data which are incompatible with the model.</p>
                  </list-item>
                  <list-item>
                    <p>7a.
<italic toggle="yes">Compare possible models</italic>. Likelihood estimates from IF2 can be produced by running sets of particle filters with the
<monospace>sample()</monospace> function. For nested model structures, these can be compared with likelihood-ratio tests.</p>
                  </list-item>
                  <list-item>
                    <p>8a.
<italic toggle="yes">Use this information to design a better model</italic>. Changes to the model structure can be made, returning to step 1 iteratively until an appropriate model is arrived at.</p>
                  </list-item>
                </list>
                <p>System requirements for running are:</p>
                <list list-type="bullet">
                  <list-item>
                    <p>R (&gt;=v3.5.0)</p>
                  </list-item>
                  <list-item>
                    <p>A C++ compiler such as gcc or clang is needed to compile dust models.</p>
                  </list-item>
                  <list-item>
                    <p>An appropriate OpenMP library (&gt;=v3.0), including a C++ compiler supporting the
<monospace>-fopenmp</monospace> option, such as gcc (&gt;=v4.0) or clang (&gt;=v3.9). If OpenMP is not available, models will still compile, but parallelisation of particles will not be supported.</p>
                  </list-item>
                  <list-item>
                    <p>odin, odin.dust, dust and mcstate, all of which can be installed with standard tools. Here, we used odin v1.1.12; odin.dust v0.2.7; dust v0.9.3; mcstate v0.6.0.</p>
                  </list-item>
                </list>
                <p>All our R packages are available for R on Linux, OS X and Windows, and are open source using the MIT licence.</p>
              </sec>
            </sec>
            <sec sec-type="cases">
              <title>Use cases</title>
              <p>Here we exhibit some brief examples of state space models, followed by a typical use case in epidemiology. We demonstrate the ease of use of these packages as this model becomes more complex, and is expanded to more realistic scenarios. These examples are included with the dust package, and detailed vignettes to reproduce the analysis here are included with the mcstate package.</p>
              <sec>
                <title>Basic stochastic models</title>
                <p>A basic model for volatility, which is a broadly used concept in finance describing randomly distributed variance of an asset’s price
<italic toggle="yes">x</italic>, is given by: </p>
                <p>
                  <disp-formula>
                    <mml:math id="math1" display="block" overflow="scroll">
                      <mml:mrow>
                        <mml:mi>d</mml:mi>
                        <mml:msub>
                          <mml:mi>x</mml:mi>
                          <mml:mi>t</mml:mi>
                        </mml:msub>
                        <mml:mo>=</mml:mo>
                        <mml:mi>a</mml:mi>
                        <mml:mi>x</mml:mi>
                        <mml:mi>d</mml:mi>
                        <mml:mi>t</mml:mi>
                        <mml:mo>+</mml:mo>
                        <mml:mi>σ</mml:mi>
                        <mml:mi>d</mml:mi>
                        <mml:msub>
                          <mml:mi>W</mml:mi>
                          <mml:mi>t</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:math>
                  </disp-formula>
                </p>
                <p>where
<italic toggle="yes">α</italic> is the constant drift,
<italic toggle="yes">σ</italic> is a constant volatility and
<italic toggle="yes">dW
<sub>t</sub>
</italic> is a Weiner process with zero mean and a variance of one
<sup><xref rid="ref-32" ref-type="bibr">32</xref>,
<xref rid="ref-33" ref-type="bibr">33</xref></sup>. Given the properties of Weiner processes (Brownian motion), the update function using the Euler-Maruyama method is:</p>
                <p>
                  <disp-formula>
                    <mml:math id="math2" display="block" overflow="scroll">
                      <mml:mrow>
                        <mml:mtable>
                          <mml:mtr>
                            <mml:mtd>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>x</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>t</mml:mi>
                                    <mml:mo>+</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>=</mml:mo>
                                <mml:mi>a</mml:mi>
                                <mml:msub>
                                  <mml:mi>x</mml:mi>
                                  <mml:mi>t</mml:mi>
                                </mml:msub>
                                <mml:mo>+</mml:mo>
                                <mml:mi>σ</mml:mi>
                                <mml:mo>∗</mml:mo>
                                <mml:mi>w</mml:mi>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                          <mml:mtr>
                            <mml:mtd>
                              <mml:mrow>
                                <mml:mi>w</mml:mi>
                                <mml:mo>~</mml:mo>
                                <mml:mi>N</mml:mi>
                                <mml:mo stretchy="false">(</mml:mo>
                                <mml:mn>0</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>1</mml:mn>
                                <mml:mo stretchy="false">)</mml:mo>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                        </mml:mtable>
                      </mml:mrow>
                    </mml:math>
                  </disp-formula>
                </p>
                <p>which in the odin DSL is simply:</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">update(x) &lt;- x * alpha + sigma * rnorm(0, 1)
initial(x) &lt;- x0
alpha &lt;- user(0.91)
sigma &lt;- user(1)
x0 &lt;- user(0)</styled-content>
                  </preformat>
                </p>
                <p>The
<monospace>user()</monospace> syntax specifies this will be a parameter provided through the R interface, either directly or through an inference method (such as mcstate). Default values can be set in brackets. Multiple realisations of this model can be run through dust (
<xref rid="f4" ref-type="fig">Figure 4</xref>) as follows:</p>
                <fig position="float" fig-type="figure" id="f4">
                  <label>Figure 4. </label>
                  <caption>
                    <title>Plot of the
<italic toggle="yes">x</italic> state from ten independent realisations (particles) from the volatility model, with an example trajectory highlighted in black, and the smoothed mean value from all particles in red.</title>
                  </caption>
                  <graphic xlink:href="wellcomeopenres-5-18728-g0003" position="float"/>
                </fig>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">gen &lt;- dust::dust_example("volatility")
# more generally:
# gen &lt;- odin.dust::odin_dust("volatility.txt")

vol &lt;- gen$new(data = list(alpha = 0.91),
               step = 0,
               n_particles = 10,
               n_threads = 4L,
               seed = 1L)
vol$run(10)</styled-content>
                  </preformat>
                </p>
                <p>This is included as an example in the dust package, but users can load their own model code by calling
<monospace>odin_dust</monospace> on the text file containing their model. This example illustrates running ten particles, ten timesteps forwards parallelised over four threads. The seed provided gives reproducible, uncorrelated runs for each of the particles.</p>
              </sec>
              <sec>
                <title>Stochastic SIR model</title>
                <p>Models of infectious disease transmission – such as the susceptible-infected-recovered (SIR) model
<sup><xref rid="ref-34" ref-type="bibr">34</xref>,
<xref rid="ref-35" ref-type="bibr">35</xref></sup> – are an obvious use of our packages. Typically these models can be expressed in three related forms: ODEs, stochastic differential equations (SDEs) or as a continuous time Markov chain (CTMC)
<sup><xref rid="ref-36" ref-type="bibr">36</xref></sup>. Their solutions have different properties: ODEs are fast to solve numerically, and are deterministic given a set of initial conditions; SDEs give stochastic solutions each time they are solved which better represent the variance in real-world systems, and still have efficient numerical solvers; CTMCs best represent the discrete nature in small populations and correctly model absorbing states, but are computationally more intensive to realise trajectories from
<sup><xref rid="ref-37" ref-type="bibr">37</xref></sup>. For the remainder of this section we focus on stochastic models, particularly CTMC formulations of infectious disease transmission models. A simple definition (using the ODE formalism) of the SIR model is:</p>
                <p>
                  <disp-formula>
                    <mml:math id="math3" display="block" overflow="scroll">
                      <mml:mrow>
                        <mml:mtable columnalign="left">
                          <mml:mtr columnalign="left">
                            <mml:mtd columnalign="left">
                              <mml:mrow>
                                <mml:mtable>
                                  <mml:mtr>
                                    <mml:mtd>
                                      <mml:mrow>
                                        <mml:mfrac>
                                          <mml:mrow>
                                            <mml:mi>d</mml:mi>
                                            <mml:mi>S</mml:mi>
                                          </mml:mrow>
                                          <mml:mrow>
                                            <mml:mi>d</mml:mi>
                                            <mml:mi>t</mml:mi>
                                          </mml:mrow>
                                        </mml:mfrac>
                                        <mml:mo>=</mml:mo>
                                        <mml:mo>−</mml:mo>
                                        <mml:mi>β</mml:mi>
                                        <mml:mfrac>
                                          <mml:mrow>
                                            <mml:mi>S</mml:mi>
                                            <mml:mi>I</mml:mi>
                                          </mml:mrow>
                                          <mml:mi>N</mml:mi>
                                        </mml:mfrac>
                                      </mml:mrow>
                                    </mml:mtd>
                                  </mml:mtr>
                                </mml:mtable>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                          <mml:mtr columnalign="left">
                            <mml:mtd columnalign="left">
                              <mml:mrow>
                                <mml:mtable>
                                  <mml:mtr>
                                    <mml:mtd>
                                      <mml:mrow>
                                        <mml:mfrac>
                                          <mml:mrow>
                                            <mml:mi>d</mml:mi>
                                            <mml:mi>I</mml:mi>
                                          </mml:mrow>
                                          <mml:mrow>
                                            <mml:mi>d</mml:mi>
                                            <mml:mi>t</mml:mi>
                                          </mml:mrow>
                                        </mml:mfrac>
                                        <mml:mo>=</mml:mo>
                                        <mml:mi>β</mml:mi>
                                        <mml:mfrac>
                                          <mml:mrow>
                                            <mml:mi>S</mml:mi>
                                            <mml:mi>I</mml:mi>
                                          </mml:mrow>
                                          <mml:mi>N</mml:mi>
                                        </mml:mfrac>
                                      </mml:mrow>
                                    </mml:mtd>
                                  </mml:mtr>
                                </mml:mtable>
                                <mml:mo>−</mml:mo>
                                <mml:mi>γ</mml:mi>
                                <mml:mi>I</mml:mi>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                          <mml:mtr columnalign="left">
                            <mml:mtd columnalign="left">
                              <mml:mrow>
                                <mml:mfrac>
                                  <mml:mrow>
                                    <mml:mi>d</mml:mi>
                                    <mml:mi>R</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mi>d</mml:mi>
                                    <mml:mi>t</mml:mi>
                                  </mml:mrow>
                                </mml:mfrac>
                                <mml:mo>=</mml:mo>
                                <mml:mi>γ</mml:mi>
                                <mml:mi>I</mml:mi>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                        </mml:mtable>
                      </mml:mrow>
                    </mml:math>
                  </disp-formula>
                </p>
                <p><italic toggle="yes">S</italic> is the number of susceptibles,
<italic toggle="yes">I</italic> is the number of infected and
<italic toggle="yes">R</italic> is the number recovered; the total population size
<italic toggle="yes">N</italic> =
<italic toggle="yes">S</italic> +
<italic toggle="yes">I</italic> +
<italic toggle="yes">R</italic> is constant.
<italic toggle="yes">β</italic> is the infection rate,
<italic toggle="yes">γ</italic> is the recovery rate.</p>
                <p>This model can be discretised in time steps of width
<italic toggle="yes">d t</italic> using the following update equations for each time step
<sup><xref rid="ref-36" ref-type="bibr">36</xref>–
<xref rid="ref-38" ref-type="bibr">38</xref>
</sup>:</p>
                <p>
                  <disp-formula>
                    <mml:math id="math4" display="block" overflow="scroll">
                      <mml:mrow>
                        <mml:mtable columnalign="left">
                          <mml:mtr columnalign="left">
                            <mml:mtd columnalign="left">
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>S</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>t</mml:mi>
                                    <mml:mo>+</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>=</mml:mo>
                                <mml:msub>
                                  <mml:mi>S</mml:mi>
                                  <mml:mi>t</mml:mi>
                                </mml:msub>
                                <mml:mo>−</mml:mo>
                                <mml:msub>
                                  <mml:mi>n</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>S</mml:mi>
                                    <mml:mi>I</mml:mi>
                                    <mml:mo>,</mml:mo>
                                    <mml:mi>t</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                          <mml:mtr columnalign="left">
                            <mml:mtd columnalign="left">
                              <mml:mrow>
                                <mml:mspace width="0.2em"/>
                                <mml:msub>
                                  <mml:mi>I</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>t</mml:mi>
                                    <mml:mo>+</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>=</mml:mo>
                                <mml:msub>
                                  <mml:mi>I</mml:mi>
                                  <mml:mi>t</mml:mi>
                                </mml:msub>
                                <mml:mo>+</mml:mo>
                                <mml:msub>
                                  <mml:mi>n</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>S</mml:mi>
                                    <mml:mi>I</mml:mi>
                                    <mml:mo>,</mml:mo>
                                    <mml:mi>t</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>−</mml:mo>
                                <mml:msub>
                                  <mml:mi>n</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>I</mml:mi>
                                    <mml:mi>R</mml:mi>
                                    <mml:mo>,</mml:mo>
                                    <mml:mi>t</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                          <mml:mtr columnalign="left">
                            <mml:mtd columnalign="left">
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>R</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>t</mml:mi>
                                    <mml:mo>+</mml:mo>
                                    <mml:mn>1</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>=</mml:mo>
                                <mml:msub>
                                  <mml:mi>R</mml:mi>
                                  <mml:mi>t</mml:mi>
                                </mml:msub>
                                <mml:mo>+</mml:mo>
                                <mml:msub>
                                  <mml:mi>n</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>I</mml:mi>
                                    <mml:mi>R</mml:mi>
                                    <mml:mo>,</mml:mo>
                                    <mml:mi>t</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                        </mml:mtable>
                      </mml:mrow>
                    </mml:math>
                  </disp-formula>
                </p>
                <p>where the number of individuals moving between compartments are given by drawing from binomial distributions:</p>
                <p>
                  <disp-formula>
                    <mml:math id="math5" display="block" overflow="scroll">
                      <mml:mrow>
                        <mml:mtable columnalign="left">
                          <mml:mtr columnalign="left">
                            <mml:mtd columnalign="left">
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>n</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>S</mml:mi>
                                    <mml:mi>I</mml:mi>
                                    <mml:mo>,</mml:mo>
                                    <mml:mi>t</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>~</mml:mo>
                                <mml:mi>B</mml:mi>
                                <mml:mo stretchy="false">(</mml:mo>
                                <mml:msub>
                                  <mml:mi>S</mml:mi>
                                  <mml:mi>t</mml:mi>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:mspace width="0.2em"/>
                                <mml:mn>1</mml:mn>
                                <mml:mo>−</mml:mo>
                                <mml:mi>exp</mml:mi>
                                <mml:mo>⁡</mml:mo>
                                <mml:mo stretchy="false">(</mml:mo>
                                <mml:mo>−</mml:mo>
                                <mml:mi>β</mml:mi>
                                <mml:mfrac>
                                  <mml:mrow>
                                    <mml:msub>
                                      <mml:mi>I</mml:mi>
                                      <mml:mi>t</mml:mi>
                                    </mml:msub>
                                  </mml:mrow>
                                  <mml:mi>N</mml:mi>
                                </mml:mfrac>
                                <mml:mo>⋅</mml:mo>
                                <mml:mi>d</mml:mi>
                                <mml:mi>t</mml:mi>
                                <mml:mo stretchy="false">)</mml:mo>
                                <mml:mo stretchy="false">)</mml:mo>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                          <mml:mtr columnalign="left">
                            <mml:mtd columnalign="left">
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mi>n</mml:mi>
                                  <mml:mrow>
                                    <mml:mi>I</mml:mi>
                                    <mml:mi>R</mml:mi>
                                    <mml:mo>,</mml:mo>
                                    <mml:mi>t</mml:mi>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>~</mml:mo>
                                <mml:mi>B</mml:mi>
                                <mml:mo stretchy="false">(</mml:mo>
                                <mml:msub>
                                  <mml:mi>I</mml:mi>
                                  <mml:mi>t</mml:mi>
                                </mml:msub>
                                <mml:mo>,</mml:mo>
                                <mml:mspace width="0.2em"/>
                                <mml:mn>1</mml:mn>
                                <mml:mo>−</mml:mo>
                                <mml:mi>exp</mml:mi>
                                <mml:mo>⁡</mml:mo>
                                <mml:mo stretchy="false">(</mml:mo>
                                <mml:mo>−</mml:mo>
                                <mml:mi>γ</mml:mi>
                                <mml:mo>⋅</mml:mo>
                                <mml:mi>d</mml:mi>
                                <mml:mi>t</mml:mi>
                                <mml:mo stretchy="false">)</mml:mo>
                                <mml:mo stretchy="false">)</mml:mo>
                              </mml:mrow>
                            </mml:mtd>
                          </mml:mtr>
                        </mml:mtable>
                      </mml:mrow>
                    </mml:math>
                  </disp-formula>
                </p>
                <p>the binomial distribution is used as there are
<italic toggle="yes">n</italic> trials, one for each individual in the compartments, who move with per-capita transition probability
<italic toggle="yes">p</italic>. In a single time step,
<italic toggle="yes">p</italic> can be calculated as 1 −
<italic toggle="yes">e</italic>
<sup><italic toggle="yes">λ</italic>·
<italic toggle="yes">dt</italic>
</sup> where
<italic toggle="yes">λ</italic> is the transition rate, as in a Poisson process time between events is exponentially distributed.</p>
                <p>These equations can be written in the odin DSL as:</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">## Definition of the time-step and output as "time"
dt &lt;- user(1)
initial(time) &lt;- 0
update(time) &lt;- (step + 1) * dt

## Model parameters (default in parenthesis)
beta &lt;- user(0.2)
gamma &lt;- user(0.1)

## Initial conditions
initial(S) &lt;- 1000
initial(I) &lt;- 1
initial(R) &lt;- 0

## Core equations for transitions between compartments:
update(S) &lt;- S - n_SI
update(I) &lt;- I + n_SI - n_IR
update(R) &lt;- R + n_IR

## Individual probabilities of transition:
N &lt;- S + I + R # total population size
p_SI &lt;- 1 - exp(-beta * I / N * dt) # S to I
p_IR &lt;- 1 - exp(-gamma * dt) # I to R

## Draws from binomial distributions for numbers changing between
## compartments:
n_IR &lt;- rbinom(I, p_IR)
n_SI &lt;- rbinom(S, p_SI)</styled-content>
                  </preformat>
                </p>
                <p>This would be saved as
<monospace>sir.R</monospace> and then compiled with
<monospace>odin.dust::odin_dust("sir.R").</monospace>
</p>
                <p>Initial conditions here are fixed, but they can also be added to the
<monospace>user()</monospace> group to be set from R for each run. For infectious disease models, users may follow the guidance in the odin documentation on discretising ODE models using appropriate random number draws (
<ext-link xlink:href="https://mrc-ide.github.io/odin/articles/discrete.html" ext-link-type="uri">https://mrc-ide.github.io/odin/articles/discrete.html</ext-link>). </p>
                <p>This model can simulate an epidemic forward in time using fixed parameters, as shown in
<xref rid="f5" ref-type="fig">Figure 5</xref>. We can also use this model to demonstrate the inference process (steps 3–8 in Operation), showing how the transmission rate
<italic toggle="yes">β</italic> and recovery rate
<italic toggle="yes">γ</italic> (as well as
<inline-formula><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mi>γ</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>) can be inferred from observed daily case counts
<italic toggle="yes">y
<sub>t</sub>
</italic>. For each day
<italic toggle="yes">t</italic>, the number of expected new cases (if all cases are observed) can be assumed to be Poisson distributed with mean
<italic toggle="yes">y
<sub>t</sub>
</italic>, so an observation function can be written by taking the log of a Poisson probability mass function at
<italic toggle="yes">k
<sub>t</sub>
</italic> =
<italic toggle="yes">S
<sub>t</sub>
</italic>
<sub>−1</sub> −
<italic toggle="yes">S
<sub>t</sub>
</italic> =
<italic toggle="yes">n
<sub>SI,t</sub>
</italic>. This can easily be achieved using the builtin R function
<monospace>dpois()</monospace> (one of many probability-distribution functions available to users):</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">case_compare &lt;- function(state, prev_state, observed, pars = NULL) {
  cases_modelled &lt;- prev_state[1, , ] - state[1, , ]
  dpois(incidence_observed, observed$cases, log = TRUE)
}</styled-content>
                  </preformat>
                </p>
                <fig position="float" fig-type="figure" id="f5">
                  <label>Figure 5. </label>
                  <caption>
                    <title>Plots of the number of individuals in the
<italic toggle="yes">S</italic>,
<italic toggle="yes">I</italic> and
<italic toggle="yes">R</italic> compartments over time in an SIR model with
<italic toggle="yes">β</italic> = 0.2 and
<italic toggle="yes">γ</italic> = 0.1.</title>
                    <p><bold>A</bold>: 10 particles run forward for 100 time steps.
<bold>B</bold>: Solid points are data generated from the model from which simulated case counts were produced. Lines are 100 particles run forward using a particle filter with this data.
<bold>C</bold>: Daily case incidence data which was fitted to (black), and modelled incidence of 100 particles (grey). Average of particles shown as points
<bold>D</bold>: Extending the particle trajectories forward in time by simulating the model forward with parameters sampled from the estimated posterior. Here, only the first half of the time series was used to show a more uncertain part of the epidemic, subsequent real points are shown in black.</p>
                  </caption>
                  <graphic xlink:href="wellcomeopenres-5-18728-g0004" position="float"/>
                </fig>
                <p>In the state array, the first dimension is over model compartments, the second dimension is over particles, and the third over time. So the index ‘1’ extracts the first state, the number of susceptibles. Multiple data-streams can straightforwardly be added by noting that log-likelihoods sum, as long as they are conditionally independent. That is, given the simulated quantities in the model, the observed quantities are assumed to be independent, and have independent noise. So a similar log-likelihood component could be defined based on deaths, in a model with these compartments, and added to the existing function. If a data stream isn’t measured at a particular time point, it simply contributes zero to the log-likelihood.</p>
                <p>A particle filter can then be set up using mcstate (steps 4 and 5), choosing the number of particles, and formatting observational data appropriately with the built-in function
<monospace>particle_filter_data()</monospace>. The observations must be evenly spaced, though missing observations are permitted. The step size in the data is defined to be one, and
<inline-formula><mml:math id="M2" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> update steps are taken between each observation.</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">n_particles &lt;- 100
dt &lt;- 0.25
data &lt;- particle_filter_data(data, time = "day", rate = 1/dt)
filter &lt;- particle_filter$new(data = data,
                              model = sir,
                              n_particles = n_particles,
                              compare = case_compare)</styled-content>
                  </preformat>
                </p>
                <p>The right panel of
<xref rid="f5" ref-type="fig">Figure 5</xref> demonstrates using this observation function with case data simulated from the model. Only those trajectories consistent with the data are continued forward at each step, and a final log-likelihood of the model parameters given the data is produced. </p>
                <p>Steps 6 and 7, which are used to estimate the posterior density for
<italic toggle="yes">β</italic> and
<italic toggle="yes">γ</italic>, are achieved by defining sampling distributions for the parameters, and running a set of MCMC chains. Priors for each parameter can be added at this stage, with an example shown on
<italic toggle="yes">γ</italic> for demonstrative purposes:</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">beta &lt;- pmcmc_parameter("beta", 0.2, min = 0)
gamma &lt;- pmcmc_parameter("gamma", 0.1, min = 0,
                         prior = function(p)
                           dgamma(p, shape = 1, scale = 0.2, log = TRUE)
                        )
proposal_matrix &lt;- diag(2) * 0.01^2
mcmc_pars &lt;- pmcmc_parameters$new(list(beta = beta, gamma = gamma),
                                  proposal_matrix)
                            
pmcmc_run &lt;-
  pmcmc(
    mcmc_pars,
    filter,
    n_steps = 2000,
    save_state = TRUE,
    save_trajectories = TRUE,
    progress = TRUE,
    n_chains = 4
  )</styled-content>
                  </preformat>
                </p>
                <p>Noting that in the SIR model
<inline-formula><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mi>γ</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>, we could alternatively directly sample
<italic toggle="yes">R</italic>
<sub>0</sub> instead of
<italic toggle="yes">β</italic>. This is achieved by also supplying a transformation function, which takes parameters being sampled in the MCMC, and returns a list of user input parameters needed by the odin model:</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">R0 &lt;- pmcmc_parameter("R0", 2, min = 0)
parameter_transform &lt;- function(pars) {
    beta &lt;- pars[["gamma"]] * pars[["R0"]]
    gamma &lt;- pars[["gamma"]]
    list(beta = beta, gamma = gamma)
}</styled-content>
                  </preformat>
                </p>
                <p>Parameter transforms can also be used to represent time-varying parameters. One way of doing so is to make fixed time points as pmcmc_parameters in R, define a piecewise linear interpolation between fixed parameters in the transformation, and give a dust model a dense vector with the parameter value at every time point. We refer interested readers to the example of the time-varying
<italic toggle="yes">β</italic> parameter in the SIRCOVID package.</p>
                <p>Posterior distributions for
<italic toggle="yes">β</italic> and
<italic toggle="yes">γ</italic> are available from the
<monospace>pmcmc</monospace> object, and are plotted for this example in
<xref rid="f6" ref-type="fig">Figure 6</xref>. They can be loaded directly into standard MCMC analysis packages such as
<monospace>coda</monospace>
<sup><xref rid="ref-39" ref-type="bibr">39</xref></sup> to produce diagnostics such as effective sample size, the Gelman-Rubin diagnostic
<inline-formula><mml:math id="M4" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. As is typical with MH sampling, the proposal distribution will likely need to be tuned to get an appropriate acceptance rate, typically thought to be 0.234 for high dimensional problems
<sup><xref rid="ref-40" ref-type="bibr">40</xref></sup>. One algorithmic way to do this is to run the chains for a short time, calculate the variance-covariance matrix among the samples, and use this as the proposal kernel. This process is covered in the ‘Tuning the pMCMC’ section of the SIR models vignette in the mcstate package.</p>
                <fig position="float" fig-type="figure" id="f6">
                  <label>Figure 6. </label>
                  <caption>
                    <title>Inferring parameters in compartmental models: the SIR model fitted to simulated daily case data.</title>
                    <p>The particle filter was set up as specified, and four independent chains were run, each chain taking 2 × 10
<sup>3</sup> samples for the SIR model. In the SIR model, true values are
<italic toggle="yes">β</italic> = 0.2,
<italic toggle="yes">γ</italic> = 0.1,
<italic toggle="yes">R</italic>
<sub>0</sub> = 2.
<bold>A</bold>: posterior samples from
<italic toggle="yes">β</italic>.
<bold>B</bold>: posterior samples from
<italic toggle="yes">γ</italic>.
<bold>C</bold>: marginal posterior distribution for
<inline-formula><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mi>r</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>.</p>
                  </caption>
                  <graphic xlink:href="wellcomeopenres-5-18728-g0005" position="float"/>
                </fig>
                <p>Finally, producing a forecast past the end of the data (step 8) is achieved simply by calling
<monospace>predict()</monospace> on the above MCMC object (as shown in the final panel of
<xref rid="f5" ref-type="fig">Figure 5</xref>):</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">forecast &lt;- predict(pmcmc_run,
		    steps = seq(400, 800, 4),
		    prepend_trajectories = TRUE,
		    seed = pmcmc_run$predict$seed)
</styled-content>
                  </preformat>
                </p>
              </sec>
              <sec>
                <title>Maximum-likelihood estimation with the SIR model</title>
                <p>Using the particle filter constructed above, an iterated filtering algorithm can be applied to find parameter values which maximise the model likelihood. This is useful for the model criticism workflow outlined in steps 6a-8a. This may also be useful when pMCMC would stretch the available computational resources, as evaluating the likelihood profile at different points has more favourable scaling properties
<sup><xref rid="ref-41" ref-type="bibr">41</xref>–
<xref rid="ref-43" ref-type="bibr">43</xref>
</sup>. In this mode, the user sets parameters up as for pMCMC, and adds a control object including an independent perturbation strength for each parameter
<monospace>pars_sd</monospace>, a population size of parameters
<monospace>n_par_sets</monospace>, and a cooling schedule in
<monospace>iterations</monospace> and
<monospace>cooling_target</monospace>:</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve"><styled-content style="font-size:15px;color:#000000;">pars &lt;- mcstate::</styled-content><styled-content style="font-size:15px;color:#000000;">if2_parameters$new(</styled-content>
              <styled-content style="font-size:15px;color:#000000;">list(mcstate::if2_parameter("beta", 0.5, min = 0, max = 1),</styled-content>
                    <styled-content style="font-size:15px;color:#000000;">mcstate::if2_parameter("gamma", 0.01, min = 0, max = 1)))</styled-content>

<styled-content style="font-size:15px;color:#000000;">control &lt;- mcstate::if2_control(
  pars_sd = list("beta" = 0.02, "gamma" = 0.02),
  iterations = 100,
  n_par_sets = 300,
  cooling_target = 0.5)

res &lt;- mcstate::if2(pars, filter, control)
</styled-content></preformat>
                </p>
                <p>This will yield a likelihood which is maximised over the course of the iterations, and the corresponding parameter estimates. The likelihood and its error can be estimated by running particle filters at these parameter estimates using the
<monospace>if2_sample()</monospace> command. This mode is covered in more detail in the “if2” package vignette.</p>
              </sec>
              <sec>
                <title>Prior specification and prior predictive checks</title>
                <p>Above, we showed a Gamma(1, 0.2) prior on
<italic toggle="yes">γ</italic> for demonstrative purposes. The default if no prior function is specified, is to use a flat improper prior, which does not contribute to the posterior. For model features which do not fit the data, it may not be possible to set a suitable prior, so this may be a particularly useful when undertaking model criticism (steps 6a–8a). The prior function is completely flexible, and therefore allows any functionality the R language allows. This can therefore include more complex setups such as using tools from external packages, or drawing from another model’s posterior, which may be used to implement hierarchical models.</p>
                <p>When setting priors, users may wish to perform prior predictive checks to determine whether the chosen prior functions are appropriate for the model and data
<sup><xref rid="ref-44" ref-type="bibr">44</xref></sup>. First, parameters are selected by drawing from the priors (in the example below, from a uniform distribution for
<italic toggle="yes">β</italic>. and gamma distribution for
<italic toggle="yes">γ</italic>). Then, the model is simulated forwards using these parameters, and the resulting data series plotted to determine appropriateness. The simulate method in dust can be used to run across a whole time series and return the model state:</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">step_start &lt;- 0
step_end &lt;- 100
mod &lt;- sir$new(pars = list(), step = start, n_particles = 100L)

# Note here the "r" version of the "d" distribution densities used in the
# prior functions. Care should be taken translating more complex densities
# into random draws
prior_draw &lt;- list("beta" = runif(1, 0, 1), "gamma" = rgamma(1, 1, 0.2))
mod$reset(pars = prior_draw, step = start)
prior_data &lt;- mod$simulate(step_end)
</styled-content>
                  </preformat>
                </p>
              </sec>
              <sec>
                <title>Adding age-structure to the SIR model</title>
                <p>This model can be extended to add more flexibility or more specificity when modelling the biology of different diseases. For example: adding new compartments to represent other disease states; compartments which represent spatial or age structuring of the population; or delay distributions which model different rates at which individuals pass through disease pathways. By matching the compartments and the transitions between them to the disease being studied, infectious disease epidemiologists can flexibly and accurately model a wide variety of real world processes.</p>
                <p> As an example of how the basic code given above can be extended, we demonstrate how the SIR model can incorporate age-structure into each of its three compartments. Adding age structure to the model consists of the following steps, which turn variables into arrays:</p>
                <list list-type="bullet">
                  <list-item>
                    <p>Define the number of age categories as a user parameter
<italic toggle="yes">N</italic>
<sub>age</sub>.</p>
                  </list-item>
                  <list-item>
                    <p>Add age structure to each compartment, by adding square brackets to the left hand side of each declaration in the odin definition of the model given at the beginning of the section describing stochastic SIR model.</p>
                  </list-item>
                  <list-item>
                    <p>Modify the right hand side of each declaration to use quantities from the appropriate compartment, by adding indices
<italic toggle="yes">i</italic> and
<italic toggle="yes">j</italic> as needed. These will automatically be turned into loops by odin.dust.</p>
                  </list-item>
                  <list-item>
                    <p>Where an age compartment needs to be reduced into a single compartment/variable, we use
<monospace>sum</monospace> (though further array reduction functions are available).</p>
                  </list-item>
                  <list-item>
                    <p>Define the dimensions of all arrays, for example by setting
<monospace>dim(S) &lt;- N_age</monospace>.</p>
                  </list-item>
                </list>
                <p>Alone, this would simply give
<italic toggle="yes">N
<sub>age</sub>
</italic> independent processes equivalent to the first model, scaled by the size of the population in each age category. To actually make this useful, some form of interaction or transitions need to be added between the compartments. An example of this would be to add an age-specific contact matrix
<italic toggle="yes">m</italic>, which defines a different force of infection
<italic toggle="yes">λ</italic> for each age group. This is calculated by</p>
                <p>
                  <disp-formula>
                    <mml:math id="math6" display="block" overflow="scroll">
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>λ</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mo>=</mml:mo>
                        <mml:mfrac>
                          <mml:mi>β</mml:mi>
                          <mml:mi>N</mml:mi>
                        </mml:mfrac>
                        <mml:mo>⋅</mml:mo>
                        <mml:mstyle displaystyle="true">
                          <mml:munderover>
                            <mml:mo>∑</mml:mo>
                            <mml:mrow>
                              <mml:mi>j</mml:mi>
                              <mml:mtext>=1</mml:mtext>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>N</mml:mi>
                                <mml:mrow>
                                  <mml:mtext>age</mml:mtext>
                                </mml:mrow>
                              </mml:msub>
                            </mml:mrow>
                          </mml:munderover>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>I</mml:mi>
                              <mml:mi>j</mml:mi>
                            </mml:msub>
                            <mml:msub>
                              <mml:mi>m</mml:mi>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                        </mml:mstyle>
                        <mml:mspace width="8em"/>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:mn>1</mml:mn>
                        <mml:mo stretchy="false">)</mml:mo>
                      </mml:mrow>
                    </mml:math>
                  </disp-formula>
                </p>
                <p>In the odin DSL:</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">m[, ] &lt;- user() # age-structured contact matrix
s_ij[, ] &lt;- m[i, j] * I[i]
lambda[] &lt;- beta / N * sum(s_ij[i, ])</styled-content>
                  </preformat>
                </p>
                <p>The contact matrix
<italic toggle="yes">m</italic> is input from R. Its entries
<italic toggle="yes">m
<sub>ij</sub>
</italic> define the intensity of contact between age classes
<italic toggle="yes">i</italic> and
<italic toggle="yes">j</italic>. One choice is to base it on the POLYMOD survey, which can conveniently be loaded in through the socialmixr R package
<sup><xref rid="ref-45" ref-type="bibr">45</xref></sup>. This can be provided as input to the model by adding it to the list returned by a transformation function.</p>
                <p>The probability of infection of a susceptible is then indexed by this force of infection:</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">p_SI[] &lt;- 1 - exp(-lambda[i] * dt)</styled-content>
                  </preformat>
                </p>
                <p>Putting this all together, the key components of the age structured SIR model is as follows (omitting initial conditions and parameter values from the unstructured SIR model for simplicity):</p>
                <p>
                  <preformat preformat-type="computer code" position="float" xml:space="preserve">
                    <styled-content style="font-size:15px;color:#000000;">## Core equations for transitions between compartments:
update(S[]) &lt;- S[i] - n_SI[i]
update(I[]) &lt;- I[i] + n_SI[i] - n_IR[i]
update(R[]) &lt;- R[i] + n_IR[i]

## Individual probabilities of transition:
p_SI[] &lt;- 1 - exp(-lambda[i] * dt) # S to I
p_IR &lt;- 1 - exp(-gamma * dt) # I to R

## Force of infection
m[, ] &lt;- user() # age-structured contact matrix
s_ij[, ] &lt;- m[i, j] * I[i]
lambda[] &lt;- beta / N * sum(s_ij[i, ])

## Draws from binomial distributions for numbers changing between
## compartments:
n_SI[] &lt;- rbinom(S[i], p_SI[i])
n_IR[] &lt;- rbinom(I[i], p_IR)

## Total population size
N &lt;- sum(S) + sum(I) + sum(R)

# Array dimensions
dim(S) &lt;- N_age
dim(I) &lt;- N_age
dim(R) &lt;- N_age
dim(n_SI) &lt;- N_age
dim(n_IR) &lt;- N_age
dim(lambda) &lt;- N_age
dim(m) &lt;- c(N_age, N_age)
dim(s_ij) &lt;- c(N_age, N_age)</styled-content>
                  </preformat>
                </p>
                <p>While we use 1- and 2- dimensional structures here, odin currently supports up to 8 dimensions, allowing for concise description of structured models (at the time of writing, we know of use of up to 4 dimensions).</p>
              </sec>
              <sec>
                <title>Comparison with alternative packages</title>
                <p>Although state space models can in some cases be analysed using a general Bayesian hierarchical framework such as JAGS
<sup><xref rid="ref-46" ref-type="bibr">46</xref></sup> or stan
<sup><xref rid="ref-47" ref-type="bibr">47</xref></sup>, care needs to be taken with state space models as trajectories can rapidly diverge from time-series data with stochastic update functions, and fitting may become slow
<sup><xref rid="ref-48" ref-type="bibr">48</xref></sup>. Two previous packages which aim to solve these issues in a similar way are pomp (partially-observed Markov processes)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup> and libBi (library for Bayesian inference)
<sup><xref rid="ref-10" ref-type="bibr">10</xref></sup>. </p>
                <p>Both packages use similar concepts to dust and mcstate, requiring users to define a Markovian update function (
<monospace>rprocess()</monospace> in pomp;
<monospace>transition()</monospace> in libBi), an initial state (
<monospace>rinit()</monospace> in pomp;
<monospace>initial()</monospace> in libBi) and a observation function (
<monospace>dmeasure()</monospace> in pomp;
<monospace>observation()</monospace> in libBi). These packages both support simulation and inference from the model using the same overall methods as mcstate, and additionally support some optimisation procedures such as maximum likelihood or particle perturbation.</p>
                <p>These packages also support some link between interpreted and compiled languages. In pomp, the interface is in R, but it also any of these functions may be written either in R or in C. This allows us to demonstrate the advantage of using compiled functions to simulate from models on an even footing. Using an SIR model coded in pomp using R functions, and and equivalent implementation in pomp coded using C function, a speedup of around 100x was seen comparing C to pure R, even for this simple model (
<xref rid="T1" ref-type="table">Table 1</xref>). libBi uses a DSL to define both the update and observation functions, which are transpiled into C++, then compiled into a standalone executable supporting all its inference methods. We implemented an identical stochastic SIR model in all three packages. With compiled functions, all three methods run at similar speeds (
<xref rid="T1" ref-type="table">Table 1</xref>). </p>
                <table-wrap position="anchor" id="T1">
                  <label>Table 1. </label>
                  <caption>
                    <title>Comparison of packages for SIR model implementations.</title>
                    <p>This table lists some features of each package. The CPU time is for a run of 10
<sup>6</sup> steps with
<italic toggle="yes">n
<sub>P</sub>
</italic> = 10;
<italic toggle="yes">S</italic>
<sub>0</sub> = 10
<sup>6</sup>;
<italic toggle="yes">I</italic>
<sub>0</sub> = 10;
<italic toggle="yes">dt</italic> = 10
<sup>−4</sup> on a single core. We focus on a long simulation time, as profiling of the more realistic COVID-19 transmission model showed most computation time during inference was spent in this stage, and minimises measurement of overheads. Array indexing can be automated when a DSL infers the correct ‘C-Tran’ sums and loops to add, or manual when they must be written in the model by the user. Bayesian inference algorithms include particle MCMC (pMCMC), approximate Bayesian computation (ABC)
<sup><xref rid="ref-49" ref-type="bibr">49</xref></sup>, SMC2
<sup><xref rid="ref-50" ref-type="bibr">50</xref></sup> and sequential importance sampling (SIS)
<sup><xref rid="ref-51" ref-type="bibr">51</xref></sup>; maximum likelihood inference algorithms include iterated filtering (IF2) and numerical likelihood optimisation (optim).</p>
                  </caption>
                  <table frame="hsides" rules="groups" content-type="article-table">
                    <thead>
                      <tr>
                        <th align="left" valign="top" rowspan="1" colspan="1">Package </th>
                        <th align="left" valign="top" rowspan="1" colspan="1">Potential
<break/>parallelisation </th>
                        <th align="right" valign="top" rowspan="1" colspan="1">CPU
<break/>time </th>
                        <th align="left" valign="top" rowspan="1" colspan="1">Model
<break/>language </th>
                        <th align="left" valign="top" rowspan="1" colspan="1">Interface
<break/>language </th>
                        <th align="left" valign="top" rowspan="1" colspan="1">Data
<break/>input</th>
                        <th align="left" valign="top" rowspan="1" colspan="1">Array
<break/>indexing</th>
                        <th align="left" valign="top" rowspan="1" colspan="1">Parameter
<break/>constraints/
<break/>transforms</th>
                        <th align="left" valign="top" rowspan="1" colspan="1">Inference
<break/>methods</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td align="left" valign="top" rowspan="1" colspan="1">dust</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">
                          <italic toggle="yes">n
<sub>P</sub>m
<sub>c</sub>
</italic>
                        </td>
                        <td align="right" valign="top" rowspan="1" colspan="1">0.96s</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">R/odin DSL</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">R</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">R</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">Automatic</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">Arbitrary R
<break/>code</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">pMCMC,
<break/>IF2</td>
                      </tr>
                      <tr>
                        <td align="left" valign="top" rowspan="1" colspan="1">pomp</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">
                          <italic toggle="yes">m
<sub>c</sub>
</italic>
                        </td>
                        <td align="right" valign="top" rowspan="1" colspan="1">82s</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">R</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">R</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">R</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">Manual</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">Fixed choice
<break/>of functions</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">pMCMC,
<break/>IF2, ABC</td>
                      </tr>
                      <tr>
                        <td align="left" valign="top" rowspan="1" colspan="1">pomp</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">
                          <italic toggle="yes">m
<sub>c</sub>
</italic>
                        </td>
                        <td align="right" valign="top" rowspan="1" colspan="1">1.3s</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">C</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">R</td>
                        <td align="left" valign="top" rowspan="1" colspan="1"/>
                        <td align="left" valign="top" rowspan="1" colspan="1"/>
                        <td align="left" valign="top" rowspan="1" colspan="1"/>
                        <td align="left" valign="top" rowspan="1" colspan="1"/>
                      </tr>
                      <tr>
                        <td align="left" valign="top" rowspan="1" colspan="1">libBi</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">
                          <italic toggle="yes">n
<sub>P</sub>m
<sub>c</sub>
</italic>
                        </td>
                        <td align="right" valign="top" rowspan="1" colspan="1">1.04s</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">libBi DSL</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">bash</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">NetCDF/
<break/>RBi</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">Automatic</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">In DSL</td>
                        <td align="left" valign="top" rowspan="1" colspan="1">pMCMC,
<break/>SMC
<sup>2</sup>, SIS,
<break/>optim</td>
                      </tr>
                    </tbody>
                  </table>
                </table-wrap>
                <p>The main differences between pomp and our packages are:</p>
                <list list-type="bullet">
                  <list-item>
                    <p>In pomp, parallelisation is only over independent chains
<italic toggle="yes">m
<sub>c</sub>
</italic>; parallelisation of particles is unsupported.</p>
                  </list-item>
                  <list-item>
                    <p>To write efficient code in pomp, users must write directly in C, no DSL is available. This also makes function debugging more challenging as there is no built-in parser.</p>
                  </list-item>
                  <list-item>
                    <p>Automated generation of code for arrays is not supported in pomp. For multi-compartment models this requires the user to write loop indexes over arrays/tensors manually, sometimes known as ‘C-Tran’ code.</p>
                  </list-item>
                  <list-item>
                    <p>Parameter constraints are not directly supported in pomp and must instead be implemented through monotonic transforms, such as taking the logarithm.</p>
                  </list-item>
                </list>
                <p>The main differences between libBi and our packages are:</p>
                <list list-type="bullet">
                  <list-item>
                    <p>The interface to libBi is through the command line, and parameters are set through configuration files.</p>
                  </list-item>
                  <list-item>
                    <p>Parameter setup to be used for both simulation and inference in libBi may require different model definitions.</p>
                  </list-item>
                  <list-item>
                    <p>Combining inference and forecasting tasks is possible, but requires chaining configuration files in libBi rather than relying on object reuse.</p>
                  </list-item>
                  <list-item>
                    <p>In libBi, Input and output is in the NetCDF format, which is efficient and compact, but requires extra tools and knowledge to manipulate, and is not human-readable.</p>
                  </list-item>
                  <list-item>
                    <p>To interface with R, the RBi package can be used, which converts between NetCDF format and R objects, and constructs calls to the libBi command line interface.</p>
                  </list-item>
                  <list-item>
                    <p>All functions must be written in the libBi DSL, and although this is extensive, it is still more restrictive than a full language such as R, as may be used in pomp and our packages. However, this also allows faster compiled code to be generated for the observation functions.</p>
                  </list-item>
                  <list-item>
                    <p>An alternative method of parallel random number generation is used in libBi
<sup><xref rid="ref-52" ref-type="bibr">52</xref>,
<xref rid="ref-53" ref-type="bibr">53</xref></sup>, and further parallelisation over parameters is additionally supported when using the SMC
<sup>2 </sup> algorithm for inference.</p>
                  </list-item>
                </list>
                <p>Overall we would summarise these three packages as being broadly similar in purpose and efficiency. We believe that the major advantages of our packages are the tight interface with R, the easy-to-use DSL, and the considered parallel simulation machinery. In comparing these packages, anecdotally we found the flow of data between the source and models was simplest in our packages – for our rapidly evolving COVID-19 model, this made our packages the only viable choice. The growing set of auxiliary functions specific to COVID-19 modelling in the SIRCOVID package are easily referenced between packages, demonstrating that being close to the language users are conversant with has a clear interface advantage. However, we expect that different users will have different preferences for these packages. Users will now have three good software choices available, which they can decide between based on their background and needs.</p>
              </sec>
            </sec>
            <sec>
              <title>Summary</title>
              <p>State space models are broadly used to model biological processes, particularly transmission of infectious diseases. In principle a simple state space model can readily be implemented in any number of programming languages, but keeping this model efficient, reproducible and correct, especially as it is expanded to include more processes and complexity, is a cross-disciplinary challenge. We have produced a suite of packages intended to make the mechanics of model development and fitting as simple and efficient as possible, so modellers can focus on the biology of their problem, rather than spending time on software integration challenges.</p>
              <p>Software solutions must balance the competing needs of modellers, statisticians and software developers, thus tradeoffs necessarily exist. Anecdotal experience with expert modellers led to the following design requests: use of a DSL close to R to make compiled code; reproducibility of results; parallelisation with a fair random number draws for simulation; tight integration with the R language to allow easier definition of an observation function; fast implementation of new inference methods, especially when adding compartments or age-structure; and more flexible uses of the model simulator. </p>
              <p>We aimed to produce methods which lie closer to the typical skill set and scientific interest of epidemiologists than previous state space modelling packages. Resulting model objects are lightweight and directly connected to R, making their reuse easy and flexible. No advanced programming skills are required to use the packages, and the definition of likelihood functions in R itself means that in practice few restrictions are placed on models, other than that they are Markovian. Optimised code for model simulation is automatically generated, and modern Bayesian methods such as SMC can be applied without needing a thorough understanding of the mechanics of their operation. Models are guaranteed to be reproducible, ‘play fair’ with randomness even when parallelised, and come with a suite of fully unit-tested inference methods. CPU parallelisation is efficient, and the code developed here will form the basis of future speedups using specialist hardware such as general purpose graphics processing units.</p>
              <p>These packages helped us with reliability, speed of model development, and the speed of real-time inference in our model of COVID-19 transmission in the UK. Due to their generality, we believe these packages will be more broadly useful for a range of modelling attempts, and will mean modellers do not have to reinvent the wheel each time a new model and inference method is produced.</p>
            </sec>
            <sec>
              <title>Software availability</title>
              <p>Software available from: </p>
              <list list-type="bullet">
                <list-item>
                  <p>odin:
<ext-link xlink:href="https://mrc-ide.github.io/odin" ext-link-type="uri">https://mrc-ide.github.io/odin</ext-link>
</p>
                </list-item>
                <list-item>
                  <p>odin.dust:
<ext-link xlink:href="https://mrc-ide.github.io/odin.dust" ext-link-type="uri">https://mrc-ide.github.io/odin.dust</ext-link>
</p>
                </list-item>
                <list-item>
                  <p>dust:
<ext-link xlink:href="https://mrc-ide.github.io/dust" ext-link-type="uri">https://mrc-ide.github.io/dust</ext-link>
</p>
                </list-item>
                <list-item>
                  <p>mcstate:
<ext-link xlink:href="https://mrc-ide.github.io/mcstate" ext-link-type="uri">https://mrc-ide.github.io/mcstate</ext-link>
</p>
                </list-item>
              </list>
              <p>Source code available from: </p>
              <list list-type="bullet">
                <list-item>
                  <p>odin:
<ext-link xlink:href="https://github.com/mrc-ide/odin" ext-link-type="uri">https://github.com/mrc-ide/odin</ext-link>
</p>
                </list-item>
                <list-item>
                  <p>odin.dust:
<ext-link xlink:href="https://github.com/mrc-ide/odin.dust" ext-link-type="uri">https://github.com/mrc-ide/odin.dust</ext-link>
</p>
                </list-item>
                <list-item>
                  <p>dust:
<ext-link xlink:href="https://github.com/mrc-ide/dust" ext-link-type="uri">https://github.com/mrc-ide/dust</ext-link>
</p>
                </list-item>
                <list-item>
                  <p>mcstate:
<ext-link xlink:href="https://github.com/mrc-ide/mcstate" ext-link-type="uri">https://github.com/mrc-ide/mcstate</ext-link>
</p>
                </list-item>
                <list-item>
                  <p>Plots:
<ext-link xlink:href="https://github.com/mrc-ide/odin-dust-plots" ext-link-type="uri">https://github.com/mrc-ide/odin-dust-plots</ext-link>
</p>
                </list-item>
              </list>
              <p>Archived source code as at time of publication: </p>
              <list list-type="bullet">
                <list-item>
                  <p>odin:
<ext-link xlink:href="https://doi.org/10.5281/zenodo.4772403" ext-link-type="uri">http://doi.org/10.5281/zenodo.4772403</ext-link>
<sup><xref rid="ref-54" ref-type="bibr">54</xref></sup>
</p>
                </list-item>
                <list-item>
                  <p>odin.dust:
<ext-link xlink:href="https://doi.org/10.5281/zenodo.4772398" ext-link-type="uri">http://doi.org/10.5281/zenodo.4772398</ext-link>
<sup><xref rid="ref-55" ref-type="bibr">55</xref></sup>
</p>
                </list-item>
                <list-item>
                  <p>dust:
<ext-link xlink:href="https://doi.org/10.5281/zenodo.4772395" ext-link-type="uri">https://doi.org/10.5281/zenodo.4772395</ext-link>
<sup><xref rid="ref-56" ref-type="bibr">56</xref></sup>
</p>
                </list-item>
                <list-item>
                  <p>mcstate:
<ext-link xlink:href="https://doi.org/10.5281/zenodo.4772455" ext-link-type="uri">http://doi.org/10.5281/zenodo.4772455</ext-link>
<sup><xref rid="ref-57" ref-type="bibr">57</xref></sup>
</p>
                </list-item>
                <list-item>
                  <p>Plots:
<ext-link xlink:href="https://doi.org/10.5281/zenodo.4293396" ext-link-type="uri">https://doi.org/10.5281/zenodo.4293396</ext-link>
<sup><xref rid="ref-58" ref-type="bibr">58</xref></sup>
</p>
                </list-item>
              </list>
              <p>Software license: MIT</p>
            </sec>
          </body>
          <back>
            <ack>
              <title>Acknowledgements</title>
              <p>We are grateful to both the Imperial COVID-19 response team and the RESIDE group, who advised on the COVID-19 model and R integration respectively. We would also like the thank the Tensorflow developers, as we based our code for rejection sampling for binomial and Poisson draw on their implementation. The COVID-19 death data fitted to was provided by the Office for National Statistics, which is provided freely and openly under the Open Government Licence.</p>
            </ack>
            <ref-list>
              <ref id="ref-1">
                <label>1</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grassly</surname><given-names>NC</given-names></name><name><surname>Fraser</surname><given-names>C</given-names></name></person-group>:
<article-title>Mathematical models of infectious disease transmission.</article-title><source><italic toggle="yes">Nat Rev Microbiol.</italic></source><year>2008</year>;<volume>6</volume>(<issue>6</issue>):<fpage>477</fpage>–<lpage>487</lpage>.
<pub-id pub-id-type="doi">10.1038/nrmicro1845</pub-id>
<!--<pub-id pub-id-type="pmcid">7097581</pub-id>-->
<?supplied-pmid 18533288?><pub-id pub-id-type="pmid">18533288</pub-id></mixed-citation>
              </ref>
              <ref id="ref-2">
                <label>2</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitty</surname><given-names>CJM</given-names></name></person-group>:
<article-title>The contribution of biological, mathematical, clinical, engineering and social sciences to combatting the west african ebola epidemic.</article-title><source><italic toggle="yes">Philos Trans R Soc Lond B Biol Sci.</italic></source><year>2017</year>;<volume>372</volume>(<issue>1721</issue>):<fpage>20160293</fpage>.
<pub-id pub-id-type="doi">10.1098/rstb.2016.0293</pub-id><!--<pub-id pub-id-type="pmcid">5394633</pub-id>--><?supplied-pmid 28396466?><pub-id pub-id-type="pmid">28396466</pub-id></mixed-citation>
              </ref>
              <ref id="ref-3">
                <label>3</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heslop</surname><given-names>DJ</given-names></name><name><surname>Chughtai</surname><given-names>AA</given-names></name><name><surname>Bui</surname><given-names>CM</given-names></name><etal/></person-group>:
<article-title>Publicly available software tools for decision-makers during an emergent epidemic-systematic evaluation of utility and usability.</article-title><source><italic toggle="yes">Epidemics.</italic></source><year>2017</year>;<volume>21</volume>:<fpage>1</fpage>–<lpage>12</lpage>.
<pub-id pub-id-type="doi">10.1016/j.epidem.2017.04.002</pub-id>
<?supplied-pmid 28576351?><pub-id pub-id-type="pmid">28576351</pub-id></mixed-citation>
              </ref>
              <ref id="ref-4">
                <label>4</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>RN</given-names></name></person-group>:
<article-title>Epidemiological models are important tools for guiding COVID-19 interventions.</article-title><source><italic toggle="yes">BMC Med.</italic></source><year>2020</year>;<volume>18</volume>(<issue>1</issue>):<fpage>152</fpage>.
<pub-id pub-id-type="doi">10.1186/s12916-020-01628-4</pub-id><!--<pub-id pub-id-type="pmcid">7246085</pub-id>--><?supplied-pmid 32448247?><pub-id pub-id-type="pmid">32448247</pub-id></mixed-citation>
              </ref>
              <ref id="ref-5">
                <label>5</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>SN</given-names></name><name><surname>Fanelli</surname><given-names>D</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group>:
<article-title>What does research reproducibility mean?</article-title><source><italic toggle="yes">Sci Transl Med.</italic></source><year>2016</year>;<volume>8</volume>(<issue>341</issue>):<fpage>341ps12</fpage>.
<pub-id pub-id-type="doi">10.1126/scitranslmed.aaf5027</pub-id><?supplied-pmid 27252173?><pub-id pub-id-type="pmid">27252173</pub-id></mixed-citation>
              </ref>
              <ref id="ref-6">
                <label>6</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medley</surname><given-names>JK</given-names></name><name><surname>Goldberg</surname><given-names>AP</given-names></name><name><surname>Karr</surname><given-names>JR</given-names></name></person-group>:
<article-title>Guidelines for reproducibly building and simulating systems biology models.</article-title><source><italic toggle="yes">IEEE Trans Biomed Eng.</italic></source><year>2016</year>;<volume>63</volume>(<issue>10</issue>):<fpage>2015</fpage>–<lpage>2020</lpage>.
<pub-id pub-id-type="doi">10.1109/TBME.2016.2591960</pub-id>
<!--<pub-id pub-id-type="pmcid">5131863</pub-id>-->
<?supplied-pmid 27429432?><pub-id pub-id-type="pmid">27429432</pub-id></mixed-citation>
              </ref>
              <ref id="ref-7">
                <label>7</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Dallmeier-Tiessen</surname><given-names>S</given-names></name><name><surname>Dasler</surname><given-names>R</given-names></name><etal/></person-group>:
<article-title>Open is not enough.</article-title><source><italic toggle="yes">Nat Phys.</italic></source><year>2019</year>;<volume>15</volume>(<issue>2</issue>):<fpage>113</fpage>–<lpage>119</lpage>.
<pub-id pub-id-type="doi">10.1038/s41567-018-0342-2</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-8">
                <label>8</label>
                <mixed-citation publication-type="journal"><collab>R Core Team</collab>:
<article-title>R: A Language and Environment for Statistical Computing</article-title>. R Foundation for Statistical Computing, Vienna, Austria.<year>2019</year>.
<ext-link xlink:href="https://www.R-project.org/" ext-link-type="uri">Reference Source</ext-link></mixed-citation>
              </ref>
              <ref id="ref-9">
                <label>9</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>A</given-names></name><name><surname>Nguyen</surname><given-names>D</given-names></name><name><surname>Ionides</surname><given-names>E</given-names></name></person-group>:
<article-title>Statistical inference for partially observed markov processes via the R package pomp.</article-title><source><italic toggle="yes">J Stat Softw, Articles.</italic></source><year>2016</year>;<volume>69</volume>(<issue>12</issue>):<fpage>1</fpage>–<lpage>43</lpage>.
<pub-id pub-id-type="doi">10.18637/jss.v069.i12</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-10">
                <label>10</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>LM</given-names></name></person-group>:
<article-title>Bayesian State-Space modelling on High-Performance hardware using LibBi.</article-title><source><italic toggle="yes">J Stat Softw.</italic></source><year>2015</year>;<volume>067</volume>(<issue>i10</issue>).
<pub-id pub-id-type="doi">10.18637/jss.v067.i10</pub-id></mixed-citation>
              </ref>
              <ref id="ref-11">
                <label>11</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Deursen</surname><given-names>A</given-names></name><name><surname>Klint</surname><given-names>P</given-names></name><name><surname>Visser</surname><given-names>J</given-names></name></person-group>:
<article-title>Domain-specific languages: An annotated bibliography.</article-title><source><italic toggle="yes">ACM SIGPLAN Notices.</italic></source><year>2000</year>;<volume>35</volume>(<issue>6</issue>):<fpage>26</fpage>–<lpage>36</lpage>.
<pub-id pub-id-type="doi">10.1145/352029.352035</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-12">
                <label>12</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wickham</surname><given-names>H</given-names></name></person-group>:
<article-title>Advanced R</article-title>. CRC Press.<year>2014</year>.
<pub-id pub-id-type="doi">10.1201/b17487</pub-id></mixed-citation>
              </ref>
              <ref id="ref-13">
                <label>13</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>JS</given-names></name><name><surname>Chen</surname><given-names>R</given-names></name></person-group>:
<article-title>Sequential monte carlo methods for dynamic systems.</article-title><source><italic toggle="yes">J Am Stat Assoc.</italic></source><year>1998</year>;<volume>93</volume>(<issue>443</issue>):<fpage>1032</fpage>–<lpage>1044</lpage>.
<pub-id pub-id-type="doi">10.1080/01621459.1998.10473765</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-14">
                <label>14</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Del Moral</surname><given-names>P</given-names></name></person-group>:
<article-title>Nonlinear filtering: Interacting particle resolution.</article-title><source><italic toggle="yes">Comptes Rendus de l’Académie des Sciences -Series I -Mathematics.</italic></source><year>1997</year>;<volume>325</volume>(<issue>6</issue>):<fpage>653</fpage>–<lpage>658</lpage>.
<ext-link xlink:href="http://people.bordeaux.inria.fr/pierre.delmoral/delmoral96nonlinear.pdf" ext-link-type="uri">Reference Source</ext-link>
</mixed-citation>
              </ref>
              <ref id="ref-15">
                <label>15</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arulampalam</surname><given-names>MS</given-names></name><name><surname>Maskell</surname><given-names>S</given-names></name><name><surname>Gordon</surname><given-names>N</given-names></name><etal/></person-group>:
<article-title>A tutorial on particle filters for online nonlinear/non-gaussian bayesian tracking.</article-title><source><italic toggle="yes">IEEE Trans Signal Process.</italic></source><year>2002</year>;<volume>50</volume>(<issue>2</issue>):<fpage>174</fpage>–<lpage>188</lpage>.
<ext-link xlink:href="https://www.irisa.fr/aspi/legland/ensta/ref/arulampalam02a.pdf" ext-link-type="uri">Reference Source</ext-link>
</mixed-citation>
              </ref>
              <ref id="ref-16">
                <label>16</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schön</surname><given-names>TB</given-names></name><name><surname>Svensson</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>L</given-names></name><etal/></person-group>:
<article-title>Probabilistic learning of nonlinear dynamical systems using sequential monte carlo.</article-title><source><italic toggle="yes">Mech Syst Signal Process.</italic></source><year>2018</year>;<volume>104</volume>:<fpage>866</fpage>–<lpage>883</lpage>.
<pub-id pub-id-type="doi">10.1016/j.ymssp.2017.10.033</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-17">
                <label>17</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Endo</surname><given-names>A</given-names></name><name><surname>van Leeuwen</surname><given-names>E</given-names></name><name><surname>Baguelin</surname><given-names>M</given-names></name></person-group>:
<article-title>Introduction to particle markov-chain monte carlo for disease dynamics modellers.</article-title><source><italic toggle="yes">Epidemics.</italic></source><year>2019</year>;<volume>29</volume>:<fpage>100363</fpage>.
<pub-id pub-id-type="doi">10.1016/j.epidem.2019.100363</pub-id><?supplied-pmid 31587877?><pub-id pub-id-type="pmid">31587877</pub-id></mixed-citation>
              </ref>
              <ref id="ref-18">
                <label>18</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ionides</surname><given-names>EL</given-names></name><name><surname>Nguyen</surname><given-names>D</given-names></name><name><surname>Atchadé</surname><given-names>Y</given-names></name><etal/></person-group>:
<article-title>Inference for dynamic and latent variable models via iterated, perturbed Bayes maps.</article-title><source><italic toggle="yes">Proc Natl Acad Sci U S A.</italic></source><year>2015</year>;<volume>112</volume>(<issue>3</issue>):<fpage>719</fpage>–<lpage>24</lpage>.
<pub-id pub-id-type="doi">10.1073/pnas.1410597112</pub-id>
<!--<pub-id pub-id-type="pmcid">4311819</pub-id>-->
<?supplied-pmid 25568084?><pub-id pub-id-type="pmid">25568084</pub-id></mixed-citation>
              </ref>
              <ref id="ref-19">
                <label>19</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dagum</surname><given-names>L</given-names></name><name><surname>Menon</surname><given-names>R</given-names></name></person-group>:
<article-title>OpenMP: An Industry-Standard API for Shared-Memory programming.</article-title><source><italic toggle="yes">IEEE Comput Sci Eng.</italic></source><year>1998</year>;<volume>5</volume>(<issue>1</issue>):<fpage>46</fpage>–<lpage>55</lpage>.
<pub-id pub-id-type="doi">10.1109/99.660313</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-20">
                <label>20</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knock</surname><given-names>ES</given-names></name><name><surname>Whittles</surname><given-names>LK</given-names></name><name><surname>Lees</surname><given-names>JA</given-names></name><etal/></person-group>:
<article-title>The 2020 SARS-CoV-2 epidemic in England: key epidemiological drivers and impact of interventions.</article-title><source><italic toggle="yes">medRxiv.</italic></source><year>2021</year>; 2021.01.11.21249564.
<pub-id pub-id-type="doi">10.1101/2021.01.11.21249564</pub-id></mixed-citation>
              </ref>
              <ref id="ref-21">
                <label>21</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bauke</surname><given-names>H</given-names></name><name><surname>Mertens</surname><given-names>S</given-names></name></person-group>:
<article-title>Pseudo random coins show more heads than tails.</article-title><source><italic toggle="yes">J Stat Phys.</italic></source><year>2004</year>;<volume>114</volume>(<issue>3</issue>):<fpage>1149</fpage>–<lpage>1169</lpage>.
<pub-id pub-id-type="doi">10.1023/B:JOSS.0000012521.67853.9a</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-22">
                <label>22</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bauke</surname><given-names>H</given-names></name><name><surname>Mertens</surname><given-names>S</given-names></name></person-group>:
<article-title>Random numbers for large-scale distributed Monte Carlo simulations.</article-title><source><italic toggle="yes">Phys Rev E Stat Nonlin Soft Matter Phys.</italic></source><year>2007</year>;<volume>75</volume>(<issue>6 Pt 2</issue>):<fpage>066701</fpage>.
<pub-id pub-id-type="doi">10.1103/PhysRevE.75.066701</pub-id><?supplied-pmid 17677383?><pub-id pub-id-type="pmid">17677383</pub-id></mixed-citation>
              </ref>
              <ref id="ref-23">
                <label>23</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blackman</surname><given-names>D</given-names></name><name><surname>Vigna</surname><given-names>S</given-names></name></person-group>:
<article-title>Scrambled linear pseudorandom number generators</article-title>.<year>2018</year>.
<ext-link xlink:href="https://arxiv.org/abs/1805.01407" ext-link-type="uri">Reference Source</ext-link></mixed-citation>
              </ref>
              <ref id="ref-24">
                <label>24</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsumoto</surname><given-names>M</given-names></name><name><surname>Nishimura</surname><given-names>T</given-names></name></person-group>:
<article-title>Mersenne twister: a 623-dimensionally equidistributed uniform pseudo-random number generator.</article-title><source><italic toggle="yes">ACM Trans Model Comput Simul.</italic></source><year>1998</year>;<volume>8</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>30</lpage>.
<pub-id pub-id-type="doi">10.1145/272991.272995</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-25">
                <label>25</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steele</surname><given-names>GL</given-names></name><name><surname>Lea</surname><given-names>D</given-names></name><name><surname>Flood</surname><given-names>CH</given-names></name></person-group>:
<article-title>Fast splittable pseudorandom number generators.</article-title><source><italic toggle="yes">SIGPLAN Not.</italic></source><year>2014</year>;<volume>49</volume>(<issue>10</issue>):<fpage>453</fpage>–<lpage>472</lpage>.
<pub-id pub-id-type="doi">10.1145/2660193.2660195</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-26">
                <label>26</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abadi</surname><given-names>M</given-names></name><name><surname>Agarwal</surname><given-names>A</given-names></name><name><surname>Barham</surname><given-names>P</given-names></name><etal/></person-group>:
<article-title>TensorFlow: Large-scale machine learning on heterogeneous systems</article-title>.<year>2015</year>.
<ext-link xlink:href="https://www.tensorflow.org/" ext-link-type="uri">Reference Source</ext-link></mixed-citation>
              </ref>
              <ref id="ref-27">
                <label>27</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Box</surname><given-names>GEP</given-names></name><name><surname>Muller</surname><given-names>ME</given-names></name></person-group>:
<article-title>A note on the generation of random normal deviates.</article-title><source><italic toggle="yes">Ann Math Stat.</italic></source><year>1958</year>;<volume>29</volume>(<issue>2</issue>):<fpage>610</fpage>–<lpage>611</lpage>.
<pub-id pub-id-type="doi">10.1214/aoms/1177706645</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-28">
                <label>28</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devroye</surname><given-names>L</given-names></name></person-group>:
<article-title>Non-Uniform Random Variate Generation</article-title>. Springer, New York, NY.<year>1986</year>.
<pub-id pub-id-type="doi">10.1007/978-1-4613-8643-8</pub-id></mixed-citation>
              </ref>
              <ref id="ref-29">
                <label>29</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hörmann</surname><given-names>W</given-names></name></person-group>:
<article-title>The generation of binomial random variates.</article-title><source><italic toggle="yes">J Stat Comput Sim.</italic></source><year>1993</year>;<volume>46</volume>(<issue>1–2</issue>):<fpage>101</fpage>–<lpage>110</lpage>.
<pub-id pub-id-type="doi">10.1080/00949659308811496</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-30">
                <label>30</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knuth</surname><given-names>DE</given-names></name></person-group>:
<article-title>The art of computer programming</article-title>, volume 2 (3rd ed.): seminumerical algorithms. Addison-Wesley Longman Publishing Co., Inc., USA,<year>1997</year>.
<ext-link xlink:href="https://seriouscomputerist.atariverse.com/media/pdf/book/ArtofComputerProgramming-Volume2(SeminumericalAlgorithms).pdf" ext-link-type="uri">Reference Source</ext-link></mixed-citation>
              </ref>
              <ref id="ref-31">
                <label>31</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hörmann</surname><given-names>W</given-names></name></person-group>:
<article-title>The transformed rejection method for generating poisson random variables.</article-title><source><italic toggle="yes">Insur Math Econ.</italic></source><year>1993</year>;<volume>12</volume>(<issue>1</issue>):<fpage>39</fpage>–<lpage>45</lpage>.
<pub-id pub-id-type="doi">10.1016/0167-6687(93)90997-4</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-32">
                <label>32</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heston</surname><given-names>SL</given-names></name></person-group>:
<article-title>A Closed-Form solution for options with stochastic volatility with applications to bond and currency options.</article-title><source><italic toggle="yes">Rev Financ Stud.</italic></source><year>1993</year>;<volume>6</volume>(<issue>2</issue>):<fpage>327</fpage>–<lpage>343</lpage>.
<pub-id pub-id-type="doi">10.1093/rfs/6.2.327</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-33">
                <label>33</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doucet</surname><given-names>A</given-names></name><name><surname>Johansen</surname><given-names>AM</given-names></name></person-group>:
<article-title>A tutorial on particle filtering and smoothing: Fifteen years later.</article-title><source><italic toggle="yes">Handbook of Nonlinear Filtering.</italic></source><year>2009</year>;<volume>12</volume>:<fpage>01</fpage>.
<ext-link xlink:href="http://web-static-aws.seas.harvard.edu/courses/cs281/papers/doucet-johansen.pdf" ext-link-type="uri">Reference Source</ext-link></mixed-citation>
              </ref>
              <ref id="ref-34">
                <label>34</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kermack</surname><given-names>WO</given-names></name><name><surname>McKendrick</surname><given-names>AG</given-names></name><name><surname>Walker</surname><given-names>GT</given-names></name></person-group>:
<article-title>A contribution to the mathematical theory of epidemics.</article-title><source><italic toggle="yes">Proceedings of the Royal Society of London A.</italic></source><year>1927</year>;<volume>115</volume>(<issue>772</issue>):<fpage>700</fpage>–<lpage>721</lpage>.
<pub-id pub-id-type="doi">10.1098/rspa.1927.0118</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-35">
                <label>35</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>RM</given-names></name><name><surname>Anderson</surname><given-names>B</given-names></name><name><surname>May</surname><given-names>RM</given-names></name></person-group>:
<article-title>Infectious Diseases of Humans: Dynamics and Control</article-title>. OUP Oxford,<year>1992</year>.
<ext-link xlink:href="https://books.google.co.in/books/about/Infectious_Diseases_of_Humans.html?id=HT0--xXBguQC" ext-link-type="uri">Reference Source</ext-link></mixed-citation>
              </ref>
              <ref id="ref-36">
                <label>36</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>EJ</given-names></name><name><surname>Allen</surname><given-names>LJS</given-names></name><name><surname>Arciniega</surname><given-names>A</given-names></name><etal/></person-group>:
<article-title>Construction of equivalent stochastic differential equation models.</article-title><source><italic toggle="yes">Stoch Anal Appl.</italic></source><year>2008</year>;<volume>26</volume>(<issue>2</issue>):<fpage>274</fpage>–<lpage>297</lpage>.
<pub-id pub-id-type="doi">10.1080/07362990701857129</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-37">
                <label>37</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>LJS</given-names></name></person-group>:
<article-title>A primer on stochastic epidemic models: Formulation, numerical simulation, and analysis.</article-title><source><italic toggle="yes">Infect Dis Model.</italic></source><year>2017</year>;<volume>2</volume>(<issue>2</issue>):<fpage>128</fpage>–<lpage>142</lpage>.
<pub-id pub-id-type="doi">10.1016/j.idm.2017.03.001</pub-id>
<!--<pub-id pub-id-type="pmcid">6002090</pub-id>-->
<?supplied-pmid 29928733?><pub-id pub-id-type="pmid">29928733</pub-id></mixed-citation>
              </ref>
              <ref id="ref-38">
                <label>38</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gillespie</surname><given-names>DT</given-names></name></person-group>:
<article-title>Approximate accelerated stochastic simulation of chemically reacting systems.</article-title><source><italic toggle="yes">J Chem Phys.</italic></source><year>2001</year>;<volume>115</volume>(<issue>4</issue>):<fpage>1716</fpage>–<lpage>1733</lpage>.
<ext-link xlink:href="https://homepages.inf.ed.ac.uk/stg/research/stochasticsimulation/papers/JChemPhys_115_1716.pdf" ext-link-type="uri">Reference Source</ext-link>
</mixed-citation>
              </ref>
              <ref id="ref-39">
                <label>39</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plummer</surname><given-names>M</given-names></name><name><surname>Best</surname><given-names>N</given-names></name><name><surname>Cowles</surname><given-names>K</given-names></name><etal/></person-group>:
<article-title>CODA: convergence diagnosis and output analysis for MCMC.</article-title><source><italic toggle="yes">R News.</italic></source><year>2006</year>;<volume>6</volume>(<issue>1</issue>):<fpage>7</fpage>–<lpage>11</lpage>.
<ext-link xlink:href="http://oro.open.ac.uk/22547/" ext-link-type="uri">Reference Source</ext-link>
</mixed-citation>
              </ref>
              <ref id="ref-40">
                <label>40</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberts</surname><given-names>GO</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Gilks</surname><given-names>WR</given-names></name></person-group>:
<article-title>Weak convergence and optimal scaling of random walk metropolis algorithms.</article-title><source><italic toggle="yes">Ann Appl Probab.</italic></source><year>1997</year>;<volume>7</volume>(<issue>1</issue>):<fpage>110</fpage>–<lpage>120</lpage>.
<pub-id pub-id-type="doi">10.1214/aoap/1034625254</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-41">
                <label>41</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ionides</surname><given-names>EL</given-names></name><name><surname>Breto</surname><given-names>C</given-names></name><name><surname>Park</surname><given-names>J</given-names></name><etal/></person-group>:
<article-title>Monte Carlo profile confidence intervals for dynamic systems.</article-title><source><italic toggle="yes">J R Soc Interface.</italic></source><year>2017</year>;<volume>14</volume>(<issue>132</issue>): 20170126.
<pub-id pub-id-type="doi">10.1098/rsif.2017.0126</pub-id><!--<pub-id pub-id-type="pmcid">5550967</pub-id>--><?supplied-pmid 28679663?><pub-id pub-id-type="pmid">28679663</pub-id></mixed-citation>
              </ref>
              <ref id="ref-42">
                <label>42</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ning</surname><given-names>N</given-names></name><name><surname>Ionides</surname><given-names>E</given-names></name><name><surname>Ritov</surname><given-names>Y</given-names></name></person-group>:
<article-title>Scalable Monte Carlo Inference and Rescaled Local Asymptotic Normality</article-title>. arXiv.<year>2020</year>.
<ext-link xlink:href="https://arxiv.org/abs/2007.00723" ext-link-type="uri">Reference Source</ext-link></mixed-citation>
              </ref>
              <ref id="ref-43">
                <label>43</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doucet</surname><given-names>A</given-names></name><name><surname>Pitt</surname><given-names>MK</given-names></name><name><surname>Deligiannidis</surname><given-names>G</given-names></name><etal/></person-group>:
<article-title>Efficient implementation of Markov chain Monte Carlo when using an unbiased likelihood estimator.</article-title><source><italic toggle="yes">Biometrika.</italic></source><year>2015</year>;<volume>102</volume>(<issue>2</issue>):<fpage>295</fpage>–<lpage>313</lpage>.
<pub-id pub-id-type="doi">10.1093/biomet/asu075</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-44">
                <label>44</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McElreath</surname><given-names>R</given-names></name></person-group>:
<article-title>Statistical rethinking: A Bayesian course with examples in R and Stan</article-title>. CRC press.<year>2020</year>.
<ext-link xlink:href="https://www.routledge.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-STAN/McElreath/p/book/9780367139919" ext-link-type="uri">Reference Source</ext-link></mixed-citation>
              </ref>
              <ref id="ref-45">
                <label>45</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mossong</surname><given-names>J</given-names></name><name><surname>Hens</surname><given-names>N</given-names></name><name><surname>Jit</surname><given-names>M</given-names></name><etal/></person-group>:
<article-title>Social contacts and mixing patterns relevant to the spread of infectious diseases.</article-title><source><italic toggle="yes">PLoS Med.</italic></source><year>2008</year>;<volume>5</volume>(<issue>3</issue>):<fpage>e74</fpage>.
<pub-id pub-id-type="doi">10.1371/journal.pmed.0050074</pub-id><!--<pub-id pub-id-type="pmcid">2270306</pub-id>--><?supplied-pmid 18366252?><pub-id pub-id-type="pmid">18366252</pub-id></mixed-citation>
              </ref>
              <ref id="ref-46">
                <label>46</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plummer</surname><given-names>M</given-names></name></person-group>:
<article-title>JAGS: A program for analysis of bayesian graphical models using gibbs sampling</article-title>. In
<italic toggle="yes">Proceedings of the 3rd international workshop on distributed statistical computing. </italic><year>2003</year>;<volume>124</volume>:<fpage>1</fpage>–<lpage>10</lpage>.
<ext-link xlink:href="https://www.r-project.org/conferences/DSC-2003/Proceedings/Plummer.pdf" ext-link-type="uri">Reference Source</ext-link>
</mixed-citation>
              </ref>
              <ref id="ref-47">
                <label>47</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Guo</surname><given-names>J</given-names></name></person-group>:
<article-title>Stan: A probabilistic programming language for bayesian inference and optimization.</article-title><source><italic toggle="yes">J Educ Behav Stat.</italic></source><year>2015</year>;<volume>40</volume>(<issue>5</issue>):<fpage>530</fpage>–<lpage>543</lpage>.
<pub-id pub-id-type="doi">10.3102/1076998615606113</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-48">
                <label>48</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrade</surname><given-names>J</given-names></name><name><surname>Duggan</surname><given-names>J</given-names></name></person-group>:
<article-title>An evaluation of hamiltonian monte carlo performance to calibrate age-structured compartmental SEIR models to incidence data.</article-title><source><italic toggle="yes">Epidemics.</italic></source><year>2020</year>;<volume>33</volume>:<fpage>100415</fpage>.
<pub-id pub-id-type="doi">10.1016/j.epidem.2020.100415</pub-id><?supplied-pmid 33212347?><pub-id pub-id-type="pmid">33212347</pub-id></mixed-citation>
              </ref>
              <ref id="ref-49">
                <label>49</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toni</surname><given-names>T</given-names></name><name><surname>Welch</surname><given-names>D</given-names></name><name><surname>Strelkowa</surname><given-names>N</given-names></name><etal/></person-group>:
<article-title>Approximate Bayesian computation scheme for parameter inference and model selection in dynamical systems.</article-title><source><italic toggle="yes">J R Soc Interface.</italic></source><year>2009</year>;<volume>6</volume>(<issue>31</issue>):<fpage>187</fpage>–<lpage>202</lpage>.
<pub-id pub-id-type="doi">10.1098/rsif.2008.0172</pub-id>
<!--<pub-id pub-id-type="pmcid">2658655</pub-id>-->
<?supplied-pmid 19205079?><pub-id pub-id-type="pmid">19205079</pub-id></mixed-citation>
              </ref>
              <ref id="ref-50">
                <label>50</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fourment</surname><given-names>M</given-names></name><name><surname>Claywell</surname><given-names>BC</given-names></name><name><surname>Dinh</surname><given-names>V</given-names></name><etal/></person-group>:
<article-title>Effective online Bayesian phylogenetics via sequential Monte Carlo with guided proposals.</article-title><source><italic toggle="yes">Syst Biol.</italic></source><year>2018</year>;<volume>67</volume>(<issue>3</issue>):<fpage>490</fpage>–<lpage>502</lpage>.
<pub-id pub-id-type="doi">10.1093/sysbio/syx090</pub-id>
<!--<pub-id pub-id-type="pmcid">5920299</pub-id>-->
<?supplied-pmid 29186587?><pub-id pub-id-type="pmid">29186587</pub-id></mixed-citation>
              </ref>
              <ref id="ref-51">
                <label>51</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doucet</surname><given-names>A</given-names></name><name><surname>Godsill</surname><given-names>S</given-names></name><name><surname>Andrieu</surname><given-names>C</given-names></name></person-group>:
<article-title>On sequential Monte Carlo sampling methods for Bayesian filtering.</article-title><source><italic toggle="yes">Stat Comput.</italic></source><year>2000</year>;<volume>10</volume>:<fpage>197</fpage>–<lpage>208</lpage>.
<pub-id pub-id-type="doi">10.1023/A:1008935410038</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-52">
                <label>52</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>L’Ecuyer</surname><given-names>P</given-names></name></person-group>:
<article-title>Good parameters and implementations for combined multiple recursive random number generators.</article-title><source><italic toggle="yes">Oper Res.</italic></source><year>1999</year>;<volume>47</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>173</lpage>.
<pub-id pub-id-type="doi">10.1287/opre.47.1.159</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-53">
                <label>53</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>L’ecuyer</surname><given-names>P</given-names></name><name><surname>Simard</surname><given-names>R</given-names></name><name><surname>Chen</surname><given-names>EJ</given-names></name><etal/></person-group>:
<article-title>An object-oriented random-number package with many long streams and substreams.</article-title><source><italic toggle="yes">Oper Res.</italic></source><year>2002</year>;<volume>50</volume>(<issue>6</issue>):<fpage>923</fpage>–<lpage>1091</lpage>.
<pub-id pub-id-type="doi">10.1287/opre.50.6.1073.358</pub-id>
</mixed-citation>
              </ref>
              <ref id="ref-54">
                <label>54</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>FitzJohn</surname><given-names>R</given-names></name></person-group>:
<article-title>mrc-ide/odin: v1.1.12</article-title>(Version v1.1.12).
<source><italic toggle="yes">Zenodo.</italic></source><year>2020</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4772403</pub-id></mixed-citation>
              </ref>
              <ref id="ref-55">
                <label>55</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lees</surname><given-names>J</given-names></name><name><surname>FitzJohn</surname><given-names>R</given-names></name></person-group>:
<article-title>mrc-ide/odin.dust: v0.2.7</article-title>(Version v0.2.7).
<source><italic toggle="yes">Zenodo.</italic></source><year>2020</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4772398</pub-id></mixed-citation>
              </ref>
              <ref id="ref-56">
                <label>56</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lees</surname><given-names>J</given-names></name><name><surname>FitzJohn</surname><given-names>R</given-names></name></person-group>:
<article-title>mrc-ide/dust: v0.9.3</article-title>(Version v0.9.3).
<source><italic toggle="yes">Zenodo.</italic></source><year>2020</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4772395</pub-id></mixed-citation>
              </ref>
              <ref id="ref-57">
                <label>57</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lees</surname><given-names>J</given-names></name><name><surname>FitzJohn</surname><given-names>R</given-names></name></person-group>:
<article-title>mrc-ide/mcstate: v0.6.0</article-title>(Version v0.6.0).
<source><italic toggle="yes">Zenodo.</italic></source><year>2020</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4772455</pub-id></mixed-citation>
              </ref>
              <ref id="ref-58">
                <label>58</label>
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lees</surname><given-names>J</given-names></name><name><surname>FitzJohn</surname><given-names>R</given-names></name></person-group>:
<article-title>mrc-ide/odin-dust-plots: Plots at submission</article-title>(Version v1.0.0).
<source><italic toggle="yes">Zenodo.</italic></source><year>2020</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4293396</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
          <sub-article article-type="peer-review" id="report44387">
            <front-stub>
              <article-id pub-id-type="doi">10.21956/wellcomeopenres.18728.r44387</article-id>
              <title-group>
                <article-title>Reviewer response for version 2</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Ionides</surname>
                    <given-names>Edward</given-names>
                  </name>
                  <xref rid="r44387a1" ref-type="aff">1</xref>
                  <role>Referee</role>
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4190-0174</contrib-id>
                </contrib>
                <aff id="r44387a1"><label>1</label>Department of Statistics, University of Michigan, Ann Arbor, MI, USA</aff>
              </contrib-group>
              <author-notes>
                <fn fn-type="COI-statement">
                  <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
                </fn>
              </author-notes>
              <pub-date pub-type="epub">
                <day>27</day>
                <month>10</month>
                <year>2021</year>
              </pub-date>
              <permissions>
                <copyright-statement>Copyright: © 2021 Ionides E</copyright-statement>
                <copyright-year>2021</copyright-year>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
                </license>
              </permissions>
              <related-article related-article-type="peer-reviewed-article" ext-link-type="doi" id="relatedArticleReport44387" xlink:href="10.12688/wellcomeopenres.16466.2">Version 2</related-article>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>recommendation</meta-name>
                  <meta-value>approve</meta-value>
                </custom-meta>
              </custom-meta-group>
            </front-stub>
            <body>
              <p>I've looked through the revision, which is thorough. Please update the status of my recommendation to "Approved". I did notice many capitalization errors in the references - perhaps an artifact of using BibTex? I recommend these are fixed, though it is not scientifically important.”</p>
              <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
              <p>Yes</p>
              <p>Is the rationale for developing the new software tool clearly explained?</p>
              <p>Yes</p>
              <p>Is the description of the software tool technically sound?</p>
              <p>Yes</p>
              <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
              <p>Yes</p>
              <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
              <p>Yes</p>
              <p>Reviewer Expertise:</p>
              <p>NA</p>
              <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
            </body>
          </sub-article>
          <sub-article article-type="peer-review" id="report41899">
            <front-stub>
              <article-id pub-id-type="doi">10.21956/wellcomeopenres.18131.r41899</article-id>
              <title-group>
                <article-title>Reviewer response for version 1</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Niehus</surname>
                    <given-names>Rene</given-names>
                  </name>
                  <xref rid="r41899a1" ref-type="aff">1</xref>
                  <role>Referee</role>
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6751-4124</contrib-id>
                </contrib>
                <aff id="r41899a1"><label>1</label>Center for Communicable Disease Dynamics, Department of Epidemiology, Harvard T H Chan School of Public Health, Boston, MA, USA</aff>
              </contrib-group>
              <author-notes>
                <fn fn-type="COI-statement">
                  <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
                </fn>
              </author-notes>
              <pub-date pub-type="epub">
                <day>26</day>
                <month>1</month>
                <year>2021</year>
              </pub-date>
              <permissions>
                <copyright-statement>Copyright: © 2021 Niehus R</copyright-statement>
                <copyright-year>2021</copyright-year>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
                </license>
              </permissions>
              <related-article related-article-type="peer-reviewed-article" ext-link-type="doi" id="relatedArticleReport41899" xlink:href="10.12688/wellcomeopenres.16466.1">Version 1</related-article>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>recommendation</meta-name>
                  <meta-value>approve</meta-value>
                </custom-meta>
              </custom-meta-group>
            </front-stub>
            <body>
              <p>Knock
<italic toggle="yes">et al</italic>. have developed a software that allows building and fitting of state space models to (partially) observed data and that allows simulation from those models. Like tools such as WinBugs or Stan their tool allows the user to define models in language that is similar to statistical modelling language. It is efficient in fitting time-series via transcribing the model into fast C++ language, parallelisation, and the use of particle filtering, similar to pomp or libBo. It integrates well with commonly used R environment, and it is thus available to use for a wide group of researchers.</p>
              <p> I would not be surprised if this software and its iterations took an important role for predicting and understanding the ongoing COVID-19 pandemic. A key determinant for this is its development and refinement by an interdisciplinary team, and working with feedback from use case in an urgent public health crisis.</p>
              <p> I truly enjoyed reading this paper, and I would like to suggest a few points of improvement, before I make some suggestions for improved readability.
<list list-type="order"><list-item><p>The authors describe at first some general concepts, then the different components of their framework, the random number generator, its operation, and finally a comparison with other tools. It should be made clearer at the very beginning, in what ways this software advances current tools, and combines the advantages of different tools. It remains unclear if the dust-object idea containing particles is novel, or an adaptation. I also suggest extending Table 1 to include several of the other features that differ between dust, pomp, and libBi.</p></list-item><list-item><p>The tool of the authors follows a Bayesian framework, which I consider especially suitable in the context of COVID-19 modelling where information on biological parameters is added constantly through various trials. I am not entirely sure, but I think the Figure 3 shows a prior-predictive simulations/checks: Once a user has written the structure of a model and they want to understand the implications of the prior choice on the outcome-scale, then they would want to simulate from the model and its priors (instead of posteriors)(see McElreath 2020, Chapter 4.3.2). As this is one of the strengths of this simulation-based tool, it would be useful if the authors added prior predictive checks as an explicit step in the described work flow. </p></list-item><list-item><p>Following the above point, I am wondering if the user is limited to priors in the shape of standard distributions (e.g., Normal(0,1) ), or would it be possible for the user to define a prior based on a posterior from a different model, for example in the form of 1000 random draws of the posterior? While I see how this is a computational challenge, I think it is a feature that might be very useful for adding results from other Bayesian studies. Can the authors at least comment on this?</p></list-item><list-item><p>Is it possible to include time varying variables, such as a R0 that is changing in time? It is not clear from the text if this is possible. If yes, a reader might benefit from advise on how to smooth such a variable over time to avoid overfitting.</p></list-item><list-item><p>It would be very helpful to have a cartoon that visualises how odi/dust/mcstate work together and how they make use of the abstractions (particle and dust) and how all this system generates the model building pipeline. </p></list-item></list> As this paper is meant to help researchers like for example infectious disease modellers to make use of sophisticated software, it will be useful to revise the text to help this target audience to better follow the paper. Here are some concrete ideas:
<list list-type="bullet"><list-item><p>A non-technical reader will not gain much from Figure 1 without further comparisons or explanation. What does a straight line signify? Should this surprise, what is to expect?</p></list-item><list-item><p>Briefly explain what a dynamics library is.</p></list-item><list-item><p>Briefly explain why C++ is used at the backend (speed).</p></list-item><list-item><p>Briefly explain (or avoid) the term transpile.</p></list-item><list-item><p>“change in randomness” page 6 should be explained more precisely.</p></list-item><list-item><p>Redefine what “m” mean on page 6.</p></list-item><list-item><p>The indexing in the expression m_{i} seems odd if m is defined as in integer above. Please explain or change.</p></list-item><list-item><p>Is the variance-covariance matrix for the proposal kernel computed in an automated step, or does the user have to do this, or make that setting?</p></list-item><list-item><p>Adding example code that uses the predict() function would help.</p></list-item><list-item><p>“adding square brackets to the left hand side of each declaration”, a reference to a code block should be added. It would help to enumerate the code blocks for easy reference.</p></list-item><list-item><p>It is not clear how entries of the contact matrix m are defined </p></list-item><list-item><p>Equation (1) needs definition of beta, N, I and m.</p></list-item></list> I found a few typos</p>
              <p> “psuedorandom numbers” page 4</p>
              <p> “first dimension[s]” page 12</p>
              <p> “and and” page 15</p>
              <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
              <p>Yes</p>
              <p>Is the rationale for developing the new software tool clearly explained?</p>
              <p>Partly</p>
              <p>Is the description of the software tool technically sound?</p>
              <p>Yes</p>
              <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
              <p>Yes</p>
              <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
              <p>Yes</p>
              <p>Reviewer Expertise:</p>
              <p>Infectious disease epidemiology, COVID-19 dynamics, microbiome dynamics.</p>
              <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
            </body>
            <back>
              <ref-list>
                <title>References</title>
                <ref id="rep-ref-41899-1">
                  <label>1</label>
                  <mixed-citation publication-type="other">
:
<article-title>Statistical rethinking: A Bayesian course with examples in R and Stan</article-title>.
<source><italic toggle="yes">CRC press</italic></source>.<year>Mar 2020</year>;</mixed-citation>
                </ref>
              </ref-list>
            </back>
            <sub-article article-type="response" id="comment4636-41899">
              <front-stub>
                <contrib-group>
                  <contrib contrib-type="author">
                    <name>
                      <surname>Lees</surname>
                      <given-names>John</given-names>
                    </name>
                    <aff>Imperial College London, UK</aff>
                  </contrib>
                </contrib-group>
                <author-notes>
                  <fn fn-type="COI-statement">
                    <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
                  </fn>
                </author-notes>
                <pub-date pub-type="epub">
                  <day>3</day>
                  <month>6</month>
                  <year>2021</year>
                </pub-date>
              </front-stub>
              <body>
                <p>
                  <italic toggle="yes">Knock et al. have developed a software that allows building and fitting of state space models to (partially) observed data and that allows simulation from those models. Like tools such as WinBugs or Stan their tool allows the user to define models in language that is similar to statistical modelling language. It is efficient in fitting time-series via transcribing the model into fast C++ language, parallelisation, and the use of particle filtering, similar to pomp or libBo. It integrates well with commonly used R environment, and it is thus available to use for a wide group of researchers.</italic>
                </p>
                <p>
                  <italic toggle="yes">I would not be surprised if this software and its iterations took an important role for predicting and understanding the ongoing COVID-19 pandemic. A key determinant for this is its development and refinement by an interdisciplinary team, and working with feedback from use case in an urgent public health crisis.</italic>
                </p>
                <p>
                  <italic toggle="yes">I truly enjoyed reading this paper, and I would like to suggest a few points of improvement, before I make some suggestions for improved readability.</italic>
                </p>
                <p> We thank the reviewer for their kind comments and positive summary. We have a number of additional changes to the text which we believe should clarify the points arising.</p>
                <p>
                  <italic toggle="yes">The authors describe at first some general concepts, then the different components of their framework, the random number generator, its operation, and finally a comparison with other tools. It should be made clearer at the very beginning, in what ways this software advances current tools, and combines the advantages of different tools. It remains unclear if the dust-object idea containing particles is novel, or an adaptation. I also suggest extending Table 1 to include several of the other features that differ between dust, pomp, and libBi.</italic>
                </p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p> We are somewhat constrained by the software manuscript format: demonstrating motivation and specific use cases before a full comparison with other methods – so we have left the full comparison with the alternative packages before the summary. However, we do agree that this would be useful to be introduced earlier on, so have added more text to the introduction to clarify the differences between packages, and expanded table 1 as suggested.</p>
                <p> We are not sure of the exact manner in which pomp and libBi are engineering in this regard, but this kind of class definition is a fairly typical occurrence in C++ libraries. But, we have added more of a description of why we opted for the Dust/Particle separation, which we think makes the rationale for this decision clearer, and was missing previously. We have also added and reference a “design” vignette, which describes this in further detail.</p>
                <p>
                  <italic toggle="yes">The tool of the authors follows a Bayesian framework, which I consider especially suitable in the context of COVID-19 modelling where information on biological parameters is added constantly through various trials. I am not entirely sure, but I think the Figure 3 shows a prior-predictive simulations/checks: Once a user has written the structure of a model and they want to understand the implications of the prior choice on the outcome-scale, then they would want to simulate from the model and its priors (instead of posteriors)(see McElreath 2020, Chapter 4.3.2). As this is one of the strengths of this simulation-based tool, it would be useful if the authors added prior predictive checks as an explicit step in the described work flow. </italic>
                </p>
                <p> We now follow the reviewer’s suggestion, and add a section on simulating from the priors to the workflow. Notably, we have added a simulate method to the dust package which makes running models across the time series using a specific set of parameters easier and more flexible.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">Following the above point, I am wondering if the user is limited to priors in the shape of standard distributions (e.g., Normal(0,1) ), or would it be possible for the user to define a prior based on a posterior from a different model, for example in the form of 1000 random draws of the posterior? While I see how this is a computational challenge, I think it is a feature that might be very useful for adding results from other Bayesian studies. Can the authors at least comment on this?</italic>
                </p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p> One advantage of our framework’s tight integration with R is that functions for the likelihood and prior are completely flexible, and can use any functionality the R language allows. Although we demonstrate with a simple prior distribution in the use cases, any function can be defined. This can include using functions from external packages, or, as suggested, drawing from another model’s posterior. We’ve noted this more specifically in the revised text. A future feature will include the ability to ‘restart’ models from part way along the time series, and will draw on this suggestion to re-initialise the model.</p>
                <p>
                  <italic toggle="yes">Is it possible to include time varying variables, such as a R0 that is changing in time? It is not clear from the text if this is possible. If yes, a reader might benefit from advise on how to smooth such a variable over time to avoid overfitting.</italic>
                </p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p> Indeed, this is possible, and used extensively in the SIRCOVID package. To do so in these packages usually requires adding a simple ‘transform’ function in the particle filter, which translates between the parameters being inferred in R, and parameters in the model code. The easiest way to implement time-varying parameters is to make them piecewise-linear, and point the reader to the example in SIRCOVID of how to set this up (but do add a paragraph noting this to the examples). In theory a smoothing method such a spline fitting using a few free parameters would also be possible, but we do not demonstrate that here.</p>
                <p>
                  <italic toggle="yes">It would be very helpful to have a cartoon that visualises how odin/dust/mcstate work together and how they make use of the abstractions (particle and dust) and how all this system generates the model building pipeline. </italic>
                </p>
                <p> We have added an extra figure giving an overview of the software packages.</p>
                <p>
                  <italic toggle="yes">As this paper is meant to help researchers like for example infectious disease modellers to make use of sophisticated software, it will be useful to revise the text to help this target audience to better follow the paper. Here are some concrete ideas:</italic>
                </p>
                <p> Thank you for these suggestions, which we address individually below. We expect that many modellers will find the package vignettes particularly useful in addition to this paper – there we are able to separate out technical language on design decisions with practical guides on how to use the software.</p>
                <p>
                  <italic toggle="yes">A non-technical reader will not gain much from Figure 1 without further comparisons or explanation. What does a straight line signify? Should this surprise, what is to expect?</italic>
                </p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p> Added to caption.</p>
                <p>
                  <italic toggle="yes">Briefly explain what a dynamics library is.</italic>
                </p>
                <p> Added.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">Briefly explain why C++ is used at the backend (speed).</italic>
                </p>
                <p> Added.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">Briefly explain (or avoid) the term transpile.</italic>
                </p>
                <p> Added.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">“change in randomness” page 6 should be explained more precisely.</italic>
                </p>
                <p> Explanation added.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">Redefine what “m” mean on page 6.</italic>
                </p>
                <p>
                  <italic toggle="yes">The indexing in the expression m_{i} seems odd if m is defined as in integer above. Please explain or change.</italic>
                </p>
                <p> Thanks for spotting this – this should have been
<italic toggle="yes">p</italic>, indexed for each core/thread not chain.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">Is the variance-covariance matrix for the proposal kernel computed in an automated step, or does the user have to do this, or make that setting?</italic>
                </p>
                <p> This is indeed a user option. We note that in the text, and a package vignette discusses how to set this in more detail than we have space for in this paper.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">Adding example code that uses the predict() function would help.</italic>
                </p>
                <p> Added.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">“adding square brackets to the left hand side of each declaration”, a reference to a code block should be added. It would help to enumerate the code blocks for easy reference.</italic>
                </p>
                <p> Reference to code block added. We are unfortunately unable to give line numbers to the code blocks due to formatting constraints.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">It is not clear how entries of the contact matrix m are defined </italic>
                </p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p> We have reordered the text slightly, and expanded the description.</p>
                <p>
                  <italic toggle="yes">Equation (1) needs definition of beta, N, I and m.</italic>
                </p>
                <p>
                  <italic toggle="yes">I found a few typos</italic>
                </p>
                <p>
                  <italic toggle="yes">“psuedorandom numbers” page 4</italic>
                </p>
                <p>
                  <italic toggle="yes">“first dimension[s]” page 12</italic>
                </p>
                <p>
                  <italic toggle="yes">“and and” page 15</italic>
                </p>
                <p> Typos fixed.</p>
              </body>
            </sub-article>
          </sub-article>
          <sub-article article-type="peer-review" id="report42058">
            <front-stub>
              <article-id pub-id-type="doi">10.21956/wellcomeopenres.18131.r42058</article-id>
              <title-group>
                <article-title>Reviewer response for version 1</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Ionides</surname>
                    <given-names>Edward</given-names>
                  </name>
                  <xref rid="r42058a1" ref-type="aff">1</xref>
                  <role>Referee</role>
                  <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4190-0174</contrib-id>
                </contrib>
                <aff id="r42058a1"><label>1</label>Department of Statistics, University of Michigan, Ann Arbor, MI, USA</aff>
              </contrib-group>
              <author-notes>
                <fn fn-type="COI-statement">
                  <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
                </fn>
              </author-notes>
              <pub-date pub-type="epub">
                <day>20</day>
                <month>1</month>
                <year>2021</year>
              </pub-date>
              <permissions>
                <copyright-statement>Copyright: © 2021 Ionides E</copyright-statement>
                <copyright-year>2021</copyright-year>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
                </license>
              </permissions>
              <related-article related-article-type="peer-reviewed-article" ext-link-type="doi" id="relatedArticleReport42058" xlink:href="10.12688/wellcomeopenres.16466.1">Version 1</related-article>
              <custom-meta-group>
                <custom-meta>
                  <meta-name>recommendation</meta-name>
                  <meta-value>approve-with-reservations</meta-value>
                </custom-meta>
              </custom-meta-group>
            </front-stub>
            <body>
              <p>The authors have built a framework for model development and statistical inference for complex partially observed stochastic dynamic models, motivated by applications in epidemiology. The methods are simulation-based, offering scientists appealing flexibility to investigate a range of different model specifications. The resulting odin/dust/mcstate software environment is compared with two other packages having similar capabilities, libBi and pomp. Time comparisons are comparable, but odin/dust/mcstate has had considerable work put into some important practical considerations: (i) the domain-specific language (DSL) used for model specification; (ii) parallelization issues.</p>
              <p> The work undertaken by the authors contributes a new perspective to the worthwhile task of building and testing models to interpret data on noisy and incompletely measured dynamic systems. I shall compare odin/dust/mcstate to my experiences with pomp (King
<italic toggle="yes">et al</italic>, 2016)
<sup><xref rid="rep-ref-42058-1" ref-type="bibr">1</xref></sup> raising some points that are missing from the current version of the authors' manuscript.
<list list-type="order"><list-item><p>The authors emphasize only Bayesian inference. The Bayesian paradigm is convenient for combining uncertainty about parameters with variability inherent in the dynamics, making it well placed to provide forecasts once the prior and model are satisfactory. However, in some situations there are advantages to avoiding the additional requirement to add to the model a quantification of prior uncertainty about parameters. For model criticism, the goal is to diagnose features of the model that are incompatible with the data. If such features exist, then a compatible prior does not exist and so the requirement to specify one is a hindrance rather than a help. It may be better to first investigate model specification by cycles of the scientific method promoted by Popper (1959)
<sup><xref rid="rep-ref-42058-2" ref-type="bibr">2</xref></sup>: What features of the data are inconsistent with the hypothesized model? Can we find a better model?</p></list-item><list-item><p>Maximum likelihood estimation, and associated likelihood ratio tests and profile likelihood confidence intervals, provide non-Bayesian methodology for partially observed stochastic dynamic models that also make statistically efficient use of data. The odin/dust/mcstate framework could, for example, implement an iterated filtering likelihood maximization (Ionides
<italic toggle="yes">et al</italic>, 2015)
<sup><xref rid="rep-ref-42058-3" ref-type="bibr">3</xref></sup> as has been much used in pomp.</p></list-item><list-item><p>Monte Carlo adjusted profile likelihood estimation (Ionides
<italic toggle="yes">et al</italic>, 2017)
<sup><xref rid="rep-ref-42058-4" ref-type="bibr">4</xref></sup> has some favorable scaling properties (Ning
<italic toggle="yes">et al</italic>, 2020)
<sup><xref rid="rep-ref-42058-5" ref-type="bibr">5</xref></sup> that are not shared by particle Markov chain Monte Carlo (Doucet
<italic toggle="yes">et al</italic>, 2015)
<sup><xref rid="rep-ref-42058-6" ref-type="bibr">6</xref></sup>. For analysis that stretches available computational resources, computational scaling may be another reason to consider likelihood-based inference.</p></list-item><list-item><p>I agree with the authors on the importance of developing software accessible to a broad technical audience. The DSL written by the authors builds on the success of packages such as WinBUGS, JAGS, and stan. The Csnippet approach used by pomp is somewhat different: it gives the users the full flexibility of C while hiding certain details such as variable definitions for latent states, observations and parameters. For simple models, pomp Csnippet code can look very much like WinBUGS DSL code. For more complex models, the user may start needing to use increasingly esoteric properties of C, but this is a strength as well as a weakness, since it is hard to anticipate and encode in a DSL all the features one might want in a simulation model. The Csnippet framework is simple enough that it is accessible to students in a
<ext-link xlink:href="https://ionides.github.io/531w20/final_project/" ext-link-type="uri">Masters level time series course</ext-link> where students with no prior C experience develop and fit their own pomp analysis.</p></list-item><list-item><p>The benefits of parallelizing the particle filter depend on the purpose to which it is put. If it is used in a single, long, particle Monte Carlo Markov chain calculation then parallelization may help. However, in practice, one should carry out many replications of the inferential algorithm while varying the starting point and the seed of the random number generator. In a likelihood-based framework, one may want to evaluate and maximize the likelihood at a range of profile points. In these cases, parallelizing within the particle filter can be inferior to parallelizing over the embarassingly parallel replicated filters.</p></list-item></list>
</p>
              <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
              <p>Yes</p>
              <p>Is the rationale for developing the new software tool clearly explained?</p>
              <p>Yes</p>
              <p>Is the description of the software tool technically sound?</p>
              <p>Yes</p>
              <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
              <p>Yes</p>
              <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
              <p>Yes</p>
              <p>Reviewer Expertise:</p>
              <p>Time series analysis, with applications in epidemiology and ecology.</p>
              <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.</p>
            </body>
            <back>
              <ref-list>
                <title>References</title>
                <ref id="rep-ref-42058-1">
                  <label>1</label>
                  <mixed-citation publication-type="journal">
:
<article-title>Statistical Inference for Partially Observed Markov Processes via theR Packagepomp</article-title>.
<source><italic toggle="yes">Journal of Statistical Software</italic></source>.<year>2016</year>;<volume>69</volume>(<issue>12</issue>) :
<elocation-id>10.18637/jss.v069.i12</elocation-id>
<pub-id pub-id-type="doi">10.18637/jss.v069.i12</pub-id>
</mixed-citation>
                </ref>
                <ref id="rep-ref-42058-2">
                  <label>2</label>
                  <mixed-citation publication-type="other">
:
<article-title>The Logic of Scientific Discovery</article-title>.
<source><italic toggle="yes">Hutchinson</italic></source>.<year>1959</year>;</mixed-citation>
                </ref>
                <ref id="rep-ref-42058-3">
                  <label>3</label>
                  <mixed-citation publication-type="journal">
:
<article-title>Inference for dynamic and latent variable models via iterated, perturbed Bayes maps.</article-title>
<source><italic toggle="yes">Proc Natl Acad Sci U S A</italic></source>.<year>2015</year>;<volume>112</volume>(<issue>3</issue>) :
<elocation-id>10.1073/pnas.1410597112</elocation-id>
<fpage>719</fpage>-<lpage>24</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.1410597112</pub-id>
<?supplied-pmid 25568084?><pub-id pub-id-type="pmid">25538295</pub-id></mixed-citation>
                </ref>
                <ref id="rep-ref-42058-4">
                  <label>4</label>
                  <mixed-citation publication-type="journal">
:
<article-title>Monte Carlo profile confidence intervals for dynamic systems.</article-title>
<source><italic toggle="yes">J R Soc Interface</italic></source>.<volume>14</volume>(<issue>132</issue>) :
<elocation-id>10.1098/rsif.2017.0126</elocation-id>
<pub-id pub-id-type="doi">10.1098/rsif.2017.0126</pub-id>
<?supplied-pmid 28679663?><pub-id pub-id-type="pmid">28679663</pub-id></mixed-citation>
                </ref>
                <ref id="rep-ref-42058-5">
                  <label>5</label>
                  <mixed-citation publication-type="other">
:
<article-title>Scalable Monte Carlo Inference and Rescaled Local Asymptotic Normality</article-title>.
<source><italic toggle="yes">arXiv</italic></source>.<year>2020</year>;
<ext-link xlink:href="https://arxiv.org/abs/2007.00723" ext-link-type="uri">Reference source</ext-link>
</mixed-citation>
                </ref>
                <ref id="rep-ref-42058-6">
                  <label>6</label>
                  <mixed-citation publication-type="journal">
:
<article-title>Efficient implementation of Markov chain Monte Carlo when using an unbiased likelihood estimator</article-title>.
<source><italic toggle="yes">Biometrika</italic></source>.<year>2015</year>;<volume>102</volume>(<issue>2</issue>) :
<elocation-id>10.1093/biomet/asu075</elocation-id>
<fpage>295</fpage>-<lpage>313</lpage>
<pub-id pub-id-type="doi">10.1093/biomet/asu075</pub-id>
</mixed-citation>
                </ref>
              </ref-list>
            </back>
            <sub-article article-type="response" id="comment4635-42058">
              <front-stub>
                <contrib-group>
                  <contrib contrib-type="author">
                    <name>
                      <surname>Lees</surname>
                      <given-names>John</given-names>
                    </name>
                    <aff>Imperial College London, UK</aff>
                  </contrib>
                </contrib-group>
                <author-notes>
                  <fn fn-type="COI-statement">
                    <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
                  </fn>
                </author-notes>
                <pub-date pub-type="epub">
                  <day>3</day>
                  <month>6</month>
                  <year>2021</year>
                </pub-date>
              </front-stub>
              <body>
                <p>
                  <italic toggle="yes">The authors have built a framework for model development and statistical inference for complex partially observed stochastic dynamic models, motivated by applications in epidemiology. The methods are simulation-based, offering scientists appealing flexibility to investigate a range of different model specifications. The resulting odin/dust/mcstate software environment is compared with two other packages having similar capabilities, libBi and pomp. Time comparisons are comparable, but odin/dust/mcstate has had considerable work put into some important practical considerations: (i) the domain-specific language (DSL) used for model specification; (ii) parallelization issues.</italic>
                </p>
                <p>
                  <italic toggle="yes">The work undertaken by the authors contributes a new perspective to the worthwhile task of building and testing models to interpret data on noisy and incompletely measured dynamic systems. I shall compare odin/dust/mcstate to my experiences with pomp (King et al, 2016)
<sup>1</sup> raising some points that are missing from the current version of the authors' manuscript.</italic>
                </p>
                <p> We thank the reviewer for their comments and thoughtful suggestions. We have made two major additions to the code to add the functionality as suggested, and modified the text to better address the issues raised. We have also added some of this summary into our introduction, to introduce pomp and libBi earlier on.</p>
                <p>
                  <italic toggle="yes">The authors emphasize only Bayesian inference. The Bayesian paradigm is convenient for combining uncertainty about parameters with variability inherent in the dynamics, making it well placed to provide forecasts once the prior and model are satisfactory. However, in some situations there are advantages to avoiding the additional requirement to add to the model a quantification of prior uncertainty about parameters. For model criticism, the goal is to diagnose features of the model that are incompatible with the data. If such features exist, then a compatible prior does not exist and so the requirement to specify one is a hindrance rather than a help. It may be better to first investigate model specification by cycles of the scientific method promoted by Popper (1959)
<sup>2</sup>: What features of the data are inconsistent with the hypothesized model? Can we find a better model?</italic>
                </p>
                <p> It is true that we focused on Bayesian inference using a prior and model which have been determined to be satisfactory, which leaves out the model criticism phase. We have now added two sections on model criticism, alternatives to prior specification, and maximum likelihood estimation (noting the additions in response to the second point). We hope this expands to scope of discussion here suitably.</p>
                <p>
                  <italic toggle="yes"> </italic>
                </p>
                <p>
                  <italic toggle="yes">Maximum likelihood estimation, and associated likelihood ratio tests and profile likelihood confidence intervals, provide non-Bayesian methodology for partially observed stochastic dynamic models that also make statistically efficient use of data. The odin/dust/mcstate framework could, for example, implement an iterated filtering likelihood maximization (Ionides et al, 2015)
<sup>3</sup> as has been much used in pomp.</italic>
                </p>
                <p> Thank you for this suggestion, we agree that this would be a nice addition, and fits well with the design of our packages. We have now implemented and tested this algorithm using dust and mcstate. We have also added a package vignette and section to this paper describing its use.</p>
                <p>
                  <italic toggle="yes">Monte Carlo adjusted profile likelihood estimation (Ionides et al, 2017)
<sup>4</sup> has some favorable scaling properties (Ning et al, 2020)
<sup>5</sup> that are not shared by particle Markov chain Monte Carlo (Doucet et al, 2015)
<sup>6</sup>. For analysis that stretches available computational resources, computational scaling may be another reason to consider likelihood-based inference.</italic>
                </p>
                <p> We hope that our additions to the text and the addition of the iterated filtering algorithm now allow likelihood-based inference in our packages. Although we have not added the MCAP algorithm to the package code, we have added this point and associated references to the text, as is done in pomp.</p>
                <p>
                  <italic toggle="yes">I agree with the authors on the importance of developing software accessible to a broad technical audience. The DSL written by the authors builds on the success of packages such as WinBUGS, JAGS, and stan. The Csnippet approach used by pomp is somewhat different: it gives the users the full flexibility of C while hiding certain details such as variable definitions for latent states, observations and parameters. For simple models, pomp Csnippet code can look very much like WinBUGS DSL code. For more complex models, the user may start needing to use increasingly esoteric properties of C, but this is a strength as well as a weakness, since it is hard to anticipate and encode in a DSL all the features one might want in a simulation model. The Csnippet framework is simple enough that it is accessible to students in a Masters level time series course where students with no prior C experience develop and fit their own pomp analysis.</italic>
                </p>
                <p> Thank you for this perspective on the Csnippet approach. We have expanded our discussion of the DSL to note the strengths and weaknesses of either approach from a user point of view.</p>
                <p> If greater flexibility is required, we also note that it is possible to directly write C/C++ code to be used as a dust model (and therefore with the rest of our framework). The easiest way of doing this is by modifying one of our examples – by just changing single sections of the model definition this ends up being somewhat similar to the Csnippet approach. For testing some models and new features of dust, this is the route we took. Our experience with real-life complex models has been that the odin DSL was greatly preferred due to its built-in bookkeeping of model indices, and did not limit any of the required features.</p>
                <p> As a further alternative, we have also added the ability to the odin DSL to call arbitrary C++ functions – essentially imitating the Csnippet approach where the DSL may prove limiting.</p>
                <p>
                  <italic toggle="yes">The benefits of parallelizing the particle filter depend on the purpose to which it is put. If it is used in a single, long, particle Monte Carlo Markov chain calculation then parallelization may help. However, in practice, one should carry out many replications of the inferential algorithm while varying the starting point and the seed of the random number generator. In a likelihood-based framework, one may want to evaluate and maximize the likelihood at a range of profile points. In these cases, parallelizing within the particle filter can be inferior to parallelizing over the embarassingly parallel replicated filters.</italic>
                </p>
                <p> This is an excellent point, and as such we have now expanded the flexibility of the parallelisation. Users can now parallelise both over particles and over filters independently, and choose how to do so depending on their problem. The interface is straightforward – between chain parallelism is enabled by increasing the number of workers, and specifying a total number of threads available.</p>
                <p> The issue of varying the starting point is addressed by the ‘initial’ argument to the particle filter, through which the user can specify an arbitrary R function to generate the initial conditions for the filter.</p>
                <p> We have added the pmcmc_chains_prepare() function to address the issue of varying the starting seed. This uses the ‘long jump’ feature of the Xoshiro random number generator to generate streams which are uncorrelated even when further parallelisation is used within them. This function automates both the process of initialising a set of chains with different (and uncorrelated) seeds and initial conditions.</p>
                <p> We concur that parallelising within the particle filter can be inferior to parallelising chains – in some cases we have observed up to a 40% loss of efficiency (mostly due to particle divergence). We have found the added flexibility on this matter of great practical use in large problems on large distributed systems. Using code to orchestrate and collect information from independent runs, we can now run independent particle filters on separate computer nodes, and nested within these parallelise further over particles on each shared memory node. This top level of parallelisation can also be used to run with different parameters, or using the same model with different data (for example, fitting a COVID-19 model to different regions).</p>
              </body>
            </sub-article>
          </sub-article>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
